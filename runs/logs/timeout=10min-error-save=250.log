W0317 02:25:51.727000 140520969041088 torch/distributed/run.py:779] 
W0317 02:25:51.727000 140520969041088 torch/distributed/run.py:779] *****************************************
W0317 02:25:51.727000 140520969041088 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0317 02:25:51.727000 140520969041088 torch/distributed/run.py:779] *****************************************
[2025-03-17 02:26:01,795] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-03-17 02:26:01,814] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-03-17 02:26:01,833] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-03-17 02:26:01,891] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-03-17 02:26:01,906] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-03-17 02:26:01,954] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-03-17 02:26:01,954] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-03-17 02:26:01,985] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
2025-03-17 02:26:44.426463: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-03-17 02:26:44.486166: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-03-17 02:26:44.500569: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-03-17 02:26:44.504094: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1742210804.535889   96372 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1742210804.546084   96372 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1742210804.590005   96375 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-03-17 02:26:44.592907: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
E0000 00:00:1742210804.595018   96375 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-03-17 02:26:44.614131: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-03-17 02:26:44.632959: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-03-17 02:26:44.634505: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-03-17 02:26:44.783583: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-03-17 02:26:44.792643: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-03-17 02:26:44.802759: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-03-17 02:26:44.807637: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-03-17 02:26:44.808960: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1742210804.812154   96376 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-03-17 02:26:44.813942: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
E0000 00:00:1742210804.823812   96376 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1742210804.839444   96373 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-03-17 02:26:44.848738: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
E0000 00:00:1742210804.849760   96373 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-03-17 02:26:44.854679: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1742210804.867694   96374 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-03-17 02:26:44.870648: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-03-17 02:26:44.872666: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
E0000 00:00:1742210804.877216   96374 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-03-17 02:26:44.885635: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-03-17 02:26:44.896922: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1742210804.908427   96377 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1742210804.914949   96378 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1742210804.926639   96377 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
E0000 00:00:1742210804.932750   96378 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-03-17 02:26:45.004779: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1742210805.014443   96371 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-03-17 02:26:45.030538: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
E0000 00:00:1742210805.030792   96371 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-03-17 02:26:45.048300: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-03-17 02:26:45.224545: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2025-03-17 02:27:02,412] [INFO] using world size: 8
[2025-03-17 02:27:02,413] [INFO] Will override arguments with manually specified deepspeed_config!
[W317 02:27:02.332383207 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[W317 02:27:02.332632465 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[2025-03-17 02:27:02,516] [INFO] [comm.py:652:init_distributed] cdb=None
[W317 02:27:03.673787555 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[W317 02:27:03.673922692 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[2025-03-17 02:27:03,857] [INFO] [comm.py:652:init_distributed] cdb=None
[W317 02:27:04.026889133 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[W317 02:27:04.026966312 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W317 02:27:04.028925065 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[W317 02:27:04.028999844 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W317 02:27:04.029884661 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[W317 02:27:04.029979202 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W317 02:27:04.031490719 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[W317 02:27:04.031565769 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[2025-03-17 02:27:04,217] [INFO] [comm.py:652:init_distributed] cdb=None
[2025-03-17 02:27:04,217] [INFO] [comm.py:652:init_distributed] cdb=None
[2025-03-17 02:27:04,219] [INFO] [comm.py:652:init_distributed] cdb=None
[2025-03-17 02:27:04,222] [INFO] [comm.py:652:init_distributed] cdb=None
[W317 02:27:04.048638487 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[W317 02:27:04.048725677 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[2025-03-17 02:27:04,237] [INFO] [comm.py:652:init_distributed] cdb=None
[W317 02:27:04.057655616 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[W317 02:27:04.057740332 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[2025-03-17 02:27:04,244] [INFO] [RANK 0] > initializing model parallel with size 1
[2025-03-17 02:27:04,246] [INFO] [comm.py:652:init_distributed] cdb=None
[2025-03-17 02:27:07,144] [INFO] [RANK 0] building SATVideoDiffusionEngine model ...
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:21<00:21, 21.96s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:22<00:22, 22.79s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:25<00:25, 25.23s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:22<00:22, 22.64s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:25<00:25, 25.46s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:26<00:26, 26.92s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:26<00:26, 26.12s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:29<00:29, 29.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:42<00:00, 20.98s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:42<00:00, 21.13s/it]
Initialized embedder #0: FrozenT5Embedder with 4762310656 params. Trainable: False
Working with z of shape (1, 16, 32, 32) = 16384 dimensions.
Loading checkpoint shards: 100%|██████████| 2/2 [00:47<00:00, 23.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:47<00:00, 23.62s/it]
Initialized embedder #0: FrozenT5Embedder with 4762310656 params. Trainable: False
Loading checkpoint shards: 100%|██████████| 2/2 [00:48<00:00, 23.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:48<00:00, 24.15s/it]
Initialized embedder #0: FrozenT5Embedder with 4762310656 params. Trainable: False
Working with z of shape (1, 16, 32, 32) = 16384 dimensions.
Loading checkpoint shards: 100%|██████████| 2/2 [00:43<00:00, 21.77s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:43<00:00, 21.90s/it]
Initialized embedder #0: FrozenT5Embedder with 4762310656 params. Trainable: False
Working with z of shape (1, 16, 32, 32) = 16384 dimensions.
Loading checkpoint shards: 100%|██████████| 2/2 [00:48<00:00, 23.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:48<00:00, 24.13s/it]
Working with z of shape (1, 16, 32, 32) = 16384 dimensions.
Initialized embedder #0: FrozenT5Embedder with 4762310656 params. Trainable: False
Deleting key loss.logvar from state_dict.
Deleting key loss.perceptual_loss.scaling_layer.shift from state_dict.
Deleting key loss.perceptual_loss.scaling_layer.scale from state_dict.
Deleting key loss.perceptual_loss.net.slice1.0.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice1.0.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice1.2.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice1.2.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice2.5.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice2.5.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice2.7.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice2.7.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice3.10.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice3.10.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice3.12.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice3.12.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice3.14.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice3.14.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice4.17.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice4.17.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice4.19.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice4.19.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice4.21.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice4.21.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice5.24.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice5.24.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice5.26.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice5.26.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice5.28.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice5.28.bias from state_dict.
Deleting key loss.perceptual_loss.lin0.model.1.weight from state_dict.
Deleting key loss.perceptual_loss.lin1.model.1.weight from state_dict.
Deleting key loss.perceptual_loss.lin2.model.1.weight from state_dict.
Deleting key loss.perceptual_loss.lin3.model.1.weight from state_dict.
Deleting key loss.perceptual_loss.lin4.model.1.weight from state_dict.
Deleting key loss.discriminator.blocks.0.downsample_res.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.0.downsample_res.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.0.net.0.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.0.net.0.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.0.net.2.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.0.net.2.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.0.downsample.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.0.downsample.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.1.downsample_res.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.1.downsample_res.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.1.net.0.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.1.net.0.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.1.net.2.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.1.net.2.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.1.downsample.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.1.downsample.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.2.downsample_res.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.2.downsample_res.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.2.net.0.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.2.net.0.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.2.net.2.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.2.net.2.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.2.downsample.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.2.downsample.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.3.downsample_res.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.3.downsample_res.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.3.net.0.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.3.net.0.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.3.net.2.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.3.net.2.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.3.downsample.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.3.downsample.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.4.0.conv_res.weight from state_dict.
Deleting key loss.discriminator.blocks.4.0.conv_res.bias from state_dict.
Deleting key loss.discriminator.blocks.4.0.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.0.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.4.0.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.4.0.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.4.0.downsample.1.weight from state_dict.
Deleting key loss.discriminator.blocks.4.0.downsample.1.bias from state_dict.
Deleting key loss.discriminator.blocks.4.1.0.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.4.1.0.fn.attn.to_q.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.0.fn.attn.to_kv.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.0.fn.attn.to_out.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.5.0.conv_res.weight from state_dict.
Deleting key loss.discriminator.blocks.5.0.conv_res.bias from state_dict.
Deleting key loss.discriminator.blocks.5.0.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.0.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.5.0.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.5.0.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.5.0.downsample.1.weight from state_dict.
Deleting key loss.discriminator.blocks.5.0.downsample.1.bias from state_dict.
Deleting key loss.discriminator.blocks.5.1.0.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.5.1.0.fn.attn.to_q.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.0.fn.attn.to_kv.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.0.fn.attn.to_out.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.6.0.conv_res.weight from state_dict.
Deleting key loss.discriminator.blocks.6.0.conv_res.bias from state_dict.
Deleting key loss.discriminator.blocks.6.0.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.0.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.6.0.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.6.0.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.6.1.0.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.6.1.0.fn.attn.to_q.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.0.fn.attn.to_kv.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.0.fn.attn.to_out.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.net.2.bias from state_dict.
Deleting key loss.discriminator.to_logits.0.weight from state_dict.
Deleting key loss.discriminator.to_logits.0.bias from state_dict.
Deleting key loss.discriminator.to_logits.3.weight from state_dict.
Deleting key loss.discriminator.to_logits.3.bias from state_dict.
Loading checkpoint shards: 100%|██████████| 2/2 [00:48<00:00, 23.79s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:48<00:00, 24.26s/it]
Initialized embedder #0: FrozenT5Embedder with 4762310656 params. Trainable: False
Missing keys:  []
Unexpected keys:  []
Restored from ./pretrained_models/cogvideox-5b-i2v-sat/vae/3d-vae.pt
Deleting key loss.logvar from state_dict.
Deleting key loss.perceptual_loss.scaling_layer.shift from state_dict.
Deleting key loss.perceptual_loss.scaling_layer.scale from state_dict.
Deleting key loss.perceptual_loss.net.slice1.0.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice1.0.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice1.2.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice1.2.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice2.5.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice2.5.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice2.7.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice2.7.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice3.10.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice3.10.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice3.12.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice3.12.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice3.14.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice3.14.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice4.17.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice4.17.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice4.19.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice4.19.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice4.21.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice4.21.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice5.24.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice5.24.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice5.26.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice5.26.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice5.28.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice5.28.bias from state_dict.
Deleting key loss.perceptual_loss.lin0.model.1.weight from state_dict.
Deleting key loss.perceptual_loss.lin1.model.1.weight from state_dict.
Deleting key loss.perceptual_loss.lin2.model.1.weight from state_dict.
Deleting key loss.perceptual_loss.lin3.model.1.weight from state_dict.
Deleting key loss.perceptual_loss.lin4.model.1.weight from state_dict.
Deleting key loss.discriminator.blocks.0.downsample_res.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.0.downsample_res.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.0.net.0.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.0.net.0.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.0.net.2.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.0.net.2.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.0.downsample.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.0.downsample.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.1.downsample_res.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.1.downsample_res.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.1.net.0.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.1.net.0.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.1.net.2.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.1.net.2.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.1.downsample.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.1.downsample.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.2.downsample_res.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.2.downsample_res.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.2.net.0.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.2.net.0.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.2.net.2.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.2.net.2.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.2.downsample.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.2.downsample.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.3.downsample_res.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.3.downsample_res.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.3.net.0.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.3.net.0.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.3.net.2.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.3.net.2.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.3.downsample.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.3.downsample.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.4.0.conv_res.weight from state_dict.
Deleting key loss.discriminator.blocks.4.0.conv_res.bias from state_dict.
Deleting key loss.discriminator.blocks.4.0.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.0.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.4.0.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.4.0.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.4.0.downsample.1.weight from state_dict.
Deleting key loss.discriminator.blocks.4.0.downsample.1.bias from state_dict.
Deleting key loss.discriminator.blocks.4.1.0.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.4.1.0.fn.attn.to_q.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.0.fn.attn.to_kv.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.0.fn.attn.to_out.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.5.0.conv_res.weight from state_dict.
Deleting key loss.discriminator.blocks.5.0.conv_res.bias from state_dict.
Deleting key loss.discriminator.blocks.5.0.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.0.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.5.0.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.5.0.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.5.0.downsample.1.weight from state_dict.
Deleting key loss.discriminator.blocks.5.0.downsample.1.bias from state_dict.
Deleting key loss.discriminator.blocks.5.1.0.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.5.1.0.fn.attn.to_q.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.0.fn.attn.to_kv.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.0.fn.attn.to_out.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.6.0.conv_res.weight from state_dict.
Deleting key loss.discriminator.blocks.6.0.conv_res.bias from state_dict.
Deleting key loss.discriminator.blocks.6.0.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.0.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.6.0.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.6.0.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.6.1.0.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.6.1.0.fn.attn.to_q.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.0.fn.attn.to_kv.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.0.fn.attn.to_out.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.net.2.bias from state_dict.
Deleting key loss.discriminator.to_logits.0.weight from state_dict.
Deleting key loss.discriminator.to_logits.0.bias from state_dict.
Deleting key loss.discriminator.to_logits.3.weight from state_dict.
Deleting key loss.discriminator.to_logits.3.bias from state_dict.
Missing keys:  []
Unexpected keys:  []
Restored from ./pretrained_models/cogvideox-5b-i2v-sat/vae/3d-vae.pt
Working with z of shape (1, 16, 32, 32) = 16384 dimensions.
Deleting key loss.logvar from state_dict.
Deleting key loss.perceptual_loss.scaling_layer.shift from state_dict.
Deleting key loss.perceptual_loss.scaling_layer.scale from state_dict.
Deleting key loss.perceptual_loss.net.slice1.0.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice1.0.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice1.2.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice1.2.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice2.5.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice2.5.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice2.7.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice2.7.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice3.10.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice3.10.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice3.12.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice3.12.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice3.14.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice3.14.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice4.17.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice4.17.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice4.19.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice4.19.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice4.21.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice4.21.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice5.24.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice5.24.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice5.26.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice5.26.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice5.28.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice5.28.bias from state_dict.
Deleting key loss.perceptual_loss.lin0.model.1.weight from state_dict.
Deleting key loss.perceptual_loss.lin1.model.1.weight from state_dict.
Deleting key loss.perceptual_loss.lin2.model.1.weight from state_dict.
Deleting key loss.perceptual_loss.lin3.model.1.weight from state_dict.
Deleting key loss.perceptual_loss.lin4.model.1.weight from state_dict.
Deleting key loss.discriminator.blocks.0.downsample_res.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.0.downsample_res.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.0.net.0.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.0.net.0.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.0.net.2.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.0.net.2.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.0.downsample.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.0.downsample.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.1.downsample_res.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.1.downsample_res.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.1.net.0.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.1.net.0.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.1.net.2.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.1.net.2.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.1.downsample.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.1.downsample.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.2.downsample_res.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.2.downsample_res.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.2.net.0.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.2.net.0.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.2.net.2.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.2.net.2.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.2.downsample.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.2.downsample.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.3.downsample_res.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.3.downsample_res.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.3.net.0.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.3.net.0.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.3.net.2.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.3.net.2.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.3.downsample.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.3.downsample.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.4.0.conv_res.weight from state_dict.
Deleting key loss.discriminator.blocks.4.0.conv_res.bias from state_dict.
Deleting key loss.discriminator.blocks.4.0.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.0.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.4.0.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.4.0.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.4.0.downsample.1.weight from state_dict.
Deleting key loss.discriminator.blocks.4.0.downsample.1.bias from state_dict.
Deleting key loss.discriminator.blocks.4.1.0.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.4.1.0.fn.attn.to_q.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.0.fn.attn.to_kv.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.0.fn.attn.to_out.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.5.0.conv_res.weight from state_dict.
Deleting key loss.discriminator.blocks.5.0.conv_res.bias from state_dict.
Deleting key loss.discriminator.blocks.5.0.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.0.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.5.0.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.5.0.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.5.0.downsample.1.weight from state_dict.
Deleting key loss.discriminator.blocks.5.0.downsample.1.bias from state_dict.
Deleting key loss.discriminator.blocks.5.1.0.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.5.1.0.fn.attn.to_q.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.0.fn.attn.to_kv.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.0.fn.attn.to_out.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.6.0.conv_res.weight from state_dict.
Deleting key loss.discriminator.blocks.6.0.conv_res.bias from state_dict.
Deleting key loss.discriminator.blocks.6.0.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.0.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.6.0.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.6.0.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.6.1.0.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.6.1.0.fn.attn.to_q.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.0.fn.attn.to_kv.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.0.fn.attn.to_out.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.net.2.bias from state_dict.
Deleting key loss.discriminator.to_logits.0.weight from state_dict.
Deleting key loss.discriminator.to_logits.0.bias from state_dict.
Deleting key loss.discriminator.to_logits.3.weight from state_dict.
Deleting key loss.discriminator.to_logits.3.bias from state_dict.
Working with z of shape (1, 16, 32, 32) = 16384 dimensions.
Loading checkpoint shards: 100%|██████████| 2/2 [00:48<00:00, 23.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:48<00:00, 24.10s/it]
Missing keys:  []
Unexpected keys:  []
Restored from ./pretrained_models/cogvideox-5b-i2v-sat/vae/3d-vae.pt
Initialized embedder #0: FrozenT5Embedder with 4762310656 params. Trainable: False
Loading checkpoint shards: 100%|██████████| 2/2 [00:52<00:00, 25.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:52<00:00, 26.16s/it]
Initialized embedder #0: FrozenT5Embedder with 4762310656 params. Trainable: False
Working with z of shape (1, 16, 32, 32) = 16384 dimensions.
Deleting key loss.logvar from state_dict.
Deleting key loss.perceptual_loss.scaling_layer.shift from state_dict.
Deleting key loss.perceptual_loss.scaling_layer.scale from state_dict.
Deleting key loss.perceptual_loss.net.slice1.0.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice1.0.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice1.2.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice1.2.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice2.5.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice2.5.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice2.7.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice2.7.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice3.10.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice3.10.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice3.12.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice3.12.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice3.14.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice3.14.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice4.17.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice4.17.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice4.19.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice4.19.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice4.21.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice4.21.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice5.24.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice5.24.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice5.26.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice5.26.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice5.28.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice5.28.bias from state_dict.
Deleting key loss.perceptual_loss.lin0.model.1.weight from state_dict.
Deleting key loss.perceptual_loss.lin1.model.1.weight from state_dict.
Deleting key loss.perceptual_loss.lin2.model.1.weight from state_dict.
Deleting key loss.perceptual_loss.lin3.model.1.weight from state_dict.
Deleting key loss.perceptual_loss.lin4.model.1.weight from state_dict.
Deleting key loss.discriminator.blocks.0.downsample_res.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.0.downsample_res.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.0.net.0.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.0.net.0.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.0.net.2.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.0.net.2.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.0.downsample.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.0.downsample.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.1.downsample_res.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.1.downsample_res.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.1.net.0.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.1.net.0.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.1.net.2.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.1.net.2.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.1.downsample.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.1.downsample.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.2.downsample_res.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.2.downsample_res.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.2.net.0.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.2.net.0.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.2.net.2.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.2.net.2.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.2.downsample.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.2.downsample.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.3.downsample_res.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.3.downsample_res.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.3.net.0.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.3.net.0.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.3.net.2.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.3.net.2.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.3.downsample.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.3.downsample.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.4.0.conv_res.weight from state_dict.
Deleting key loss.discriminator.blocks.4.0.conv_res.bias from state_dict.
Deleting key loss.discriminator.blocks.4.0.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.0.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.4.0.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.4.0.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.4.0.downsample.1.weight from state_dict.
Deleting key loss.discriminator.blocks.4.0.downsample.1.bias from state_dict.
Deleting key loss.discriminator.blocks.4.1.0.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.4.1.0.fn.attn.to_q.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.0.fn.attn.to_kv.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.0.fn.attn.to_out.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.5.0.conv_res.weight from state_dict.
Deleting key loss.discriminator.blocks.5.0.conv_res.bias from state_dict.
Deleting key loss.discriminator.blocks.5.0.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.0.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.5.0.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.5.0.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.5.0.downsample.1.weight from state_dict.
Deleting key loss.discriminator.blocks.5.0.downsample.1.bias from state_dict.
Deleting key loss.discriminator.blocks.5.1.0.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.5.1.0.fn.attn.to_q.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.0.fn.attn.to_kv.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.0.fn.attn.to_out.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.6.0.conv_res.weight from state_dict.
Deleting key loss.discriminator.blocks.6.0.conv_res.bias from state_dict.
Deleting key loss.discriminator.blocks.6.0.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.0.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.6.0.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.6.0.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.6.1.0.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.6.1.0.fn.attn.to_q.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.0.fn.attn.to_kv.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.0.fn.attn.to_out.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.net.2.bias from state_dict.
Deleting key loss.discriminator.to_logits.0.weight from state_dict.
Deleting key loss.discriminator.to_logits.0.bias from state_dict.
Deleting key loss.discriminator.to_logits.3.weight from state_dict.
Deleting key loss.discriminator.to_logits.3.bias from state_dict.
Working with z of shape (1, 16, 32, 32) = 16384 dimensions.
Missing keys:  []
Unexpected keys:  []
Restored from ./pretrained_models/cogvideox-5b-i2v-sat/vae/3d-vae.pt
Deleting key loss.logvar from state_dict.
Deleting key loss.perceptual_loss.scaling_layer.shift from state_dict.
Deleting key loss.perceptual_loss.scaling_layer.scale from state_dict.
Deleting key loss.perceptual_loss.net.slice1.0.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice1.0.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice1.2.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice1.2.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice2.5.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice2.5.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice2.7.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice2.7.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice3.10.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice3.10.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice3.12.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice3.12.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice3.14.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice3.14.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice4.17.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice4.17.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice4.19.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice4.19.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice4.21.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice4.21.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice5.24.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice5.24.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice5.26.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice5.26.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice5.28.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice5.28.bias from state_dict.
Deleting key loss.perceptual_loss.lin0.model.1.weight from state_dict.
Deleting key loss.perceptual_loss.lin1.model.1.weight from state_dict.
Deleting key loss.perceptual_loss.lin2.model.1.weight from state_dict.
Deleting key loss.perceptual_loss.lin3.model.1.weight from state_dict.
Deleting key loss.perceptual_loss.lin4.model.1.weight from state_dict.
Deleting key loss.discriminator.blocks.0.downsample_res.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.0.downsample_res.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.0.net.0.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.0.net.0.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.0.net.2.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.0.net.2.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.0.downsample.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.0.downsample.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.1.downsample_res.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.1.downsample_res.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.1.net.0.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.1.net.0.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.1.net.2.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.1.net.2.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.1.downsample.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.1.downsample.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.2.downsample_res.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.2.downsample_res.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.2.net.0.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.2.net.0.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.2.net.2.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.2.net.2.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.2.downsample.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.2.downsample.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.3.downsample_res.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.3.downsample_res.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.3.net.0.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.3.net.0.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.3.net.2.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.3.net.2.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.3.downsample.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.3.downsample.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.4.0.conv_res.weight from state_dict.
Deleting key loss.discriminator.blocks.4.0.conv_res.bias from state_dict.
Deleting key loss.discriminator.blocks.4.0.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.0.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.4.0.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.4.0.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.4.0.downsample.1.weight from state_dict.
Deleting key loss.discriminator.blocks.4.0.downsample.1.bias from state_dict.
Deleting key loss.discriminator.blocks.4.1.0.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.4.1.0.fn.attn.to_q.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.0.fn.attn.to_kv.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.0.fn.attn.to_out.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.5.0.conv_res.weight from state_dict.
Deleting key loss.discriminator.blocks.5.0.conv_res.bias from state_dict.
Deleting key loss.discriminator.blocks.5.0.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.0.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.5.0.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.5.0.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.5.0.downsample.1.weight from state_dict.
Deleting key loss.discriminator.blocks.5.0.downsample.1.bias from state_dict.
Deleting key loss.discriminator.blocks.5.1.0.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.5.1.0.fn.attn.to_q.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.0.fn.attn.to_kv.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.0.fn.attn.to_out.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.6.0.conv_res.weight from state_dict.
Deleting key loss.discriminator.blocks.6.0.conv_res.bias from state_dict.
Deleting key loss.discriminator.blocks.6.0.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.0.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.6.0.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.6.0.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.6.1.0.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.6.1.0.fn.attn.to_q.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.0.fn.attn.to_kv.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.0.fn.attn.to_out.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.net.2.bias from state_dict.
Deleting key loss.discriminator.to_logits.0.weight from state_dict.
Deleting key loss.discriminator.to_logits.0.bias from state_dict.
Deleting key loss.discriminator.to_logits.3.weight from state_dict.
Deleting key loss.discriminator.to_logits.3.bias from state_dict.
Missing keys:  []
Unexpected keys:  []
Restored from ./pretrained_models/cogvideox-5b-i2v-sat/vae/3d-vae.pt
Deleting key loss.logvar from state_dict.
Deleting key loss.perceptual_loss.scaling_layer.shift from state_dict.
Deleting key loss.perceptual_loss.scaling_layer.scale from state_dict.
Deleting key loss.perceptual_loss.net.slice1.0.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice1.0.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice1.2.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice1.2.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice2.5.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice2.5.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice2.7.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice2.7.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice3.10.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice3.10.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice3.12.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice3.12.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice3.14.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice3.14.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice4.17.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice4.17.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice4.19.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice4.19.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice4.21.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice4.21.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice5.24.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice5.24.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice5.26.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice5.26.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice5.28.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice5.28.bias from state_dict.
Deleting key loss.perceptual_loss.lin0.model.1.weight from state_dict.
Deleting key loss.perceptual_loss.lin1.model.1.weight from state_dict.
Deleting key loss.perceptual_loss.lin2.model.1.weight from state_dict.
Deleting key loss.perceptual_loss.lin3.model.1.weight from state_dict.
Deleting key loss.perceptual_loss.lin4.model.1.weight from state_dict.
Deleting key loss.discriminator.blocks.0.downsample_res.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.0.downsample_res.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.0.net.0.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.0.net.0.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.0.net.2.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.0.net.2.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.0.downsample.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.0.downsample.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.1.downsample_res.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.1.downsample_res.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.1.net.0.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.1.net.0.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.1.net.2.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.1.net.2.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.1.downsample.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.1.downsample.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.2.downsample_res.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.2.downsample_res.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.2.net.0.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.2.net.0.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.2.net.2.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.2.net.2.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.2.downsample.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.2.downsample.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.3.downsample_res.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.3.downsample_res.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.3.net.0.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.3.net.0.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.3.net.2.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.3.net.2.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.3.downsample.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.3.downsample.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.4.0.conv_res.weight from state_dict.
Deleting key loss.discriminator.blocks.4.0.conv_res.bias from state_dict.
Deleting key loss.discriminator.blocks.4.0.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.0.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.4.0.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.4.0.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.4.0.downsample.1.weight from state_dict.
Deleting key loss.discriminator.blocks.4.0.downsample.1.bias from state_dict.
Deleting key loss.discriminator.blocks.4.1.0.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.4.1.0.fn.attn.to_q.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.0.fn.attn.to_kv.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.0.fn.attn.to_out.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.net.2.weight from state_dict.
Deleting key loss.logvar from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.net.2.bias from state_dict.
Deleting key loss.perceptual_loss.scaling_layer.shift from state_dict.
Deleting key loss.perceptual_loss.scaling_layer.scale from state_dict.
Deleting key loss.perceptual_loss.net.slice1.0.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice1.0.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice1.2.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice1.2.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice2.5.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice2.5.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice2.7.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice2.7.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice3.10.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice3.10.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice3.12.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice3.12.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice3.14.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice3.14.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice4.17.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice4.17.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice4.19.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice4.19.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice4.21.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice4.21.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice5.24.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice5.24.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice5.26.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice5.26.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice5.28.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice5.28.bias from state_dict.
Deleting key loss.perceptual_loss.lin0.model.1.weight from state_dict.
Deleting key loss.perceptual_loss.lin1.model.1.weight from state_dict.
Deleting key loss.perceptual_loss.lin2.model.1.weight from state_dict.
Deleting key loss.perceptual_loss.lin3.model.1.weight from state_dict.
Deleting key loss.perceptual_loss.lin4.model.1.weight from state_dict.
Deleting key loss.discriminator.blocks.0.downsample_res.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.0.downsample_res.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.0.net.0.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.0.net.0.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.0.net.2.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.0.net.2.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.0.downsample.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.0.downsample.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.1.downsample_res.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.5.0.conv_res.weight from state_dict.Deleting key loss.discriminator.blocks.1.downsample_res.conv.bias from state_dict.

Deleting key loss.discriminator.blocks.1.net.0.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.1.net.0.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.1.net.2.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.1.net.2.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.1.downsample.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.1.downsample.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.2.downsample_res.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.2.downsample_res.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.2.net.0.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.2.net.0.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.2.net.2.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.2.net.2.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.2.downsample.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.2.downsample.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.3.downsample_res.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.3.downsample_res.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.3.net.0.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.3.net.0.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.3.net.2.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.3.net.2.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.3.downsample.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.3.downsample.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.4.0.conv_res.weight from state_dict.
Deleting key loss.discriminator.blocks.4.0.conv_res.bias from state_dict.
Deleting key loss.discriminator.blocks.4.0.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.0.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.4.0.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.4.0.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.4.0.downsample.1.weight from state_dict.
Deleting key loss.discriminator.blocks.4.0.downsample.1.bias from state_dict.
Deleting key loss.discriminator.blocks.4.1.0.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.4.1.0.fn.attn.to_q.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.0.fn.attn.to_kv.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.0.fn.attn.to_out.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.5.0.conv_res.weight from state_dict.
Deleting key loss.discriminator.blocks.5.0.conv_res.bias from state_dict.
Deleting key loss.discriminator.blocks.5.0.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.0.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.5.0.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.5.0.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.5.0.downsample.1.weight from state_dict.
Deleting key loss.discriminator.blocks.5.0.downsample.1.bias from state_dict.
Deleting key loss.discriminator.blocks.5.1.0.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.5.1.0.fn.attn.to_q.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.0.fn.attn.to_kv.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.0.fn.attn.to_out.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.5.0.conv_res.bias from state_dict.
Deleting key loss.discriminator.blocks.5.0.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.0.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.5.0.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.5.0.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.5.0.downsample.1.weight from state_dict.
Deleting key loss.discriminator.blocks.5.0.downsample.1.bias from state_dict.
Deleting key loss.discriminator.blocks.5.1.0.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.5.1.0.fn.attn.to_q.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.0.fn.attn.to_kv.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.0.fn.attn.to_out.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.6.0.conv_res.weight from state_dict.
Deleting key loss.discriminator.blocks.6.0.conv_res.bias from state_dict.
Deleting key loss.discriminator.blocks.6.0.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.0.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.6.0.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.6.0.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.6.1.0.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.6.1.0.fn.attn.to_q.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.0.fn.attn.to_kv.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.0.fn.attn.to_out.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.net.2.bias from state_dict.
Deleting key loss.discriminator.to_logits.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.net.2.bias from state_dict.
Deleting key loss.discriminator.to_logits.0.bias from state_dict.
Deleting key loss.discriminator.blocks.6.0.conv_res.weight from state_dict.
Deleting key loss.discriminator.blocks.6.0.conv_res.bias from state_dict.
Deleting key loss.discriminator.blocks.6.0.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.0.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.6.0.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.6.0.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.6.1.0.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.6.1.0.fn.attn.to_q.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.0.fn.attn.to_kv.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.0.fn.attn.to_out.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.net.2.bias from state_dict.
Deleting key loss.discriminator.to_logits.0.weight from state_dict.
Deleting key loss.discriminator.to_logits.0.bias from state_dict.
Deleting key loss.discriminator.to_logits.3.weight from state_dict.
Deleting key loss.discriminator.to_logits.3.bias from state_dict.
Deleting key loss.discriminator.to_logits.3.weight from state_dict.
Deleting key loss.discriminator.to_logits.3.bias from state_dict.
Missing keys:  []
Unexpected keys:  []
Restored from ./pretrained_models/cogvideox-5b-i2v-sat/vae/3d-vae.pt
Missing keys:  []
Unexpected keys:  []
Restored from ./pretrained_models/cogvideox-5b-i2v-sat/vae/3d-vae.pt
Deleting key loss.logvar from state_dict.
Deleting key loss.perceptual_loss.scaling_layer.shift from state_dict.
Deleting key loss.perceptual_loss.scaling_layer.scale from state_dict.
Deleting key loss.perceptual_loss.net.slice1.0.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice1.0.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice1.2.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice1.2.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice2.5.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice2.5.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice2.7.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice2.7.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice3.10.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice3.10.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice3.12.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice3.12.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice3.14.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice3.14.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice4.17.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice4.17.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice4.19.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice4.19.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice4.21.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice4.21.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice5.24.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice5.24.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice5.26.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice5.26.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice5.28.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice5.28.bias from state_dict.
Deleting key loss.perceptual_loss.lin0.model.1.weight from state_dict.
Deleting key loss.perceptual_loss.lin1.model.1.weight from state_dict.
Deleting key loss.perceptual_loss.lin2.model.1.weight from state_dict.
Deleting key loss.perceptual_loss.lin3.model.1.weight from state_dict.
Deleting key loss.perceptual_loss.lin4.model.1.weight from state_dict.
Deleting key loss.discriminator.blocks.0.downsample_res.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.0.downsample_res.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.0.net.0.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.0.net.0.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.0.net.2.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.0.net.2.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.0.downsample.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.0.downsample.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.1.downsample_res.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.1.downsample_res.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.1.net.0.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.1.net.0.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.1.net.2.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.1.net.2.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.1.downsample.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.1.downsample.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.2.downsample_res.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.2.downsample_res.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.2.net.0.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.2.net.0.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.2.net.2.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.2.net.2.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.2.downsample.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.2.downsample.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.3.downsample_res.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.3.downsample_res.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.3.net.0.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.3.net.0.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.3.net.2.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.3.net.2.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.3.downsample.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.3.downsample.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.4.0.conv_res.weight from state_dict.
Deleting key loss.discriminator.blocks.4.0.conv_res.bias from state_dict.
Deleting key loss.discriminator.blocks.4.0.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.0.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.4.0.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.4.0.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.4.0.downsample.1.weight from state_dict.
Deleting key loss.discriminator.blocks.4.0.downsample.1.bias from state_dict.
Deleting key loss.discriminator.blocks.4.1.0.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.4.1.0.fn.attn.to_q.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.0.fn.attn.to_kv.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.0.fn.attn.to_out.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.5.0.conv_res.weight from state_dict.
Deleting key loss.discriminator.blocks.5.0.conv_res.bias from state_dict.
Deleting key loss.discriminator.blocks.5.0.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.0.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.5.0.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.5.0.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.5.0.downsample.1.weight from state_dict.
Deleting key loss.discriminator.blocks.5.0.downsample.1.bias from state_dict.
Deleting key loss.discriminator.blocks.5.1.0.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.5.1.0.fn.attn.to_q.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.0.fn.attn.to_kv.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.0.fn.attn.to_out.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.6.0.conv_res.weight from state_dict.
Deleting key loss.discriminator.blocks.6.0.conv_res.bias from state_dict.
Deleting key loss.discriminator.blocks.6.0.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.0.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.6.0.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.6.0.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.6.1.0.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.6.1.0.fn.attn.to_q.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.0.fn.attn.to_kv.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.0.fn.attn.to_out.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.net.2.bias from state_dict.
Deleting key loss.discriminator.to_logits.0.weight from state_dict.
Deleting key loss.discriminator.to_logits.0.bias from state_dict.
Deleting key loss.discriminator.to_logits.3.weight from state_dict.
Deleting key loss.discriminator.to_logits.3.bias from state_dict.
Missing keys:  []
Unexpected keys:  []
Restored from ./pretrained_models/cogvideox-5b-i2v-sat/vae/3d-vae.pt
[2025-03-17 02:33:08,889] [INFO] [RANK 0]  > number of parameters on model parallel rank 0: 19524432675
[2025-03-17 02:35:08,484] [INFO] [RANK 0] global rank 0 is loading checkpoint pretrained_models/hallo3/1/mp_rank_00_model_states.pt
[2025-03-17 02:36:28,441] [INFO] [RANK 0] > successfully loaded pretrained_models/hallo3/1/mp_rank_00_model_states.pt
[2025-03-17 02:36:50,400] [INFO] [RANK 0] model.diffusion_model.transformer.layers.0.audio_input_layernorm.weight
[2025-03-17 02:36:50,401] [INFO] [RANK 0] model.diffusion_model.transformer.layers.0.audio_input_layernorm.bias
[2025-03-17 02:36:50,402] [INFO] [RANK 0] model.diffusion_model.transformer.layers.0.audio_attn.query.weight
[2025-03-17 02:36:50,402] [INFO] [RANK 0] model.diffusion_model.transformer.layers.0.audio_attn.query.bias
[2025-03-17 02:36:50,402] [INFO] [RANK 0] model.diffusion_model.transformer.layers.0.audio_attn.key_value.weight
[2025-03-17 02:36:50,402] [INFO] [RANK 0] model.diffusion_model.transformer.layers.0.audio_attn.key_value.bias
[2025-03-17 02:36:50,402] [INFO] [RANK 0] model.diffusion_model.transformer.layers.0.audio_attn.dense.weight
[2025-03-17 02:36:50,402] [INFO] [RANK 0] model.diffusion_model.transformer.layers.0.audio_attn.dense.bias
[2025-03-17 02:36:50,404] [INFO] [RANK 0] model.diffusion_model.transformer.layers.1.audio_input_layernorm.weight
[2025-03-17 02:36:50,404] [INFO] [RANK 0] model.diffusion_model.transformer.layers.1.audio_input_layernorm.bias
[2025-03-17 02:36:50,404] [INFO] [RANK 0] model.diffusion_model.transformer.layers.1.audio_attn.query.weight
[2025-03-17 02:36:50,404] [INFO] [RANK 0] model.diffusion_model.transformer.layers.1.audio_attn.query.bias
[2025-03-17 02:36:50,404] [INFO] [RANK 0] model.diffusion_model.transformer.layers.1.audio_attn.key_value.weight
[2025-03-17 02:36:50,405] [INFO] [RANK 0] model.diffusion_model.transformer.layers.1.audio_attn.key_value.bias
[2025-03-17 02:36:50,405] [INFO] [RANK 0] model.diffusion_model.transformer.layers.1.audio_attn.dense.weight
[2025-03-17 02:36:50,405] [INFO] [RANK 0] model.diffusion_model.transformer.layers.1.audio_attn.dense.bias
[2025-03-17 02:36:50,406] [INFO] [RANK 0] model.diffusion_model.transformer.layers.2.audio_input_layernorm.weight
[2025-03-17 02:36:50,407] [INFO] [RANK 0] model.diffusion_model.transformer.layers.2.audio_input_layernorm.bias
[2025-03-17 02:36:50,407] [INFO] [RANK 0] model.diffusion_model.transformer.layers.2.audio_attn.query.weight
[2025-03-17 02:36:50,407] [INFO] [RANK 0] model.diffusion_model.transformer.layers.2.audio_attn.query.bias
[2025-03-17 02:36:50,407] [INFO] [RANK 0] model.diffusion_model.transformer.layers.2.audio_attn.key_value.weight
[2025-03-17 02:36:50,408] [INFO] [RANK 0] model.diffusion_model.transformer.layers.2.audio_attn.key_value.bias
[2025-03-17 02:36:50,408] [INFO] [RANK 0] model.diffusion_model.transformer.layers.2.audio_attn.dense.weight
[2025-03-17 02:36:50,408] [INFO] [RANK 0] model.diffusion_model.transformer.layers.2.audio_attn.dense.bias
[2025-03-17 02:36:50,425] [INFO] [RANK 0] model.diffusion_model.transformer.layers.3.audio_input_layernorm.weight
[2025-03-17 02:36:50,425] [INFO] [RANK 0] model.diffusion_model.transformer.layers.3.audio_input_layernorm.bias
[2025-03-17 02:36:50,426] [INFO] [RANK 0] model.diffusion_model.transformer.layers.3.audio_attn.query.weight
[2025-03-17 02:36:50,426] [INFO] [RANK 0] model.diffusion_model.transformer.layers.3.audio_attn.query.bias
[2025-03-17 02:36:50,426] [INFO] [RANK 0] model.diffusion_model.transformer.layers.3.audio_attn.key_value.weight
[2025-03-17 02:36:50,426] [INFO] [RANK 0] model.diffusion_model.transformer.layers.3.audio_attn.key_value.bias
[2025-03-17 02:36:50,426] [INFO] [RANK 0] model.diffusion_model.transformer.layers.3.audio_attn.dense.weight
[2025-03-17 02:36:50,426] [INFO] [RANK 0] model.diffusion_model.transformer.layers.3.audio_attn.dense.bias
[2025-03-17 02:36:50,428] [INFO] [RANK 0] model.diffusion_model.transformer.layers.4.audio_input_layernorm.weight
[2025-03-17 02:36:50,428] [INFO] [RANK 0] model.diffusion_model.transformer.layers.4.audio_input_layernorm.bias
[2025-03-17 02:36:50,428] [INFO] [RANK 0] model.diffusion_model.transformer.layers.4.audio_attn.query.weight
[2025-03-17 02:36:50,428] [INFO] [RANK 0] model.diffusion_model.transformer.layers.4.audio_attn.query.bias
[2025-03-17 02:36:50,429] [INFO] [RANK 0] model.diffusion_model.transformer.layers.4.audio_attn.key_value.weight
[2025-03-17 02:36:50,429] [INFO] [RANK 0] model.diffusion_model.transformer.layers.4.audio_attn.key_value.bias
[2025-03-17 02:36:50,429] [INFO] [RANK 0] model.diffusion_model.transformer.layers.4.audio_attn.dense.weight
[2025-03-17 02:36:50,429] [INFO] [RANK 0] model.diffusion_model.transformer.layers.4.audio_attn.dense.bias
[2025-03-17 02:36:50,430] [INFO] [RANK 0] model.diffusion_model.transformer.layers.5.audio_input_layernorm.weight
[2025-03-17 02:36:50,431] [INFO] [RANK 0] model.diffusion_model.transformer.layers.5.audio_input_layernorm.bias
[2025-03-17 02:36:50,431] [INFO] [RANK 0] model.diffusion_model.transformer.layers.5.audio_attn.query.weight
[2025-03-17 02:36:50,431] [INFO] [RANK 0] model.diffusion_model.transformer.layers.5.audio_attn.query.bias
[2025-03-17 02:36:50,431] [INFO] [RANK 0] model.diffusion_model.transformer.layers.5.audio_attn.key_value.weight
[2025-03-17 02:36:50,431] [INFO] [RANK 0] model.diffusion_model.transformer.layers.5.audio_attn.key_value.bias
[2025-03-17 02:36:50,431] [INFO] [RANK 0] model.diffusion_model.transformer.layers.5.audio_attn.dense.weight
[2025-03-17 02:36:50,431] [INFO] [RANK 0] model.diffusion_model.transformer.layers.5.audio_attn.dense.bias
[2025-03-17 02:36:50,433] [INFO] [RANK 0] model.diffusion_model.transformer.layers.6.audio_input_layernorm.weight
[2025-03-17 02:36:50,433] [INFO] [RANK 0] model.diffusion_model.transformer.layers.6.audio_input_layernorm.bias
[2025-03-17 02:36:50,433] [INFO] [RANK 0] model.diffusion_model.transformer.layers.6.audio_attn.query.weight
[2025-03-17 02:36:50,433] [INFO] [RANK 0] model.diffusion_model.transformer.layers.6.audio_attn.query.bias
[2025-03-17 02:36:50,433] [INFO] [RANK 0] model.diffusion_model.transformer.layers.6.audio_attn.key_value.weight
[2025-03-17 02:36:50,433] [INFO] [RANK 0] model.diffusion_model.transformer.layers.6.audio_attn.key_value.bias
[2025-03-17 02:36:50,434] [INFO] [RANK 0] model.diffusion_model.transformer.layers.6.audio_attn.dense.weight
[2025-03-17 02:36:50,434] [INFO] [RANK 0] model.diffusion_model.transformer.layers.6.audio_attn.dense.bias
[2025-03-17 02:36:50,435] [INFO] [RANK 0] model.diffusion_model.transformer.layers.7.audio_input_layernorm.weight
[2025-03-17 02:36:50,435] [INFO] [RANK 0] model.diffusion_model.transformer.layers.7.audio_input_layernorm.bias
[2025-03-17 02:36:50,436] [INFO] [RANK 0] model.diffusion_model.transformer.layers.7.audio_attn.query.weight
[2025-03-17 02:36:50,436] [INFO] [RANK 0] model.diffusion_model.transformer.layers.7.audio_attn.query.bias
[2025-03-17 02:36:50,436] [INFO] [RANK 0] model.diffusion_model.transformer.layers.7.audio_attn.key_value.weight
[2025-03-17 02:36:50,437] [INFO] [RANK 0] model.diffusion_model.transformer.layers.7.audio_attn.key_value.bias
[2025-03-17 02:36:50,437] [INFO] [RANK 0] model.diffusion_model.transformer.layers.7.audio_attn.dense.weight
[2025-03-17 02:36:50,437] [INFO] [RANK 0] model.diffusion_model.transformer.layers.7.audio_attn.dense.bias
[2025-03-17 02:36:50,439] [INFO] [RANK 0] model.diffusion_model.transformer.layers.8.audio_input_layernorm.weight
[2025-03-17 02:36:50,440] [INFO] [RANK 0] model.diffusion_model.transformer.layers.8.audio_input_layernorm.bias
[2025-03-17 02:36:50,440] [INFO] [RANK 0] model.diffusion_model.transformer.layers.8.audio_attn.query.weight
[2025-03-17 02:36:50,440] [INFO] [RANK 0] model.diffusion_model.transformer.layers.8.audio_attn.query.bias
[2025-03-17 02:36:50,440] [INFO] [RANK 0] model.diffusion_model.transformer.layers.8.audio_attn.key_value.weight
[2025-03-17 02:36:50,440] [INFO] [RANK 0] model.diffusion_model.transformer.layers.8.audio_attn.key_value.bias
[2025-03-17 02:36:50,441] [INFO] [RANK 0] model.diffusion_model.transformer.layers.8.audio_attn.dense.weight
[2025-03-17 02:36:50,441] [INFO] [RANK 0] model.diffusion_model.transformer.layers.8.audio_attn.dense.bias
[2025-03-17 02:36:50,442] [INFO] [RANK 0] model.diffusion_model.transformer.layers.9.audio_input_layernorm.weight
[2025-03-17 02:36:50,443] [INFO] [RANK 0] model.diffusion_model.transformer.layers.9.audio_input_layernorm.bias
[2025-03-17 02:36:50,443] [INFO] [RANK 0] model.diffusion_model.transformer.layers.9.audio_attn.query.weight
[2025-03-17 02:36:50,443] [INFO] [RANK 0] model.diffusion_model.transformer.layers.9.audio_attn.query.bias
[2025-03-17 02:36:50,443] [INFO] [RANK 0] model.diffusion_model.transformer.layers.9.audio_attn.key_value.weight
[2025-03-17 02:36:50,443] [INFO] [RANK 0] model.diffusion_model.transformer.layers.9.audio_attn.key_value.bias
[2025-03-17 02:36:50,444] [INFO] [RANK 0] model.diffusion_model.transformer.layers.9.audio_attn.dense.weight
[2025-03-17 02:36:50,444] [INFO] [RANK 0] model.diffusion_model.transformer.layers.9.audio_attn.dense.bias
[2025-03-17 02:36:50,445] [INFO] [RANK 0] model.diffusion_model.transformer.layers.10.audio_input_layernorm.weight
[2025-03-17 02:36:50,446] [INFO] [RANK 0] model.diffusion_model.transformer.layers.10.audio_input_layernorm.bias
[2025-03-17 02:36:50,446] [INFO] [RANK 0] model.diffusion_model.transformer.layers.10.audio_attn.query.weight
[2025-03-17 02:36:50,446] [INFO] [RANK 0] model.diffusion_model.transformer.layers.10.audio_attn.query.bias
[2025-03-17 02:36:50,446] [INFO] [RANK 0] model.diffusion_model.transformer.layers.10.audio_attn.key_value.weight
[2025-03-17 02:36:50,446] [INFO] [RANK 0] model.diffusion_model.transformer.layers.10.audio_attn.key_value.bias
[2025-03-17 02:36:50,446] [INFO] [RANK 0] model.diffusion_model.transformer.layers.10.audio_attn.dense.weight
[2025-03-17 02:36:50,446] [INFO] [RANK 0] model.diffusion_model.transformer.layers.10.audio_attn.dense.bias
[2025-03-17 02:36:50,448] [INFO] [RANK 0] model.diffusion_model.transformer.layers.11.audio_input_layernorm.weight
[2025-03-17 02:36:50,448] [INFO] [RANK 0] model.diffusion_model.transformer.layers.11.audio_input_layernorm.bias
[2025-03-17 02:36:50,448] [INFO] [RANK 0] model.diffusion_model.transformer.layers.11.audio_attn.query.weight
[2025-03-17 02:36:50,448] [INFO] [RANK 0] model.diffusion_model.transformer.layers.11.audio_attn.query.bias
[2025-03-17 02:36:50,448] [INFO] [RANK 0] model.diffusion_model.transformer.layers.11.audio_attn.key_value.weight
[2025-03-17 02:36:50,448] [INFO] [RANK 0] model.diffusion_model.transformer.layers.11.audio_attn.key_value.bias
[2025-03-17 02:36:50,448] [INFO] [RANK 0] model.diffusion_model.transformer.layers.11.audio_attn.dense.weight
[2025-03-17 02:36:50,448] [INFO] [RANK 0] model.diffusion_model.transformer.layers.11.audio_attn.dense.bias
[2025-03-17 02:36:50,485] [INFO] [RANK 0] model.diffusion_model.transformer.layers.12.audio_input_layernorm.weight
[2025-03-17 02:36:50,486] [INFO] [RANK 0] model.diffusion_model.transformer.layers.12.audio_input_layernorm.bias
[2025-03-17 02:36:50,487] [INFO] [RANK 0] model.diffusion_model.transformer.layers.12.audio_attn.query.weight
[2025-03-17 02:36:50,487] [INFO] [RANK 0] model.diffusion_model.transformer.layers.12.audio_attn.query.bias
[2025-03-17 02:36:50,490] [INFO] [RANK 0] model.diffusion_model.transformer.layers.12.audio_attn.key_value.weight
[2025-03-17 02:36:50,490] [INFO] [RANK 0] model.diffusion_model.transformer.layers.12.audio_attn.key_value.bias
[2025-03-17 02:36:50,490] [INFO] [RANK 0] model.diffusion_model.transformer.layers.12.audio_attn.dense.weight
[2025-03-17 02:36:50,490] [INFO] [RANK 0] model.diffusion_model.transformer.layers.12.audio_attn.dense.bias
[2025-03-17 02:36:50,492] [INFO] [RANK 0] model.diffusion_model.transformer.layers.13.audio_input_layernorm.weight
[2025-03-17 02:36:50,492] [INFO] [RANK 0] model.diffusion_model.transformer.layers.13.audio_input_layernorm.bias
[2025-03-17 02:36:50,492] [INFO] [RANK 0] model.diffusion_model.transformer.layers.13.audio_attn.query.weight
[2025-03-17 02:36:50,492] [INFO] [RANK 0] model.diffusion_model.transformer.layers.13.audio_attn.query.bias
[2025-03-17 02:36:50,492] [INFO] [RANK 0] model.diffusion_model.transformer.layers.13.audio_attn.key_value.weight
[2025-03-17 02:36:50,492] [INFO] [RANK 0] model.diffusion_model.transformer.layers.13.audio_attn.key_value.bias
[2025-03-17 02:36:50,493] [INFO] [RANK 0] model.diffusion_model.transformer.layers.13.audio_attn.dense.weight
[2025-03-17 02:36:50,493] [INFO] [RANK 0] model.diffusion_model.transformer.layers.13.audio_attn.dense.bias
[2025-03-17 02:36:50,494] [INFO] [RANK 0] model.diffusion_model.transformer.layers.14.audio_input_layernorm.weight
[2025-03-17 02:36:50,494] [INFO] [RANK 0] model.diffusion_model.transformer.layers.14.audio_input_layernorm.bias
[2025-03-17 02:36:50,495] [INFO] [RANK 0] model.diffusion_model.transformer.layers.14.audio_attn.query.weight
[2025-03-17 02:36:50,495] [INFO] [RANK 0] model.diffusion_model.transformer.layers.14.audio_attn.query.bias
[2025-03-17 02:36:50,495] [INFO] [RANK 0] model.diffusion_model.transformer.layers.14.audio_attn.key_value.weight
[2025-03-17 02:36:50,495] [INFO] [RANK 0] model.diffusion_model.transformer.layers.14.audio_attn.key_value.bias
[2025-03-17 02:36:50,495] [INFO] [RANK 0] model.diffusion_model.transformer.layers.14.audio_attn.dense.weight
[2025-03-17 02:36:50,495] [INFO] [RANK 0] model.diffusion_model.transformer.layers.14.audio_attn.dense.bias
[2025-03-17 02:36:50,497] [INFO] [RANK 0] model.diffusion_model.transformer.layers.15.audio_input_layernorm.weight
[2025-03-17 02:36:50,499] [INFO] [RANK 0] model.diffusion_model.transformer.layers.15.audio_input_layernorm.bias
[2025-03-17 02:36:50,499] [INFO] [RANK 0] model.diffusion_model.transformer.layers.15.audio_attn.query.weight
[2025-03-17 02:36:50,499] [INFO] [RANK 0] model.diffusion_model.transformer.layers.15.audio_attn.query.bias
[2025-03-17 02:36:50,501] [INFO] [RANK 0] model.diffusion_model.transformer.layers.15.audio_attn.key_value.weight
[2025-03-17 02:36:50,502] [INFO] [RANK 0] model.diffusion_model.transformer.layers.15.audio_attn.key_value.bias
[2025-03-17 02:36:50,502] [INFO] [RANK 0] model.diffusion_model.transformer.layers.15.audio_attn.dense.weight
[2025-03-17 02:36:50,502] [INFO] [RANK 0] model.diffusion_model.transformer.layers.15.audio_attn.dense.bias
[2025-03-17 02:36:50,504] [INFO] [RANK 0] model.diffusion_model.transformer.layers.16.audio_input_layernorm.weight
[2025-03-17 02:36:50,505] [INFO] [RANK 0] model.diffusion_model.transformer.layers.16.audio_input_layernorm.bias
[2025-03-17 02:36:50,505] [INFO] [RANK 0] model.diffusion_model.transformer.layers.16.audio_attn.query.weight
[2025-03-17 02:36:50,505] [INFO] [RANK 0] model.diffusion_model.transformer.layers.16.audio_attn.query.bias
[2025-03-17 02:36:50,506] [INFO] [RANK 0] model.diffusion_model.transformer.layers.16.audio_attn.key_value.weight
[2025-03-17 02:36:50,506] [INFO] [RANK 0] model.diffusion_model.transformer.layers.16.audio_attn.key_value.bias
[2025-03-17 02:36:50,506] [INFO] [RANK 0] model.diffusion_model.transformer.layers.16.audio_attn.dense.weight
[2025-03-17 02:36:50,509] [INFO] [RANK 0] model.diffusion_model.transformer.layers.16.audio_attn.dense.bias
[2025-03-17 02:36:50,513] [INFO] [RANK 0] model.diffusion_model.transformer.layers.17.audio_input_layernorm.weight
[2025-03-17 02:36:50,514] [INFO] [RANK 0] model.diffusion_model.transformer.layers.17.audio_input_layernorm.bias
[2025-03-17 02:36:50,514] [INFO] [RANK 0] model.diffusion_model.transformer.layers.17.audio_attn.query.weight
[2025-03-17 02:36:50,514] [INFO] [RANK 0] model.diffusion_model.transformer.layers.17.audio_attn.query.bias
[2025-03-17 02:36:50,514] [INFO] [RANK 0] model.diffusion_model.transformer.layers.17.audio_attn.key_value.weight
[2025-03-17 02:36:50,515] [INFO] [RANK 0] model.diffusion_model.transformer.layers.17.audio_attn.key_value.bias
[2025-03-17 02:36:50,515] [INFO] [RANK 0] model.diffusion_model.transformer.layers.17.audio_attn.dense.weight
[2025-03-17 02:36:50,515] [INFO] [RANK 0] model.diffusion_model.transformer.layers.17.audio_attn.dense.bias
[2025-03-17 02:36:50,517] [INFO] [RANK 0] model.diffusion_model.transformer.layers.18.audio_input_layernorm.weight
[2025-03-17 02:36:50,517] [INFO] [RANK 0] model.diffusion_model.transformer.layers.18.audio_input_layernorm.bias
[2025-03-17 02:36:50,517] [INFO] [RANK 0] model.diffusion_model.transformer.layers.18.audio_attn.query.weight
[2025-03-17 02:36:50,518] [INFO] [RANK 0] model.diffusion_model.transformer.layers.18.audio_attn.query.bias
[2025-03-17 02:36:50,518] [INFO] [RANK 0] model.diffusion_model.transformer.layers.18.audio_attn.key_value.weight
[2025-03-17 02:36:50,518] [INFO] [RANK 0] model.diffusion_model.transformer.layers.18.audio_attn.key_value.bias
[2025-03-17 02:36:50,518] [INFO] [RANK 0] model.diffusion_model.transformer.layers.18.audio_attn.dense.weight
[2025-03-17 02:36:50,518] [INFO] [RANK 0] model.diffusion_model.transformer.layers.18.audio_attn.dense.bias
[2025-03-17 02:36:50,520] [INFO] [RANK 0] model.diffusion_model.transformer.layers.19.audio_input_layernorm.weight
[2025-03-17 02:36:50,520] [INFO] [RANK 0] model.diffusion_model.transformer.layers.19.audio_input_layernorm.bias
[2025-03-17 02:36:50,520] [INFO] [RANK 0] model.diffusion_model.transformer.layers.19.audio_attn.query.weight
[2025-03-17 02:36:50,520] [INFO] [RANK 0] model.diffusion_model.transformer.layers.19.audio_attn.query.bias
[2025-03-17 02:36:50,521] [INFO] [RANK 0] model.diffusion_model.transformer.layers.19.audio_attn.key_value.weight
[2025-03-17 02:36:50,521] [INFO] [RANK 0] model.diffusion_model.transformer.layers.19.audio_attn.key_value.bias
[2025-03-17 02:36:50,521] [INFO] [RANK 0] model.diffusion_model.transformer.layers.19.audio_attn.dense.weight
[2025-03-17 02:36:50,521] [INFO] [RANK 0] model.diffusion_model.transformer.layers.19.audio_attn.dense.bias
[2025-03-17 02:36:50,523] [INFO] [RANK 0] model.diffusion_model.transformer.layers.20.audio_input_layernorm.weight
[2025-03-17 02:36:50,523] [INFO] [RANK 0] model.diffusion_model.transformer.layers.20.audio_input_layernorm.bias
[2025-03-17 02:36:50,523] [INFO] [RANK 0] model.diffusion_model.transformer.layers.20.audio_attn.query.weight
[2025-03-17 02:36:50,523] [INFO] [RANK 0] model.diffusion_model.transformer.layers.20.audio_attn.query.bias
[2025-03-17 02:36:50,534] [INFO] [RANK 0] model.diffusion_model.transformer.layers.20.audio_attn.key_value.weight
[2025-03-17 02:36:50,535] [INFO] [RANK 0] model.diffusion_model.transformer.layers.20.audio_attn.key_value.bias
[2025-03-17 02:36:50,535] [INFO] [RANK 0] model.diffusion_model.transformer.layers.20.audio_attn.dense.weight
[2025-03-17 02:36:50,535] [INFO] [RANK 0] model.diffusion_model.transformer.layers.20.audio_attn.dense.bias
[2025-03-17 02:36:50,536] [INFO] [RANK 0] model.diffusion_model.transformer.layers.21.audio_input_layernorm.weight
[2025-03-17 02:36:50,536] [INFO] [RANK 0] model.diffusion_model.transformer.layers.21.audio_input_layernorm.bias
[2025-03-17 02:36:50,585] [INFO] [RANK 0] model.diffusion_model.transformer.layers.21.audio_attn.query.weight
[2025-03-17 02:36:50,585] [INFO] [RANK 0] model.diffusion_model.transformer.layers.21.audio_attn.query.bias
[2025-03-17 02:36:50,586] [INFO] [RANK 0] model.diffusion_model.transformer.layers.21.audio_attn.key_value.weight
[2025-03-17 02:36:50,586] [INFO] [RANK 0] model.diffusion_model.transformer.layers.21.audio_attn.key_value.bias
[2025-03-17 02:36:50,586] [INFO] [RANK 0] model.diffusion_model.transformer.layers.21.audio_attn.dense.weight
[2025-03-17 02:36:50,586] [INFO] [RANK 0] model.diffusion_model.transformer.layers.21.audio_attn.dense.bias
[2025-03-17 02:36:50,587] [INFO] [RANK 0] model.diffusion_model.transformer.layers.22.audio_input_layernorm.weight
[2025-03-17 02:36:50,587] [INFO] [RANK 0] model.diffusion_model.transformer.layers.22.audio_input_layernorm.bias
[2025-03-17 02:36:50,587] [INFO] [RANK 0] model.diffusion_model.transformer.layers.22.audio_attn.query.weight
[2025-03-17 02:36:50,588] [INFO] [RANK 0] model.diffusion_model.transformer.layers.22.audio_attn.query.bias
[2025-03-17 02:36:50,588] [INFO] [RANK 0] model.diffusion_model.transformer.layers.22.audio_attn.key_value.weight
[2025-03-17 02:36:50,588] [INFO] [RANK 0] model.diffusion_model.transformer.layers.22.audio_attn.key_value.bias
[2025-03-17 02:36:50,588] [INFO] [RANK 0] model.diffusion_model.transformer.layers.22.audio_attn.dense.weight
[2025-03-17 02:36:50,588] [INFO] [RANK 0] model.diffusion_model.transformer.layers.22.audio_attn.dense.bias
[2025-03-17 02:36:50,589] [INFO] [RANK 0] model.diffusion_model.transformer.layers.23.audio_input_layernorm.weight
[2025-03-17 02:36:50,589] [INFO] [RANK 0] model.diffusion_model.transformer.layers.23.audio_input_layernorm.bias
[2025-03-17 02:36:50,590] [INFO] [RANK 0] model.diffusion_model.transformer.layers.23.audio_attn.query.weight
[2025-03-17 02:36:50,590] [INFO] [RANK 0] model.diffusion_model.transformer.layers.23.audio_attn.query.bias
[2025-03-17 02:36:50,590] [INFO] [RANK 0] model.diffusion_model.transformer.layers.23.audio_attn.key_value.weight
[2025-03-17 02:36:50,590] [INFO] [RANK 0] model.diffusion_model.transformer.layers.23.audio_attn.key_value.bias
[2025-03-17 02:36:50,590] [INFO] [RANK 0] model.diffusion_model.transformer.layers.23.audio_attn.dense.weight
[2025-03-17 02:36:50,590] [INFO] [RANK 0] model.diffusion_model.transformer.layers.23.audio_attn.dense.bias
[2025-03-17 02:36:50,591] [INFO] [RANK 0] model.diffusion_model.transformer.layers.24.audio_input_layernorm.weight
[2025-03-17 02:36:50,591] [INFO] [RANK 0] model.diffusion_model.transformer.layers.24.audio_input_layernorm.bias
[2025-03-17 02:36:50,591] [INFO] [RANK 0] model.diffusion_model.transformer.layers.24.audio_attn.query.weight
[2025-03-17 02:36:50,591] [INFO] [RANK 0] model.diffusion_model.transformer.layers.24.audio_attn.query.bias
[2025-03-17 02:36:50,591] [INFO] [RANK 0] model.diffusion_model.transformer.layers.24.audio_attn.key_value.weight
[2025-03-17 02:36:50,591] [INFO] [RANK 0] model.diffusion_model.transformer.layers.24.audio_attn.key_value.bias
[2025-03-17 02:36:50,592] [INFO] [RANK 0] model.diffusion_model.transformer.layers.24.audio_attn.dense.weight
[2025-03-17 02:36:50,592] [INFO] [RANK 0] model.diffusion_model.transformer.layers.24.audio_attn.dense.bias
[2025-03-17 02:36:50,592] [INFO] [RANK 0] model.diffusion_model.transformer.layers.25.audio_input_layernorm.weight
[2025-03-17 02:36:50,592] [INFO] [RANK 0] model.diffusion_model.transformer.layers.25.audio_input_layernorm.bias
[2025-03-17 02:36:50,593] [INFO] [RANK 0] model.diffusion_model.transformer.layers.25.audio_attn.query.weight
[2025-03-17 02:36:50,593] [INFO] [RANK 0] model.diffusion_model.transformer.layers.25.audio_attn.query.bias
[2025-03-17 02:36:50,593] [INFO] [RANK 0] model.diffusion_model.transformer.layers.25.audio_attn.key_value.weight
[2025-03-17 02:36:50,593] [INFO] [RANK 0] model.diffusion_model.transformer.layers.25.audio_attn.key_value.bias
[2025-03-17 02:36:50,593] [INFO] [RANK 0] model.diffusion_model.transformer.layers.25.audio_attn.dense.weight
[2025-03-17 02:36:50,593] [INFO] [RANK 0] model.diffusion_model.transformer.layers.25.audio_attn.dense.bias
[2025-03-17 02:36:50,594] [INFO] [RANK 0] model.diffusion_model.transformer.layers.26.audio_input_layernorm.weight
[2025-03-17 02:36:50,594] [INFO] [RANK 0] model.diffusion_model.transformer.layers.26.audio_input_layernorm.bias
[2025-03-17 02:36:50,594] [INFO] [RANK 0] model.diffusion_model.transformer.layers.26.audio_attn.query.weight
[2025-03-17 02:36:50,594] [INFO] [RANK 0] model.diffusion_model.transformer.layers.26.audio_attn.query.bias
[2025-03-17 02:36:50,594] [INFO] [RANK 0] model.diffusion_model.transformer.layers.26.audio_attn.key_value.weight
[2025-03-17 02:36:50,594] [INFO] [RANK 0] model.diffusion_model.transformer.layers.26.audio_attn.key_value.bias
[2025-03-17 02:36:50,594] [INFO] [RANK 0] model.diffusion_model.transformer.layers.26.audio_attn.dense.weight
[2025-03-17 02:36:50,594] [INFO] [RANK 0] model.diffusion_model.transformer.layers.26.audio_attn.dense.bias
[2025-03-17 02:36:50,595] [INFO] [RANK 0] model.diffusion_model.transformer.layers.27.audio_input_layernorm.weight
[2025-03-17 02:36:50,595] [INFO] [RANK 0] model.diffusion_model.transformer.layers.27.audio_input_layernorm.bias
[2025-03-17 02:36:50,595] [INFO] [RANK 0] model.diffusion_model.transformer.layers.27.audio_attn.query.weight
[2025-03-17 02:36:50,595] [INFO] [RANK 0] model.diffusion_model.transformer.layers.27.audio_attn.query.bias
[2025-03-17 02:36:50,595] [INFO] [RANK 0] model.diffusion_model.transformer.layers.27.audio_attn.key_value.weight
[2025-03-17 02:36:50,595] [INFO] [RANK 0] model.diffusion_model.transformer.layers.27.audio_attn.key_value.bias
[2025-03-17 02:36:50,595] [INFO] [RANK 0] model.diffusion_model.transformer.layers.27.audio_attn.dense.weight
[2025-03-17 02:36:50,595] [INFO] [RANK 0] model.diffusion_model.transformer.layers.27.audio_attn.dense.bias
[2025-03-17 02:36:50,596] [INFO] [RANK 0] model.diffusion_model.transformer.layers.28.audio_input_layernorm.weight
[2025-03-17 02:36:50,596] [INFO] [RANK 0] model.diffusion_model.transformer.layers.28.audio_input_layernorm.bias
[2025-03-17 02:36:50,596] [INFO] [RANK 0] model.diffusion_model.transformer.layers.28.audio_attn.query.weight
[2025-03-17 02:36:50,596] [INFO] [RANK 0] model.diffusion_model.transformer.layers.28.audio_attn.query.bias
[2025-03-17 02:36:50,596] [INFO] [RANK 0] model.diffusion_model.transformer.layers.28.audio_attn.key_value.weight
[2025-03-17 02:36:50,597] [INFO] [RANK 0] model.diffusion_model.transformer.layers.28.audio_attn.key_value.bias
[2025-03-17 02:36:50,597] [INFO] [RANK 0] model.diffusion_model.transformer.layers.28.audio_attn.dense.weight
[2025-03-17 02:36:50,597] [INFO] [RANK 0] model.diffusion_model.transformer.layers.28.audio_attn.dense.bias
[2025-03-17 02:36:50,597] [INFO] [RANK 0] model.diffusion_model.transformer.layers.29.audio_input_layernorm.weight
[2025-03-17 02:36:50,598] [INFO] [RANK 0] model.diffusion_model.transformer.layers.29.audio_input_layernorm.bias
[2025-03-17 02:36:50,598] [INFO] [RANK 0] model.diffusion_model.transformer.layers.29.audio_attn.query.weight
[2025-03-17 02:36:50,598] [INFO] [RANK 0] model.diffusion_model.transformer.layers.29.audio_attn.query.bias
[2025-03-17 02:36:50,598] [INFO] [RANK 0] model.diffusion_model.transformer.layers.29.audio_attn.key_value.weight
[2025-03-17 02:36:50,598] [INFO] [RANK 0] model.diffusion_model.transformer.layers.29.audio_attn.key_value.bias
[2025-03-17 02:36:50,598] [INFO] [RANK 0] model.diffusion_model.transformer.layers.29.audio_attn.dense.weight
[2025-03-17 02:36:50,598] [INFO] [RANK 0] model.diffusion_model.transformer.layers.29.audio_attn.dense.bias
[2025-03-17 02:36:50,599] [INFO] [RANK 0] model.diffusion_model.transformer.layers.30.audio_input_layernorm.weight
[2025-03-17 02:36:50,599] [INFO] [RANK 0] model.diffusion_model.transformer.layers.30.audio_input_layernorm.bias
[2025-03-17 02:36:50,599] [INFO] [RANK 0] model.diffusion_model.transformer.layers.30.audio_attn.query.weight
[2025-03-17 02:36:50,599] [INFO] [RANK 0] model.diffusion_model.transformer.layers.30.audio_attn.query.bias
[2025-03-17 02:36:50,599] [INFO] [RANK 0] model.diffusion_model.transformer.layers.30.audio_attn.key_value.weight
[2025-03-17 02:36:50,599] [INFO] [RANK 0] model.diffusion_model.transformer.layers.30.audio_attn.key_value.bias
[2025-03-17 02:36:50,599] [INFO] [RANK 0] model.diffusion_model.transformer.layers.30.audio_attn.dense.weight
[2025-03-17 02:36:50,599] [INFO] [RANK 0] model.diffusion_model.transformer.layers.30.audio_attn.dense.bias
[2025-03-17 02:36:50,600] [INFO] [RANK 0] model.diffusion_model.transformer.layers.31.audio_input_layernorm.weight
[2025-03-17 02:36:50,600] [INFO] [RANK 0] model.diffusion_model.transformer.layers.31.audio_input_layernorm.bias
[2025-03-17 02:36:50,600] [INFO] [RANK 0] model.diffusion_model.transformer.layers.31.audio_attn.query.weight
[2025-03-17 02:36:50,600] [INFO] [RANK 0] model.diffusion_model.transformer.layers.31.audio_attn.query.bias
[2025-03-17 02:36:50,600] [INFO] [RANK 0] model.diffusion_model.transformer.layers.31.audio_attn.key_value.weight
[2025-03-17 02:36:50,600] [INFO] [RANK 0] model.diffusion_model.transformer.layers.31.audio_attn.key_value.bias
[2025-03-17 02:36:50,600] [INFO] [RANK 0] model.diffusion_model.transformer.layers.31.audio_attn.dense.weight
[2025-03-17 02:36:50,601] [INFO] [RANK 0] model.diffusion_model.transformer.layers.31.audio_attn.dense.bias
[2025-03-17 02:36:50,602] [INFO] [RANK 0] model.diffusion_model.transformer.layers.32.audio_input_layernorm.weight
[2025-03-17 02:36:50,602] [INFO] [RANK 0] model.diffusion_model.transformer.layers.32.audio_input_layernorm.bias
[2025-03-17 02:36:50,602] [INFO] [RANK 0] model.diffusion_model.transformer.layers.32.audio_attn.query.weight
[2025-03-17 02:36:50,602] [INFO] [RANK 0] model.diffusion_model.transformer.layers.32.audio_attn.query.bias
[2025-03-17 02:36:50,602] [INFO] [RANK 0] model.diffusion_model.transformer.layers.32.audio_attn.key_value.weight
[2025-03-17 02:36:50,602] [INFO] [RANK 0] model.diffusion_model.transformer.layers.32.audio_attn.key_value.bias
[2025-03-17 02:36:50,603] [INFO] [RANK 0] model.diffusion_model.transformer.layers.32.audio_attn.dense.weight
[2025-03-17 02:36:50,603] [INFO] [RANK 0] model.diffusion_model.transformer.layers.32.audio_attn.dense.bias
[2025-03-17 02:36:50,604] [INFO] [RANK 0] model.diffusion_model.transformer.layers.33.audio_input_layernorm.weight
[2025-03-17 02:36:50,604] [INFO] [RANK 0] model.diffusion_model.transformer.layers.33.audio_input_layernorm.bias
[2025-03-17 02:36:50,604] [INFO] [RANK 0] model.diffusion_model.transformer.layers.33.audio_attn.query.weight
[2025-03-17 02:36:50,605] [INFO] [RANK 0] model.diffusion_model.transformer.layers.33.audio_attn.query.bias
[2025-03-17 02:36:50,605] [INFO] [RANK 0] model.diffusion_model.transformer.layers.33.audio_attn.key_value.weight
[2025-03-17 02:36:50,605] [INFO] [RANK 0] model.diffusion_model.transformer.layers.33.audio_attn.key_value.bias
[2025-03-17 02:36:50,605] [INFO] [RANK 0] model.diffusion_model.transformer.layers.33.audio_attn.dense.weight
[2025-03-17 02:36:50,605] [INFO] [RANK 0] model.diffusion_model.transformer.layers.33.audio_attn.dense.bias
[2025-03-17 02:36:50,607] [INFO] [RANK 0] model.diffusion_model.transformer.layers.34.audio_input_layernorm.weight
[2025-03-17 02:36:50,607] [INFO] [RANK 0] model.diffusion_model.transformer.layers.34.audio_input_layernorm.bias
[2025-03-17 02:36:50,607] [INFO] [RANK 0] model.diffusion_model.transformer.layers.34.audio_attn.query.weight
[2025-03-17 02:36:50,607] [INFO] [RANK 0] model.diffusion_model.transformer.layers.34.audio_attn.query.bias
[2025-03-17 02:36:50,607] [INFO] [RANK 0] model.diffusion_model.transformer.layers.34.audio_attn.key_value.weight
[2025-03-17 02:36:50,607] [INFO] [RANK 0] model.diffusion_model.transformer.layers.34.audio_attn.key_value.bias
[2025-03-17 02:36:50,608] [INFO] [RANK 0] model.diffusion_model.transformer.layers.34.audio_attn.dense.weight
[2025-03-17 02:36:50,608] [INFO] [RANK 0] model.diffusion_model.transformer.layers.34.audio_attn.dense.bias
[2025-03-17 02:36:50,609] [INFO] [RANK 0] model.diffusion_model.transformer.layers.35.audio_input_layernorm.weight
[2025-03-17 02:36:50,609] [INFO] [RANK 0] model.diffusion_model.transformer.layers.35.audio_input_layernorm.bias
[2025-03-17 02:36:50,610] [INFO] [RANK 0] model.diffusion_model.transformer.layers.35.audio_attn.query.weight
[2025-03-17 02:36:50,610] [INFO] [RANK 0] model.diffusion_model.transformer.layers.35.audio_attn.query.bias
[2025-03-17 02:36:50,610] [INFO] [RANK 0] model.diffusion_model.transformer.layers.35.audio_attn.key_value.weight
[2025-03-17 02:36:50,610] [INFO] [RANK 0] model.diffusion_model.transformer.layers.35.audio_attn.key_value.bias
[2025-03-17 02:36:50,610] [INFO] [RANK 0] model.diffusion_model.transformer.layers.35.audio_attn.dense.weight
[2025-03-17 02:36:50,610] [INFO] [RANK 0] model.diffusion_model.transformer.layers.35.audio_attn.dense.bias
[2025-03-17 02:36:50,612] [INFO] [RANK 0] model.diffusion_model.transformer.layers.36.audio_input_layernorm.weight
[2025-03-17 02:36:50,612] [INFO] [RANK 0] model.diffusion_model.transformer.layers.36.audio_input_layernorm.bias
[2025-03-17 02:36:50,612] [INFO] [RANK 0] model.diffusion_model.transformer.layers.36.audio_attn.query.weight
[2025-03-17 02:36:50,612] [INFO] [RANK 0] model.diffusion_model.transformer.layers.36.audio_attn.query.bias
[2025-03-17 02:36:50,612] [INFO] [RANK 0] model.diffusion_model.transformer.layers.36.audio_attn.key_value.weight
[2025-03-17 02:36:50,613] [INFO] [RANK 0] model.diffusion_model.transformer.layers.36.audio_attn.key_value.bias
[2025-03-17 02:36:50,613] [INFO] [RANK 0] model.diffusion_model.transformer.layers.36.audio_attn.dense.weight
[2025-03-17 02:36:50,613] [INFO] [RANK 0] model.diffusion_model.transformer.layers.36.audio_attn.dense.bias
[2025-03-17 02:36:50,614] [INFO] [RANK 0] model.diffusion_model.transformer.layers.37.audio_input_layernorm.weight
[2025-03-17 02:36:50,614] [INFO] [RANK 0] model.diffusion_model.transformer.layers.37.audio_input_layernorm.bias
[2025-03-17 02:36:50,615] [INFO] [RANK 0] model.diffusion_model.transformer.layers.37.audio_attn.query.weight
[2025-03-17 02:36:50,615] [INFO] [RANK 0] model.diffusion_model.transformer.layers.37.audio_attn.query.bias
[2025-03-17 02:36:50,615] [INFO] [RANK 0] model.diffusion_model.transformer.layers.37.audio_attn.key_value.weight
[2025-03-17 02:36:50,615] [INFO] [RANK 0] model.diffusion_model.transformer.layers.37.audio_attn.key_value.bias
[2025-03-17 02:36:50,615] [INFO] [RANK 0] model.diffusion_model.transformer.layers.37.audio_attn.dense.weight
[2025-03-17 02:36:50,615] [INFO] [RANK 0] model.diffusion_model.transformer.layers.37.audio_attn.dense.bias
[2025-03-17 02:36:50,617] [INFO] [RANK 0] model.diffusion_model.transformer.layers.38.audio_input_layernorm.weight
[2025-03-17 02:36:50,617] [INFO] [RANK 0] model.diffusion_model.transformer.layers.38.audio_input_layernorm.bias
[2025-03-17 02:36:50,617] [INFO] [RANK 0] model.diffusion_model.transformer.layers.38.audio_attn.query.weight
[2025-03-17 02:36:50,617] [INFO] [RANK 0] model.diffusion_model.transformer.layers.38.audio_attn.query.bias
[2025-03-17 02:36:50,617] [INFO] [RANK 0] model.diffusion_model.transformer.layers.38.audio_attn.key_value.weight
[2025-03-17 02:36:50,617] [INFO] [RANK 0] model.diffusion_model.transformer.layers.38.audio_attn.key_value.bias
[2025-03-17 02:36:50,617] [INFO] [RANK 0] model.diffusion_model.transformer.layers.38.audio_attn.dense.weight
[2025-03-17 02:36:50,617] [INFO] [RANK 0] model.diffusion_model.transformer.layers.38.audio_attn.dense.bias
[2025-03-17 02:36:50,619] [INFO] [RANK 0] model.diffusion_model.transformer.layers.39.audio_input_layernorm.weight
[2025-03-17 02:36:50,619] [INFO] [RANK 0] model.diffusion_model.transformer.layers.39.audio_input_layernorm.bias
[2025-03-17 02:36:50,619] [INFO] [RANK 0] model.diffusion_model.transformer.layers.39.audio_attn.query.weight
[2025-03-17 02:36:50,619] [INFO] [RANK 0] model.diffusion_model.transformer.layers.39.audio_attn.query.bias
[2025-03-17 02:36:50,619] [INFO] [RANK 0] model.diffusion_model.transformer.layers.39.audio_attn.key_value.weight
[2025-03-17 02:36:50,619] [INFO] [RANK 0] model.diffusion_model.transformer.layers.39.audio_attn.key_value.bias
[2025-03-17 02:36:50,620] [INFO] [RANK 0] model.diffusion_model.transformer.layers.39.audio_attn.dense.weight
[2025-03-17 02:36:50,644] [INFO] [RANK 0] model.diffusion_model.transformer.layers.39.audio_attn.dense.bias
[2025-03-17 02:36:50,647] [INFO] [RANK 0] model.diffusion_model.transformer.layers.40.audio_input_layernorm.weight
[2025-03-17 02:36:50,647] [INFO] [RANK 0] model.diffusion_model.transformer.layers.40.audio_input_layernorm.bias
[2025-03-17 02:36:50,648] [INFO] [RANK 0] model.diffusion_model.transformer.layers.40.audio_attn.query.weight
[2025-03-17 02:36:50,649] [INFO] [RANK 0] model.diffusion_model.transformer.layers.40.audio_attn.query.bias
[2025-03-17 02:36:50,649] [INFO] [RANK 0] model.diffusion_model.transformer.layers.40.audio_attn.key_value.weight
[2025-03-17 02:36:50,649] [INFO] [RANK 0] model.diffusion_model.transformer.layers.40.audio_attn.key_value.bias
[2025-03-17 02:36:50,649] [INFO] [RANK 0] model.diffusion_model.transformer.layers.40.audio_attn.dense.weight
[2025-03-17 02:36:50,649] [INFO] [RANK 0] model.diffusion_model.transformer.layers.40.audio_attn.dense.bias
[2025-03-17 02:36:50,650] [INFO] [RANK 0] model.diffusion_model.transformer.layers.41.audio_input_layernorm.weight
[2025-03-17 02:36:50,650] [INFO] [RANK 0] model.diffusion_model.transformer.layers.41.audio_input_layernorm.bias
[2025-03-17 02:36:50,651] [INFO] [RANK 0] model.diffusion_model.transformer.layers.41.audio_attn.query.weight
[2025-03-17 02:36:50,651] [INFO] [RANK 0] model.diffusion_model.transformer.layers.41.audio_attn.query.bias
[2025-03-17 02:36:50,651] [INFO] [RANK 0] model.diffusion_model.transformer.layers.41.audio_attn.key_value.weight
[2025-03-17 02:36:50,651] [INFO] [RANK 0] model.diffusion_model.transformer.layers.41.audio_attn.key_value.bias
[2025-03-17 02:36:50,807] [INFO] [RANK 0] model.diffusion_model.transformer.layers.41.audio_attn.dense.weight
[2025-03-17 02:36:50,808] [INFO] [RANK 0] model.diffusion_model.transformer.layers.41.audio_attn.dense.bias
[2025-03-17 02:36:50,808] [INFO] [RANK 0] model.diffusion_model.transformer.audio_proj.proj1.weight
[2025-03-17 02:36:50,814] [INFO] [RANK 0] model.diffusion_model.transformer.audio_proj.proj1.bias
[2025-03-17 02:36:50,814] [INFO] [RANK 0] model.diffusion_model.transformer.audio_proj.proj2.weight
[2025-03-17 02:36:50,814] [INFO] [RANK 0] model.diffusion_model.transformer.audio_proj.proj2.bias
[2025-03-17 02:36:50,815] [INFO] [RANK 0] model.diffusion_model.transformer.audio_proj.proj3.weight
[2025-03-17 02:36:50,815] [INFO] [RANK 0] model.diffusion_model.transformer.audio_proj.proj3.bias
[2025-03-17 02:36:50,815] [INFO] [RANK 0] model.diffusion_model.transformer.audio_proj.norm.weight
[2025-03-17 02:36:50,815] [INFO] [RANK 0] model.diffusion_model.transformer.audio_proj.norm.bias
[2025-03-17 02:36:50,815] [INFO] [RANK 0] model.diffusion_model.transformer.audio_proj.conv1.weight
[2025-03-17 02:36:50,815] [INFO] [RANK 0] model.diffusion_model.transformer.audio_proj.conv1.bias
[2025-03-17 02:36:50,892] [INFO] [RANK 0] ***** Total trainable parameters: 2236127744 *****
[2025-03-17 02:36:50,893] [INFO] [RANK 0] [<class 'sat.ops.layernorm.LayerNorm'>, <class 'torch.nn.modules.normalization.LayerNorm'>, <class 'sat.ops.layernorm.RMSNorm'>] is set to no_weight_decay
[2025-03-17 02:36:50,908] [INFO] [RANK 0] Syncing initialized parameters...
[2025-03-17 02:36:57,519] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2025-03-17 02:36:57,519] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2025-03-17 02:36:57,520] [WARNING] [config_utils.py:70:_process_deprecated_field] Config parameter cpu_offload is deprecated use offload_optimizer instead
[2025-03-17 02:36:57,520] [WARNING] [config_utils.py:70:_process_deprecated_field] Config parameter cpu_offload is deprecated use offload_optimizer instead
[2025-03-17 02:36:57,520] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2025-03-17 02:36:57,521] [WARNING] [config_utils.py:70:_process_deprecated_field] Config parameter cpu_offload is deprecated use offload_optimizer instead
[2025-03-17 02:36:57,524] [INFO] [RANK 0] Finished syncing initialized parameters.
[2025-03-17 02:36:57,525] [INFO] [RANK 0] Using optimizer sat.ops.FusedEmaAdam from sat.
[2025-03-17 02:36:57,525] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2025-03-17 02:36:57,526] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed info: version=0.16.2, git-hash=unknown, git-branch=unknown
[2025-03-17 02:36:57,526] [WARNING] [config_utils.py:70:_process_deprecated_field] Config parameter cpu_offload is deprecated use offload_optimizer instead
[2025-03-17 02:36:57,527] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2025-03-17 02:36:57,527] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2025-03-17 02:36:57,527] [WARNING] [config_utils.py:70:_process_deprecated_field] Config parameter cpu_offload is deprecated use offload_optimizer instead
[2025-03-17 02:36:57,528] [WARNING] [config_utils.py:70:_process_deprecated_field] Config parameter cpu_offload is deprecated use offload_optimizer instead
[2025-03-17 02:36:57,528] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2025-03-17 02:36:57,529] [WARNING] [config_utils.py:70:_process_deprecated_field] Config parameter cpu_offload is deprecated use offload_optimizer instead
[2025-03-17 02:36:57,531] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2025-03-17 02:36:57,532] [WARNING] [config_utils.py:70:_process_deprecated_field] Config parameter cpu_offload is deprecated use offload_optimizer instead
[2025-03-17 02:36:58,951] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
Using /root/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /root/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /root/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /root/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /root/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /root/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /root/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /root/.cache/torch_extensions/py310_cu121/fused_ema_adam/build.ninja...
/sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1965: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
Building extension module fused_ema_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Using /root/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
ninja: no work to do.
Loading extension module fused_ema_adam...
Loading extension module fused_ema_adam...
Time to load fused_ema_adam op: 0.6192371845245361 seconds
Loading extension module fused_ema_adam...
Time to load fused_ema_adam op: 0.6263635158538818 secondsTime to load fused_ema_adam op: 0.6197123527526855 seconds

[2025-03-17 02:36:59,608] [INFO] [logging.py:128:log_dist] [Rank 0] Using client callable to create basic optimizer
[2025-03-17 02:36:59,609] [INFO] [logging.py:128:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
Loading extension module fused_ema_adam...Loading extension module fused_ema_adam...Loading extension module fused_ema_adam...

Loading extension module fused_ema_adam...

Loading extension module fused_ema_adam...
Time to load fused_ema_adam op: 0.5260751247406006 seconds
Time to load fused_ema_adam op: 0.633500337600708 seconds
Time to load fused_ema_adam op: 0.6373727321624756 seconds
Time to load fused_ema_adam op: 0.6306421756744385 seconds
Time to load fused_ema_adam op: 0.6395268440246582 seconds
[2025-03-17 02:36:59,869] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedEmaAdam
[2025-03-17 02:36:59,869] [INFO] [utils.py:59:is_zero_supported_optimizer] Checking ZeRO support for optimizer=FusedEmaAdam type=<class 'sat.ops.fused_ema_adam.FusedEmaAdam'>
[2025-03-17 02:36:59,874] [WARNING] [engine.py:1244:_do_optimizer_sanity_check] **** You are using ZeRO with an untested optimizer, proceed with caution *****
[2025-03-17 02:36:59,874] [INFO] [logging.py:128:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer
[2025-03-17 02:36:59,875] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 1000000000
[2025-03-17 02:36:59,875] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 1000000000
[2025-03-17 02:36:59,875] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False
[2025-03-17 02:36:59,875] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False
[2025-03-17 02:37:17,105] [INFO] [utils.py:781:see_memory_usage] Before initializing optimizer states
[2025-03-17 02:37:17,111] [INFO] [utils.py:782:see_memory_usage] MA 37.42 GB         Max_MA 37.42 GB         CA 38.26 GB         Max_CA 38 GB 
[2025-03-17 02:37:17,113] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 234.65 GB, percent = 11.6%
[2025-03-17 02:37:19,589] [INFO] [utils.py:781:see_memory_usage] After initializing optimizer states
[2025-03-17 02:37:19,590] [INFO] [utils.py:782:see_memory_usage] MA 37.42 GB         Max_MA 38.46 GB         CA 39.31 GB         Max_CA 39 GB 
[2025-03-17 02:37:19,592] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 243.63 GB, percent = 12.1%
[2025-03-17 02:37:19,592] [INFO] [stage_1_and_2.py:544:__init__] optimizer state initialized
[2025-03-17 02:37:22,950] [INFO] [utils.py:781:see_memory_usage] After initializing ZeRO optimizer
[2025-03-17 02:37:22,952] [INFO] [utils.py:782:see_memory_usage] MA 37.42 GB         Max_MA 37.42 GB         CA 39.31 GB         Max_CA 39 GB 
[2025-03-17 02:37:22,954] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 255.54 GB, percent = 12.7%
[2025-03-17 02:37:22,959] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedZeroOptimizer
[2025-03-17 02:37:22,960] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed using configured LR scheduler = None
[2025-03-17 02:37:22,960] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2025-03-17 02:37:22,960] [INFO] [logging.py:128:log_dist] [Rank 0] step=0, skipped=0, lr=[1.0, 1.0], mom=[[0.9, 0.95], [0.9, 0.95]]
[2025-03-17 02:37:23,100] [INFO] [config.py:999:print] DeepSpeedEngine configuration:
[2025-03-17 02:37:23,102] [INFO] [config.py:1003:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2025-03-17 02:37:23,102] [INFO] [config.py:1003:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True, 'use_gds': False}
[2025-03-17 02:37:23,102] [INFO] [config.py:1003:print]   amp_enabled .................. False
[2025-03-17 02:37:23,102] [INFO] [config.py:1003:print]   amp_params ................... False
[2025-03-17 02:37:23,103] [INFO] [config.py:1003:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2025-03-17 02:37:23,104] [INFO] [config.py:1003:print]   bfloat16_enabled ............. True
[2025-03-17 02:37:23,111] [INFO] [config.py:1003:print]   bfloat16_immediate_grad_update  False
[2025-03-17 02:37:23,112] [INFO] [config.py:1003:print]   checkpoint_parallel_write_pipeline  False
[2025-03-17 02:37:23,112] [INFO] [config.py:1003:print]   checkpoint_tag_validation_enabled  True
[2025-03-17 02:37:23,112] [INFO] [config.py:1003:print]   checkpoint_tag_validation_fail  False
[2025-03-17 02:37:23,112] [INFO] [config.py:1003:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f10c7e41210>
[2025-03-17 02:37:23,112] [INFO] [config.py:1003:print]   communication_data_type ...... None
[2025-03-17 02:37:23,114] [INFO] [config.py:1003:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2025-03-17 02:37:23,116] [INFO] [config.py:1003:print]   curriculum_enabled_legacy .... False
[2025-03-17 02:37:23,117] [INFO] [config.py:1003:print]   curriculum_params_legacy ..... False
[2025-03-17 02:37:23,117] [INFO] [config.py:1003:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2025-03-17 02:37:23,117] [INFO] [config.py:1003:print]   data_efficiency_enabled ...... False
[2025-03-17 02:37:23,117] [INFO] [config.py:1003:print]   dataloader_drop_last ......... False
[2025-03-17 02:37:23,117] [INFO] [config.py:1003:print]   disable_allgather ............ False
[2025-03-17 02:37:23,117] [INFO] [config.py:1003:print]   dump_state ................... False
[2025-03-17 02:37:23,117] [INFO] [config.py:1003:print]   dynamic_loss_scale_args ...... None
[2025-03-17 02:37:23,117] [INFO] [config.py:1003:print]   eigenvalue_enabled ........... False
[2025-03-17 02:37:23,117] [INFO] [config.py:1003:print]   eigenvalue_gas_boundary_resolution  1
[2025-03-17 02:37:23,117] [INFO] [config.py:1003:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2025-03-17 02:37:23,117] [INFO] [config.py:1003:print]   eigenvalue_layer_num ......... 0
[2025-03-17 02:37:23,117] [INFO] [config.py:1003:print]   eigenvalue_max_iter .......... 100
[2025-03-17 02:37:23,117] [INFO] [config.py:1003:print]   eigenvalue_stability ......... 1e-06
[2025-03-17 02:37:23,117] [INFO] [config.py:1003:print]   eigenvalue_tol ............... 0.01
[2025-03-17 02:37:23,117] [INFO] [config.py:1003:print]   eigenvalue_verbose ........... False
[2025-03-17 02:37:23,117] [INFO] [config.py:1003:print]   elasticity_enabled ........... False
[2025-03-17 02:37:23,117] [INFO] [config.py:1003:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2025-03-17 02:37:23,117] [INFO] [config.py:1003:print]   fp16_auto_cast ............... None
[2025-03-17 02:37:23,119] [INFO] [config.py:1003:print]   fp16_enabled ................. False
[2025-03-17 02:37:23,119] [INFO] [config.py:1003:print]   fp16_master_weights_and_gradients  False
[2025-03-17 02:37:23,120] [INFO] [config.py:1003:print]   global_rank .................. 0
[2025-03-17 02:37:23,120] [INFO] [config.py:1003:print]   grad_accum_dtype ............. None
[2025-03-17 02:37:23,120] [INFO] [config.py:1003:print]   gradient_accumulation_steps .. 1
[2025-03-17 02:37:23,121] [INFO] [config.py:1003:print]   gradient_clipping ............ 0.1
[2025-03-17 02:37:23,121] [INFO] [config.py:1003:print]   gradient_predivide_factor .... 1.0
[2025-03-17 02:37:23,121] [INFO] [config.py:1003:print]   graph_harvesting ............. False
[2025-03-17 02:37:23,121] [INFO] [config.py:1003:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2025-03-17 02:37:23,123] [INFO] [config.py:1003:print]   initial_dynamic_scale ........ 1
[2025-03-17 02:37:23,123] [INFO] [config.py:1003:print]   load_universal_checkpoint .... False
[2025-03-17 02:37:23,123] [INFO] [config.py:1003:print]   loss_scale ................... 1.0
[2025-03-17 02:37:23,124] [INFO] [config.py:1003:print]   memory_breakdown ............. False
[2025-03-17 02:37:23,124] [INFO] [config.py:1003:print]   mics_hierarchial_params_gather  False
[2025-03-17 02:37:23,124] [INFO] [config.py:1003:print]   mics_shard_size .............. -1
[2025-03-17 02:37:23,124] [INFO] [config.py:1003:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') comet=CometConfig(enabled=False, samples_log_interval=100, project=None, workspace=None, api_key=None, experiment_name=None, experiment_key=None, online=None, mode=None) wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName')
[2025-03-17 02:37:23,125] [INFO] [config.py:1003:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2025-03-17 02:37:23,125] [INFO] [config.py:1003:print]   optimizer_legacy_fusion ...... False
[2025-03-17 02:37:23,125] [INFO] [config.py:1003:print]   optimizer_name ............... None
[2025-03-17 02:37:23,125] [INFO] [config.py:1003:print]   optimizer_params ............. None
[2025-03-17 02:37:23,125] [INFO] [config.py:1003:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2025-03-17 02:37:23,125] [INFO] [config.py:1003:print]   pld_enabled .................. False
[2025-03-17 02:37:23,125] [INFO] [config.py:1003:print]   pld_params ................... False
[2025-03-17 02:37:23,126] [INFO] [config.py:1003:print]   prescale_gradients ........... False
[2025-03-17 02:37:23,126] [INFO] [config.py:1003:print]   scheduler_name ............... None
[2025-03-17 02:37:23,126] [INFO] [config.py:1003:print]   scheduler_params ............. None
[2025-03-17 02:37:23,126] [INFO] [config.py:1003:print]   seq_parallel_communication_data_type  torch.float32
[2025-03-17 02:37:23,128] [INFO] [config.py:1003:print]   sparse_attention ............. None
[2025-03-17 02:37:23,128] [INFO] [config.py:1003:print]   sparse_gradients_enabled ..... False
[2025-03-17 02:37:23,128] [INFO] [config.py:1003:print]   steps_per_print .............. 50
[2025-03-17 02:37:23,128] [INFO] [config.py:1003:print]   timers_config ................ enabled=True synchronized=True
[2025-03-17 02:37:23,128] [INFO] [config.py:1003:print]   train_batch_size ............. 8
[2025-03-17 02:37:23,128] [INFO] [config.py:1003:print]   train_micro_batch_size_per_gpu  1
[2025-03-17 02:37:23,128] [INFO] [config.py:1003:print]   use_data_before_expert_parallel_  False
[2025-03-17 02:37:23,130] [INFO] [config.py:1003:print]   use_node_local_storage ....... False
[2025-03-17 02:37:23,131] [INFO] [config.py:1003:print]   wall_clock_breakdown ......... False
[2025-03-17 02:37:23,131] [INFO] [config.py:1003:print]   weight_quantization_config ... None
[2025-03-17 02:37:23,131] [INFO] [config.py:1003:print]   world_size ................... 8
[2025-03-17 02:37:23,131] [INFO] [config.py:1003:print]   zero_allow_untested_optimizer  True
[2025-03-17 02:37:23,132] [INFO] [config.py:1003:print]   zero_config .................. stage=2 contiguous_gradients=False reduce_scatter=True reduce_bucket_size=1000000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=1000000000 overlap_comm=True load_from_fp32_weights=False elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None prefetch_bucket_size=50000000 param_persistence_threshold=100000 model_persistence_threshold=9223372036854775807 max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=False module_granularity_threshold=0 use_all_reduce_for_fetch_params=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False zeropp_loco_param=None mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2025-03-17 02:37:23,132] [INFO] [config.py:1003:print]   zero_enabled ................. True
[2025-03-17 02:37:23,132] [INFO] [config.py:1003:print]   zero_force_ds_cpu_optimizer .. True
[2025-03-17 02:37:23,132] [INFO] [config.py:1003:print]   zero_optimization_stage ...... 2
[2025-03-17 02:37:23,132] [INFO] [config.py:989:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "steps_per_print": 50, 
    "gradient_clipping": 0.1, 
    "zero_optimization": {
        "stage": 2, 
        "cpu_offload": false, 
        "contiguous_gradients": false, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 1.000000e+09, 
        "allgather_bucket_size": 1.000000e+09, 
        "load_from_fp32_weights": false
    }, 
    "zero_allow_untested_optimizer": true, 
    "bf16": {
        "enabled": true
    }, 
    "fp16": {
        "enabled": false
    }, 
    "loss_scale": 0, 
    "loss_scale_window": 400, 
    "hysteresis": 2, 
    "min_loss_scale": 1, 
    "activation_checkpointing": {
        "partition_activations": false, 
        "contiguous_memory_optimization": false
    }, 
    "wall_clock_breakdown": false
}
[2025-03-17 02:37:23,133] [INFO] [RANK 0] learning rate decaying style linear, ratio 10.0
[2025-03-17 02:37:23,133] [INFO] [RANK 0] Finetuning Model...
[2025-03-17 02:37:23,134] [INFO] [RANK 0] arguments:
[2025-03-17 02:37:23,134] [INFO] [RANK 0]   base ......................... ['configs/cogvideox_5b_i2v_s2.yaml', 'configs/sft_s2.yaml']
[2025-03-17 02:37:23,134] [INFO] [RANK 0]   model_parallel_size .......... 1
[2025-03-17 02:37:23,134] [INFO] [RANK 0]   force_pretrain ............... False
[2025-03-17 02:37:23,134] [INFO] [RANK 0]   device ....................... 0
[2025-03-17 02:37:23,134] [INFO] [RANK 0]   debug ........................ False
[2025-03-17 02:37:23,135] [INFO] [RANK 0]   log_image .................... True
[2025-03-17 02:37:23,135] [INFO] [RANK 0]   output_dir ................... samples
[2025-03-17 02:37:23,135] [INFO] [RANK 0]   input_dir .................... None
[2025-03-17 02:37:23,135] [INFO] [RANK 0]   input_type ................... cli
[2025-03-17 02:37:23,135] [INFO] [RANK 0]   input_file ................... input.txt
[2025-03-17 02:37:23,135] [INFO] [RANK 0]   final_size ................... 2048
[2025-03-17 02:37:23,136] [INFO] [RANK 0]   sdedit ....................... False
[2025-03-17 02:37:23,137] [INFO] [RANK 0]   grid_num_rows ................ 1
[2025-03-17 02:37:23,137] [INFO] [RANK 0]   force_inference .............. False
[2025-03-17 02:37:23,137] [INFO] [RANK 0]   lcm_steps .................... None
[2025-03-17 02:37:23,137] [INFO] [RANK 0]   sampling_num_frames .......... 32
[2025-03-17 02:37:23,137] [INFO] [RANK 0]   sampling_fps ................. 8
[2025-03-17 02:37:23,137] [INFO] [RANK 0]   only_save_latents ............ False
[2025-03-17 02:37:23,138] [INFO] [RANK 0]   only_log_video_latents ....... True
[2025-03-17 02:37:23,138] [INFO] [RANK 0]   latent_channels .............. 32
[2025-03-17 02:37:23,138] [INFO] [RANK 0]   image2video .................. False
[2025-03-17 02:37:23,138] [INFO] [RANK 0]   experiment_name .............. train-stage-2-03-17-02-27
[2025-03-17 02:37:23,138] [INFO] [RANK 0]   train_iters .................. 30000
[2025-03-17 02:37:23,138] [INFO] [RANK 0]   batch_size ................... 1
[2025-03-17 02:37:23,139] [INFO] [RANK 0]   lr ........................... 1e-05
[2025-03-17 02:37:23,139] [INFO] [RANK 0]   mode ......................... finetune
[2025-03-17 02:37:23,139] [INFO] [RANK 0]   seed ......................... 27024
[2025-03-17 02:37:23,139] [INFO] [RANK 0]   zero_stage ................... 0
[2025-03-17 02:37:23,139] [INFO] [RANK 0]   checkpoint_activations ....... True
[2025-03-17 02:37:23,139] [INFO] [RANK 0]   checkpoint_num_layers ........ 1
[2025-03-17 02:37:23,139] [INFO] [RANK 0]   checkpoint_skip_layers ....... 0
[2025-03-17 02:37:23,139] [INFO] [RANK 0]   fp16 ......................... False
[2025-03-17 02:37:23,139] [INFO] [RANK 0]   bf16 ......................... True
[2025-03-17 02:37:23,139] [INFO] [RANK 0]   gradient_accumulation_steps .. 1
[2025-03-17 02:37:23,139] [INFO] [RANK 0]   profiling .................... -1
[2025-03-17 02:37:23,139] [INFO] [RANK 0]   epochs ....................... None
[2025-03-17 02:37:23,140] [INFO] [RANK 0]   log_interval ................. 1
[2025-03-17 02:37:23,140] [INFO] [RANK 0]   summary_dir .................. 
[2025-03-17 02:37:23,140] [INFO] [RANK 0]   save_args .................... False
[2025-03-17 02:37:23,140] [INFO] [RANK 0]   lr_decay_iters ............... None
[2025-03-17 02:37:23,140] [INFO] [RANK 0]   lr_decay_style ............... linear
[2025-03-17 02:37:23,140] [INFO] [RANK 0]   lr_decay_ratio ............... 0.1
[2025-03-17 02:37:23,140] [INFO] [RANK 0]   warmup ....................... 0.01
[2025-03-17 02:37:23,140] [INFO] [RANK 0]   weight_decay ................. 0.0001
[2025-03-17 02:37:23,140] [INFO] [RANK 0]   save ......................... stage-2/train-stage-2-03-17-02-27
[2025-03-17 02:37:23,140] [INFO] [RANK 0]   load ......................... pretrained_models/hallo3
[2025-03-17 02:37:23,140] [INFO] [RANK 0]   force_train .................. True
[2025-03-17 02:37:23,140] [INFO] [RANK 0]   save_interval ................ 250
[2025-03-17 02:37:23,140] [INFO] [RANK 0]   no_save_rng .................. False
[2025-03-17 02:37:23,140] [INFO] [RANK 0]   no_load_rng .................. True
[2025-03-17 02:37:23,140] [INFO] [RANK 0]   resume_dataloader ............ False
[2025-03-17 02:37:23,140] [INFO] [RANK 0]   distributed_backend .......... nccl
[2025-03-17 02:37:23,140] [INFO] [RANK 0]   local_rank ................... 0
[2025-03-17 02:37:23,140] [INFO] [RANK 0]   exit_interval ................ None
[2025-03-17 02:37:23,140] [INFO] [RANK 0]   wandb ........................ True
[2025-03-17 02:37:23,140] [INFO] [RANK 0]   wandb_project_name ........... default_project
[2025-03-17 02:37:23,140] [INFO] [RANK 0]   eval_batch_size .............. 1
[2025-03-17 02:37:23,140] [INFO] [RANK 0]   eval_iters ................... 1
[2025-03-17 02:37:23,140] [INFO] [RANK 0]   eval_interval ................ 30000
[2025-03-17 02:37:23,141] [INFO] [RANK 0]   strict_eval .................. False
[2025-03-17 02:37:23,141] [INFO] [RANK 0]   train_data ................... ['./data/shunian-hallo3-22k.json']
[2025-03-17 02:37:23,141] [INFO] [RANK 0]   train_data_weights ........... None
[2025-03-17 02:37:23,141] [INFO] [RANK 0]   iterable_dataset ............. False
[2025-03-17 02:37:23,141] [INFO] [RANK 0]   iterable_dataset_eval ........ 
[2025-03-17 02:37:23,141] [INFO] [RANK 0]   batch_from_same_dataset ...... False
[2025-03-17 02:37:23,141] [INFO] [RANK 0]   valid_data ................... ['./data/hallo3-55f.json']
[2025-03-17 02:37:23,141] [INFO] [RANK 0]   test_data .................... None
[2025-03-17 02:37:23,141] [INFO] [RANK 0]   split ........................ 1,0,0
[2025-03-17 02:37:23,141] [INFO] [RANK 0]   num_workers .................. 1
[2025-03-17 02:37:23,141] [INFO] [RANK 0]   block_size ................... 10000
[2025-03-17 02:37:23,141] [INFO] [RANK 0]   prefetch_factor .............. 4
[2025-03-17 02:37:23,141] [INFO] [RANK 0]   sample_rate .................. 16000
[2025-03-17 02:37:23,141] [INFO] [RANK 0]   wav2vec_model_path ........... None
[2025-03-17 02:37:23,141] [INFO] [RANK 0]   wav2vec_features ............. all
[2025-03-17 02:37:23,142] [INFO] [RANK 0]   audio_separator_model_path ... None
[2025-03-17 02:37:23,142] [INFO] [RANK 0]   face_analysis_model_path ..... None
[2025-03-17 02:37:23,142] [INFO] [RANK 0]   deepspeed .................... True
[2025-03-17 02:37:23,142] [INFO] [RANK 0]   deepspeed_config ............. {'train_micro_batch_size_per_gpu': 1, 'gradient_accumulation_steps': 1, 'steps_per_print': 50, 'gradient_clipping': 0.1, 'zero_optimization': {'stage': 2, 'cpu_offload': False, 'contiguous_gradients': False, 'overlap_comm': True, 'reduce_scatter': True, 'reduce_bucket_size': 1000000000, 'allgather_bucket_size': 1000000000, 'load_from_fp32_weights': False}, 'zero_allow_untested_optimizer': True, 'bf16': {'enabled': True}, 'fp16': {'enabled': False}, 'loss_scale': 0, 'loss_scale_window': 400, 'hysteresis': 2, 'min_loss_scale': 1, 'activation_checkpointing': {'partition_activations': False, 'contiguous_memory_optimization': False}, 'wall_clock_breakdown': False}
[2025-03-17 02:37:23,142] [INFO] [RANK 0]   deepscale .................... False
[2025-03-17 02:37:23,142] [INFO] [RANK 0]   deepscale_config ............. None
[2025-03-17 02:37:23,142] [INFO] [RANK 0]   model_config ................. {'scale_factor': 0.7, 'disable_first_stage_autocast': True, 'latent_input': False, 'noised_image_input': True, 'noised_image_all_concat': False, 'noised_image_dropout': 0.05, 'not_trainable_prefixes': ['ref_model'], 'train_prefix': {'model': ['audio']}, 'log_keys': ['txt'], 'denoiser_config': {'target': 'sgm.modules.diffusionmodules.denoiser.DiscreteDenoiser', 'params': {'num_idx': 1000, 'quantize_c_noise': False, 'weighting_config': {'target': 'sgm.modules.diffusionmodules.denoiser_weighting.EpsWeighting'}, 'scaling_config': {'target': 'sgm.modules.diffusionmodules.denoiser_scaling.VideoScaling'}, 'discretization_config': {'target': 'sgm.modules.diffusionmodules.discretizer.ZeroSNRDDPMDiscretization', 'params': {'shift_scale': 1.0}}}}, 'network_config': {'target': 'dit_video_concat.DiffusionTransformer', 'params': {'time_embed_dim': 512, 'elementwise_affine': True, 'num_frames': 49, 'time_compressed_rate': 4, 'latent_width': 90, 'latent_height': 60, 'num_layers': 42, 'patch_size': 2, 'in_channels': 32, 'out_channels': 16, 'hidden_size': 3072, 'adm_in_channels': 256, 'num_attention_heads': 48, 'add_audio_module': True, 'transformer_args': {'checkpoint_activations': True, 'vocab_size': 1, 'max_sequence_length': 64, 'layernorm_order': 'pre', 'skip_init': False, 'model_parallel_size': 1, 'is_decoder': False, 'cross_attn_hidden_size': 768, 'face_cross_attn_hidden_size': 1024, 'num_layers': 42, 'hidden_size': 3072, 'num_attention_heads': 48, 'parallel_output': True, 'add_audio_module': True}, 'modules': {'pos_embed_config': {'target': 'dit_video_concat.Rotary3DPositionEmbeddingMixin', 'params': {'learnable_pos_embed': True, 'hidden_size_head': 64, 'text_length': 226}}, 'patch_embed_config': {'target': 'dit_video_concat.ImagePatchEmbeddingMixin', 'params': {'text_hidden_size': 4096}}, 'adaln_layer_config': {'target': 'dit_video_concat.AdaLNMixin', 'params': {'qk_ln': True}}, 'final_layer_config': {'target': 'dit_video_concat.FinalLayerMixin'}}, 'dtype': 'bf16'}}, 'ref_network_config': {'target': 'ref_dit_video_concat.DiffusionTransformer', 'params': {'time_embed_dim': 512, 'elementwise_affine': True, 'num_frames': 49, 'time_compressed_rate': 4, 'latent_width': 90, 'latent_height': 60, 'num_layers': 42, 'patch_size': 2, 'in_channels': 32, 'out_channels': 16, 'hidden_size': 3072, 'adm_in_channels': 256, 'num_attention_heads': 48, 'transformer_args': {'checkpoint_activations': False, 'vocab_size': 1, 'max_sequence_length': 64, 'layernorm_order': 'pre', 'skip_init': False, 'model_parallel_size': 1, 'is_decoder': False, 'num_layers': 42, 'hidden_size': 3072, 'num_attention_heads': 48, 'parallel_output': True}, 'modules': {'pos_embed_config': {'target': 'ref_dit_video_concat.Rotary3DPositionEmbeddingMixin', 'params': {'learnable_pos_embed': True, 'hidden_size_head': 64, 'text_length': 226}}, 'patch_embed_config': {'target': 'ref_dit_video_concat.ImagePatchEmbeddingMixin', 'params': {'text_hidden_size': 4096}}, 'adaln_layer_config': {'target': 'ref_dit_video_concat.AdaLNMixin', 'params': {'qk_ln': True}}, 'final_layer_config': {'target': 'ref_dit_video_concat.FinalLayerMixin'}}, 'dtype': 'bf16'}}, 'conditioner_config': {'target': 'sgm.modules.GeneralConditioner', 'params': {'emb_models': [{'is_trainable': False, 'input_key': 'txt', 'ucg_rate': 0.1, 'target': 'sgm.modules.encoders.modules.FrozenT5Embedder', 'params': {'model_dir': './pretrained_models/t5-v1_1-xxl', 'max_length': 226}}]}}, 'first_stage_config': {'target': 'vae_modules.autoencoder.VideoAutoencoderInferenceWrapper', 'params': {'cp_size': 1, 'ckpt_path': './pretrained_models/cogvideox-5b-i2v-sat/vae/3d-vae.pt', 'ignore_keys': ['loss'], 'loss_config': {'target': 'torch.nn.Identity'}, 'regularizer_config': {'target': 'vae_modules.regularizers.DiagonalGaussianRegularizer'}, 'encoder_config': {'target': 'vae_modules.cp_enc_dec.ContextParallelEncoder3D', 'params': {'double_z': True, 'z_channels': 16, 'resolution': 256, 'in_channels': 3, 'out_ch': 3, 'ch': 128, 'ch_mult': [1, 2, 2, 4], 'attn_resolutions': [], 'num_res_blocks': 3, 'dropout': 0.0, 'gather_norm': True}}, 'decoder_config': {'target': 'vae_modules.cp_enc_dec.ContextParallelDecoder3D', 'params': {'double_z': True, 'z_channels': 16, 'resolution': 256, 'in_channels': 3, 'out_ch': 3, 'ch': 128, 'ch_mult': [1, 2, 2, 4], 'attn_resolutions': [], 'num_res_blocks': 3, 'dropout': 0.0, 'gather_norm': True}}}}, 'loss_fn_config': {'target': 'sgm.modules.diffusionmodules.loss.VideoDiffusionLoss', 'params': {'batch2model_keys': ['audio_emb', 'face_emb'], 'fixed_frames': 0, 'offset_noise_level': 0, 'sigma_sampler_config': {'target': 'sgm.modules.diffusionmodules.sigma_sampling.DiscreteSampling', 'params': {'uniform_sampling': True, 'num_idx': 1000, 'discretization_config': {'target': 'sgm.modules.diffusionmodules.discretizer.ZeroSNRDDPMDiscretization', 'params': {'shift_scale': 1.0}}}}}}, 'sampler_config': {'target': 'sgm.modules.diffusionmodules.sampling.VPSDEDPMPP2MSampler', 'params': {'fixed_frames': 0, 'num_steps': 50, 'verbose': True, 'discretization_config': {'target': 'sgm.modules.diffusionmodules.discretizer.ZeroSNRDDPMDiscretization', 'params': {'shift_scale': 1.0}}, 'guider_config': {'target': 'sgm.modules.diffusionmodules.guiders.DynamicCFG', 'params': {'scale': 6, 'exp': 5, 'num_steps': 50}}}}}
[2025-03-17 02:37:23,260] [INFO] [RANK 0]   data_config .................. {'target': 'data_video.Stage2_SFTDataset', 'params': {'video_size': [480, 720], 'fps': 8, 'max_num_frames': 49, 'skip_frms_num': 3.0}}
[2025-03-17 02:37:23,260] [INFO] [RANK 0]   cuda ......................... True
[2025-03-17 02:37:23,261] [INFO] [RANK 0]   rank ......................... 0
[2025-03-17 02:37:23,261] [INFO] [RANK 0]   world_size ................... 8
[2025-03-17 02:37:23,261] [INFO] [RANK 0]   deepspeed_activation_checkpointing  True
[2025-03-17 02:37:23,261] [INFO] [RANK 0]   master_ip .................... 3vvvmc4cgetnp-0
[2025-03-17 02:37:23,261] [INFO] [RANK 0]   master_port .................. 50004
[2025-03-17 02:37:23,274] [INFO] [RANK 0]   log_config ................... [{'model': {'scale_factor': 0.7, 'disable_first_stage_autocast': True, 'latent_input': False, 'noised_image_input': True, 'noised_image_all_concat': False, 'noised_image_dropout': 0.05, 'not_trainable_prefixes': ['ref_model'], 'train_prefix': {'model': ['audio']}, 'log_keys': ['txt'], 'denoiser_config': {'target': 'sgm.modules.diffusionmodules.denoiser.DiscreteDenoiser', 'params': {'num_idx': 1000, 'quantize_c_noise': False, 'weighting_config': {'target': 'sgm.modules.diffusionmodules.denoiser_weighting.EpsWeighting'}, 'scaling_config': {'target': 'sgm.modules.diffusionmodules.denoiser_scaling.VideoScaling'}, 'discretization_config': {'target': 'sgm.modules.diffusionmodules.discretizer.ZeroSNRDDPMDiscretization', 'params': {'shift_scale': 1.0}}}}, 'network_config': {'target': 'dit_video_concat.DiffusionTransformer', 'params': {'time_embed_dim': 512, 'elementwise_affine': True, 'num_frames': 49, 'time_compressed_rate': 4, 'latent_width': 90, 'latent_height': 60, 'num_layers': 42, 'patch_size': 2, 'in_channels': 32, 'out_channels': 16, 'hidden_size': 3072, 'adm_in_channels': 256, 'num_attention_heads': 48, 'add_audio_module': True, 'transformer_args': {'checkpoint_activations': True, 'vocab_size': 1, 'max_sequence_length': 64, 'layernorm_order': 'pre', 'skip_init': False, 'model_parallel_size': 1, 'is_decoder': False, 'cross_attn_hidden_size': 768, 'face_cross_attn_hidden_size': 1024}, 'modules': {'pos_embed_config': {'target': 'dit_video_concat.Rotary3DPositionEmbeddingMixin', 'params': {'learnable_pos_embed': True, 'hidden_size_head': 64, 'text_length': 226}}, 'patch_embed_config': {'target': 'dit_video_concat.ImagePatchEmbeddingMixin', 'params': {'text_hidden_size': 4096}}, 'adaln_layer_config': {'target': 'dit_video_concat.AdaLNMixin', 'params': {'qk_ln': True}}, 'final_layer_config': {'target': 'dit_video_concat.FinalLayerMixin'}}}}, 'ref_network_config': {'target': 'ref_dit_video_concat.DiffusionTransformer', 'params': {'time_embed_dim': 512, 'elementwise_affine': True, 'num_frames': 49, 'time_compressed_rate': 4, 'latent_width': 90, 'latent_height': 60, 'num_layers': 42, 'patch_size': 2, 'in_channels': 32, 'out_channels': 16, 'hidden_size': 3072, 'adm_in_channels': 256, 'num_attention_heads': 48, 'transformer_args': {'checkpoint_activations': False, 'vocab_size': 1, 'max_sequence_length': 64, 'layernorm_order': 'pre', 'skip_init': False, 'model_parallel_size': 1, 'is_decoder': False}, 'modules': {'pos_embed_config': {'target': 'ref_dit_video_concat.Rotary3DPositionEmbeddingMixin', 'params': {'learnable_pos_embed': True, 'hidden_size_head': 64, 'text_length': 226}}, 'patch_embed_config': {'target': 'ref_dit_video_concat.ImagePatchEmbeddingMixin', 'params': {'text_hidden_size': 4096}}, 'adaln_layer_config': {'target': 'ref_dit_video_concat.AdaLNMixin', 'params': {'qk_ln': True}}, 'final_layer_config': {'target': 'ref_dit_video_concat.FinalLayerMixin'}}}}, 'conditioner_config': {'target': 'sgm.modules.GeneralConditioner', 'params': {'emb_models': [{'is_trainable': False, 'input_key': 'txt', 'ucg_rate': 0.1, 'target': 'sgm.modules.encoders.modules.FrozenT5Embedder', 'params': {'model_dir': './pretrained_models/t5-v1_1-xxl', 'max_length': 226}}]}}, 'first_stage_config': {'target': 'vae_modules.autoencoder.VideoAutoencoderInferenceWrapper', 'params': {'cp_size': 1, 'ckpt_path': './pretrained_models/cogvideox-5b-i2v-sat/vae/3d-vae.pt', 'ignore_keys': ['loss'], 'loss_config': {'target': 'torch.nn.Identity'}, 'regularizer_config': {'target': 'vae_modules.regularizers.DiagonalGaussianRegularizer'}, 'encoder_config': {'target': 'vae_modules.cp_enc_dec.ContextParallelEncoder3D', 'params': {'double_z': True, 'z_channels': 16, 'resolution': 256, 'in_channels': 3, 'out_ch': 3, 'ch': 128, 'ch_mult': [1, 2, 2, 4], 'attn_resolutions': [], 'num_res_blocks': 3, 'dropout': 0.0, 'gather_norm': True}}, 'decoder_config': {'target': 'vae_modules.cp_enc_dec.ContextParallelDecoder3D', 'params': {'double_z': True, 'z_channels': 16, 'resolution': 256, 'in_channels': 3, 'out_ch': 3, 'ch': 128, 'ch_mult': [1, 2, 2, 4], 'attn_resolutions': [], 'num_res_blocks': 3, 'dropout': 0.0, 'gather_norm': True}}}}, 'loss_fn_config': {'target': 'sgm.modules.diffusionmodules.loss.VideoDiffusionLoss', 'params': {'batch2model_keys': ['audio_emb', 'face_emb'], 'fixed_frames': 0, 'offset_noise_level': 0, 'sigma_sampler_config': {'target': 'sgm.modules.diffusionmodules.sigma_sampling.DiscreteSampling', 'params': {'uniform_sampling': True, 'num_idx': 1000, 'discretization_config': {'target': 'sgm.modules.diffusionmodules.discretizer.ZeroSNRDDPMDiscretization', 'params': {'shift_scale': 1.0}}}}}}, 'sampler_config': {'target': 'sgm.modules.diffusionmodules.sampling.VPSDEDPMPP2MSampler', 'params': {'fixed_frames': 0, 'num_steps': 50, 'verbose': True, 'discretization_config': {'target': 'sgm.modules.diffusionmodules.discretizer.ZeroSNRDDPMDiscretization', 'params': {'shift_scale': 1.0}}, 'guider_config': {'target': 'sgm.modules.diffusionmodules.guiders.DynamicCFG', 'params': {'scale': 6, 'exp': 5, 'num_steps': 50}}}}}}, {'args': {'checkpoint_activations': True, 'model_parallel_size': 1, 'experiment_name': 'train-stage-2', 'mode': 'finetune', 'load': 'pretrained_models/hallo3', 'no_load_rng': True, 'train_iters': 30000, 'eval_iters': 1, 'eval_interval': 30000, 'eval_batch_size': 1, 'save': 'stage-2', 'save_interval': 250, 'log_interval': 1, 'train_data': ['./data/shunian-hallo3-22k.json'], 'valid_data': ['./data/hallo3-55f.json'], 'split': '1,0,0', 'num_workers': 1, 'force_train': True, 'only_log_video_latents': True}, 'data': {'target': 'data_video.Stage2_SFTDataset', 'params': {'video_size': [480, 720], 'fps': 8, 'max_num_frames': 49, 'skip_frms_num': 3.0}}, 'deepspeed': {'train_micro_batch_size_per_gpu': 1, 'gradient_accumulation_steps': 1, 'steps_per_print': 50, 'gradient_clipping': 0.1, 'zero_optimization': {'stage': 2, 'cpu_offload': False, 'contiguous_gradients': False, 'overlap_comm': True, 'reduce_scatter': True, 'reduce_bucket_size': 1000000000, 'allgather_bucket_size': 1000000000, 'load_from_fp32_weights': False}, 'zero_allow_untested_optimizer': True, 'bf16': {'enabled': True}, 'fp16': {'enabled': False}, 'loss_scale': 0, 'loss_scale_window': 400, 'hysteresis': 2, 'min_loss_scale': 1, 'optimizer': {'type': 'sat.ops.FusedEmaAdam', 'params': {'lr': '1e-5', 'betas': [0.9, 0.95], 'eps': '1e-8', 'weight_decay': '1e-4'}}, 'activation_checkpointing': {'partition_activations': False, 'contiguous_memory_optimization': False}, 'wall_clock_breakdown': False}}]
[2025-03-17 02:37:23,277] [INFO] [RANK 0]   do_train ..................... True
[2025-03-17 02:37:23,277] [INFO] [RANK 0]   val_last_shape ............... []
[2025-03-17 02:37:23,277] [INFO] [RANK 0]   val_drop_number .............. 0
[2025-03-17 02:37:23,277] [INFO] [RANK 0]   do_valid ..................... True
[2025-03-17 02:37:23,277] [INFO] [RANK 0]   do_test ...................... False
[2025-03-17 02:37:23,277] [INFO] [RANK 0]   iteration .................... 0
wandb: Currently logged in as: hhj2950526463 (hhj2950526463-sun-yat-sen-university). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.19.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.5
wandb: Run data is saved locally in wandb/run-20250317_023732-xaird4r1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run train-stage-2-03-17-02-27
wandb: ⭐️ View project at https://wandb.ai/hhj2950526463-sun-yat-sen-university/default_project
wandb: 🚀 View run at https://wandb.ai/hhj2950526463-sun-yat-sen-university/default_project/runs/xaird4r1
[2025-03-17 02:39:59,802] [INFO] [RANK 0]  iteration        1/   30000 | elapsed time per iteration (ms): 125780.2 | learning rate 6.667E-08 | total loss 1.380026E-01 | loss 1.380026E-01 |speed 0.48 samples/(min*GPU)
[2025-03-17 02:39:59,827] [INFO] [RANK 0] after 1 iterations memory (MB) | allocated: 46568.955078125 | max allocated: 64515.869140625 | cached: 57278.0 | max cached: 70396.0
[2025-03-17 02:39:59,828] [INFO] [RANK 0] time (ms) | forward: 83691.03 | backward: 41476.66 | allreduce: 0.00 | optimizer: 592.34 | data loader: 14550.13
[2025-03-17 02:40:59,808] [INFO] [RANK 0]  iteration        2/   30000 | elapsed time per iteration (ms): 60005.9 | learning rate 1.000E-07 | total loss 7.681612E-02 | loss 7.681612E-02 |speed 1.00 samples/(min*GPU)
[2025-03-17 02:40:59,813] [INFO] [RANK 0] time (ms) | forward: 39979.35 | backward: 17921.64 | allreduce: 0.00 | optimizer: 54.47 | data loader: 5.47
[2025-03-17 02:41:59,049] [INFO] [RANK 0]  iteration        3/   30000 | elapsed time per iteration (ms): 59241.7 | learning rate 1.333E-07 | total loss 7.224033E-02 | loss 7.224033E-02 |speed 1.01 samples/(min*GPU)
[2025-03-17 02:41:59,203] [INFO] [RANK 0] time (ms) | forward: 36181.23 | backward: 16446.65 | allreduce: 0.00 | optimizer: 117.83 | data loader: 0.98
[2025-03-17 02:43:01,345] [INFO] [RANK 0]  iteration        4/   30000 | elapsed time per iteration (ms): 62295.7 | learning rate 1.667E-07 | total loss 1.294400E-01 | loss 1.294400E-01 |speed 0.96 samples/(min*GPU)
[2025-03-17 02:43:01,352] [INFO] [RANK 0] time (ms) | forward: 43157.09 | backward: 16610.44 | allreduce: 0.00 | optimizer: 224.92 | data loader: 0.81
[2025-03-17 02:44:08,022] [INFO] [RANK 0]  iteration        5/   30000 | elapsed time per iteration (ms): 66676.5 | learning rate 2.000E-07 | total loss 1.050591E-01 | loss 1.050591E-01 |speed 0.90 samples/(min*GPU)
[2025-03-17 02:44:08,040] [INFO] [RANK 0] time (ms) | forward: 41255.43 | backward: 19654.49 | allreduce: 0.00 | optimizer: 137.65 | data loader: 1.32
[2025-03-17 02:45:08,584] [INFO] [RANK 0]  iteration        6/   30000 | elapsed time per iteration (ms): 60559.6 | learning rate 2.333E-07 | total loss 8.778766E-02 | loss 8.778766E-02 |speed 0.99 samples/(min*GPU)
[2025-03-17 02:45:08,595] [INFO] [RANK 0] time (ms) | forward: 35772.05 | backward: 19074.09 | allreduce: 0.00 | optimizer: 122.63 | data loader: 2.82
[2025-03-17 02:46:11,639] [INFO] [RANK 0]  iteration        7/   30000 | elapsed time per iteration (ms): 63057.7 | learning rate 2.667E-07 | total loss 7.364516E-02 | loss 7.364516E-02 |speed 0.95 samples/(min*GPU)
[2025-03-17 02:46:11,775] [INFO] [RANK 0] time (ms) | forward: 45887.69 | backward: 16781.61 | allreduce: 0.00 | optimizer: 101.41 | data loader: 3.93
[2025-03-17 02:47:14,307] [INFO] [RANK 0]  iteration        8/   30000 | elapsed time per iteration (ms): 62667.9 | learning rate 3.000E-07 | total loss 6.869838E-02 | loss 6.869838E-02 |speed 0.96 samples/(min*GPU)
[2025-03-17 02:47:14,316] [INFO] [RANK 0] time (ms) | forward: 46249.82 | backward: 15841.59 | allreduce: 0.00 | optimizer: 264.35 | data loader: 6.11
[2025-03-17 02:48:15,944] [INFO] [RANK 0]  iteration        9/   30000 | elapsed time per iteration (ms): 61636.3 | learning rate 3.333E-07 | total loss 6.379016E-02 | loss 6.379016E-02 |speed 0.97 samples/(min*GPU)
[2025-03-17 02:48:16,124] [INFO] [RANK 0] time (ms) | forward: 41365.96 | backward: 18735.81 | allreduce: 0.00 | optimizer: 111.95 | data loader: 1.42
[2025-03-17 02:49:14,116] [INFO] [RANK 0]  iteration       10/   30000 | elapsed time per iteration (ms): 58173.0 | learning rate 3.667E-07 | total loss 9.446345E-02 | loss 9.446345E-02 |speed 1.03 samples/(min*GPU)
[2025-03-17 02:49:14,120] [INFO] [RANK 0] time (ms) | forward: 39808.67 | backward: 17564.58 | allreduce: 0.00 | optimizer: 157.92 | data loader: 2.87
[2025-03-17 02:50:14,406] [INFO] [RANK 0]  iteration       11/   30000 | elapsed time per iteration (ms): 60290.1 | learning rate 4.000E-07 | total loss 6.876227E-02 | loss 6.876227E-02 |speed 1.00 samples/(min*GPU)
[2025-03-17 02:50:14,413] [INFO] [RANK 0] time (ms) | forward: 38075.09 | backward: 16930.82 | allreduce: 0.00 | optimizer: 165.88 | data loader: 1.90
[2025-03-17 02:51:16,486] [INFO] [RANK 0]  iteration       12/   30000 | elapsed time per iteration (ms): 62079.6 | learning rate 4.333E-07 | total loss 8.226323E-02 | loss 8.226323E-02 |speed 0.97 samples/(min*GPU)
[2025-03-17 02:51:16,535] [INFO] [RANK 0] time (ms) | forward: 42419.62 | backward: 14878.96 | allreduce: 0.00 | optimizer: 176.31 | data loader: 1.60
[2025-03-17 02:52:19,797] [INFO] [RANK 0]  iteration       13/   30000 | elapsed time per iteration (ms): 63310.4 | learning rate 4.667E-07 | total loss 7.399286E-02 | loss 7.399286E-02 |speed 0.95 samples/(min*GPU)
[2025-03-17 02:52:19,814] [INFO] [RANK 0] time (ms) | forward: 40782.86 | backward: 18727.27 | allreduce: 0.00 | optimizer: 104.81 | data loader: 3.06
[2025-03-17 02:53:19,721] [INFO] [RANK 0]  iteration       14/   30000 | elapsed time per iteration (ms): 59924.2 | learning rate 5.000E-07 | total loss 9.668472E-02 | loss 9.668472E-02 |speed 1.00 samples/(min*GPU)
[2025-03-17 02:53:19,728] [INFO] [RANK 0] time (ms) | forward: 38816.43 | backward: 17928.66 | allreduce: 0.00 | optimizer: 49.72 | data loader: 2.02
[2025-03-17 02:54:18,232] [INFO] [RANK 0]  iteration       15/   30000 | elapsed time per iteration (ms): 58511.2 | learning rate 5.000E-07 | total loss 7.913011E-02 | loss 7.913011E-02 |speed 1.03 samples/(min*GPU)
[2025-03-17 02:54:18,386] [INFO] [RANK 0] time (ms) | forward: 40364.25 | backward: 15485.15 | allreduce: 0.00 | optimizer: 110.11 | data loader: 1.11
[2025-03-17 02:55:20,750] [INFO] [RANK 0]  iteration       16/   30000 | elapsed time per iteration (ms): 62518.1 | learning rate 5.000E-07 | total loss 7.421975E-02 | loss 7.421975E-02 |speed 0.96 samples/(min*GPU)
[2025-03-17 02:55:20,762] [INFO] [RANK 0] time (ms) | forward: 41808.96 | backward: 16720.04 | allreduce: 0.00 | optimizer: 114.90 | data loader: 1.93
[2025-03-17 02:56:26,387] [INFO] [RANK 0]  iteration       17/   30000 | elapsed time per iteration (ms): 65636.9 | learning rate 5.000E-07 | total loss 1.052458E-01 | loss 1.052458E-01 |speed 0.91 samples/(min*GPU)
[2025-03-17 02:56:26,399] [INFO] [RANK 0] time (ms) | forward: 41687.46 | backward: 20569.57 | allreduce: 0.00 | optimizer: 165.80 | data loader: 2.52
[2025-03-17 02:57:26,457] [INFO] [RANK 0]  iteration       18/   30000 | elapsed time per iteration (ms): 60069.5 | learning rate 5.000E-07 | total loss 9.166594E-02 | loss 9.166594E-02 |speed 1.00 samples/(min*GPU)
[2025-03-17 02:57:26,464] [INFO] [RANK 0] time (ms) | forward: 40021.17 | backward: 18665.02 | allreduce: 0.00 | optimizer: 70.92 | data loader: 1.89
[2025-03-17 02:58:24,258] [INFO] [RANK 0]  iteration       19/   30000 | elapsed time per iteration (ms): 57801.3 | learning rate 5.000E-07 | total loss 1.069765E-01 | loss 1.069765E-01 |speed 1.04 samples/(min*GPU)
[2025-03-17 02:58:24,267] [INFO] [RANK 0] time (ms) | forward: 38537.50 | backward: 15882.83 | allreduce: 0.00 | optimizer: 119.15 | data loader: 3.76
[2025-03-17 02:59:25,470] [INFO] [RANK 0]  iteration       20/   30000 | elapsed time per iteration (ms): 61212.3 | learning rate 5.000E-07 | total loss 7.242329E-02 | loss 7.242329E-02 |speed 0.98 samples/(min*GPU)
[2025-03-17 02:59:25,477] [INFO] [RANK 0] time (ms) | forward: 40822.46 | backward: 16730.84 | allreduce: 0.00 | optimizer: 99.13 | data loader: 0.95
[2025-03-17 03:00:29,585] [INFO] [RANK 0]  iteration       21/   30000 | elapsed time per iteration (ms): 64114.8 | learning rate 5.000E-07 | total loss 7.667682E-02 | loss 7.667682E-02 |speed 0.94 samples/(min*GPU)
[2025-03-17 03:00:29,593] [INFO] [RANK 0] time (ms) | forward: 40167.97 | backward: 18329.57 | allreduce: 0.00 | optimizer: 248.27 | data loader: 0.53
[2025-03-17 03:01:32,862] [INFO] [RANK 0]  iteration       22/   30000 | elapsed time per iteration (ms): 63276.7 | learning rate 5.000E-07 | total loss 1.418104E-01 | loss 1.418104E-01 |speed 0.95 samples/(min*GPU)
[2025-03-17 03:01:32,886] [INFO] [RANK 0] time (ms) | forward: 37040.83 | backward: 19211.21 | allreduce: 0.00 | optimizer: 122.57 | data loader: 2.02
[2025-03-17 03:02:36,063] [INFO] [RANK 0]  iteration       23/   30000 | elapsed time per iteration (ms): 63201.5 | learning rate 5.000E-07 | total loss 6.797120E-02 | loss 6.797120E-02 |speed 0.95 samples/(min*GPU)
[2025-03-17 03:02:36,069] [INFO] [RANK 0] time (ms) | forward: 35217.01 | backward: 16452.51 | allreduce: 0.00 | optimizer: 64.46 | data loader: 0.48
[2025-03-17 03:03:39,336] [INFO] [RANK 0]  iteration       24/   30000 | elapsed time per iteration (ms): 63271.9 | learning rate 5.000E-07 | total loss 8.615824E-02 | loss 8.615824E-02 |speed 0.95 samples/(min*GPU)
[2025-03-17 03:03:39,345] [INFO] [RANK 0] time (ms) | forward: 41205.69 | backward: 16067.49 | allreduce: 0.00 | optimizer: 110.27 | data loader: 2.31
[2025-03-17 03:04:42,970] [INFO] [RANK 0]  iteration       25/   30000 | elapsed time per iteration (ms): 63634.9 | learning rate 5.000E-07 | total loss 7.838143E-02 | loss 7.838143E-02 |speed 0.94 samples/(min*GPU)
[2025-03-17 03:04:42,997] [INFO] [RANK 0] time (ms) | forward: 41833.24 | backward: 17430.62 | allreduce: 0.00 | optimizer: 218.97 | data loader: 0.81
[2025-03-17 03:05:43,607] [INFO] [RANK 0]  iteration       26/   30000 | elapsed time per iteration (ms): 60636.2 | learning rate 5.000E-07 | total loss 8.372878E-02 | loss 8.372878E-02 |speed 0.99 samples/(min*GPU)
[2025-03-17 03:05:43,612] [INFO] [RANK 0] time (ms) | forward: 35804.32 | backward: 17911.92 | allreduce: 0.00 | optimizer: 96.24 | data loader: 3.01
[2025-03-17 03:06:47,748] [INFO] [RANK 0]  iteration       27/   30000 | elapsed time per iteration (ms): 64141.7 | learning rate 5.000E-07 | total loss 1.458807E-01 | loss 1.458807E-01 |speed 0.94 samples/(min*GPU)
[2025-03-17 03:06:47,754] [INFO] [RANK 0] time (ms) | forward: 42990.76 | backward: 16755.46 | allreduce: 0.00 | optimizer: 94.61 | data loader: 2.25
[2025-03-17 03:07:54,133] [INFO] [RANK 0]  iteration       28/   30000 | elapsed time per iteration (ms): 66383.9 | learning rate 5.000E-07 | total loss 7.076983E-02 | loss 7.076983E-02 |speed 0.90 samples/(min*GPU)
[2025-03-17 03:07:54,200] [INFO] [RANK 0] time (ms) | forward: 45041.97 | backward: 19422.04 | allreduce: 0.00 | optimizer: 58.06 | data loader: 0.44
[2025-03-17 03:08:54,494] [INFO] [RANK 0]  iteration       29/   30000 | elapsed time per iteration (ms): 60360.7 | learning rate 5.000E-07 | total loss 1.105851E-01 | loss 1.105851E-01 |speed 0.99 samples/(min*GPU)
[2025-03-17 03:08:54,508] [INFO] [RANK 0] time (ms) | forward: 37807.79 | backward: 17925.09 | allreduce: 0.00 | optimizer: 141.79 | data loader: 1.41
[2025-03-17 03:09:55,031] [INFO] [RANK 0]  iteration       30/   30000 | elapsed time per iteration (ms): 60538.0 | learning rate 5.000E-07 | total loss 8.925214E-02 | loss 8.925214E-02 |speed 0.99 samples/(min*GPU)
[2025-03-17 03:09:55,126] [INFO] [RANK 0] time (ms) | forward: 39706.23 | backward: 17174.27 | allreduce: 0.00 | optimizer: 213.69 | data loader: 1.09
[2025-03-17 03:11:00,301] [INFO] [RANK 0]  iteration       31/   30000 | elapsed time per iteration (ms): 65269.6 | learning rate 5.000E-07 | total loss 9.065435E-02 | loss 9.065435E-02 |speed 0.92 samples/(min*GPU)
[2025-03-17 03:11:00,302] [INFO] [RANK 0] time (ms) | forward: 42597.41 | backward: 19419.13 | allreduce: 0.00 | optimizer: 104.15 | data loader: 1.90
[2025-03-17 03:12:00,826] [INFO] [RANK 0]  iteration       32/   30000 | elapsed time per iteration (ms): 60525.6 | learning rate 5.000E-07 | total loss 7.143440E-02 | loss 7.143440E-02 |speed 0.99 samples/(min*GPU)
[2025-03-17 03:12:00,855] [INFO] [RANK 0] time (ms) | forward: 35240.99 | backward: 18765.62 | allreduce: 0.00 | optimizer: 126.14 | data loader: 0.44
[2025-03-17 03:12:58,942] [INFO] [RANK 0]  iteration       33/   30000 | elapsed time per iteration (ms): 58115.1 | learning rate 5.000E-07 | total loss 7.147060E-02 | loss 7.147060E-02 |speed 1.03 samples/(min*GPU)
[2025-03-17 03:12:58,947] [INFO] [RANK 0] time (ms) | forward: 32880.79 | backward: 17203.70 | allreduce: 0.00 | optimizer: 108.90 | data loader: 2.43
[2025-03-17 03:13:58,037] [INFO] [RANK 0]  iteration       34/   30000 | elapsed time per iteration (ms): 59095.0 | learning rate 5.000E-07 | total loss 1.048410E-01 | loss 1.048410E-01 |speed 1.02 samples/(min*GPU)
[2025-03-17 03:13:58,086] [INFO] [RANK 0] time (ms) | forward: 38362.66 | backward: 15967.20 | allreduce: 0.00 | optimizer: 120.80 | data loader: 2.89
[2025-03-17 03:15:03,681] [INFO] [RANK 0]  iteration       35/   30000 | elapsed time per iteration (ms): 65644.5 | learning rate 5.000E-07 | total loss 7.913907E-02 | loss 7.913907E-02 |speed 0.91 samples/(min*GPU)
[2025-03-17 03:15:03,683] [INFO] [RANK 0] time (ms) | forward: 45117.51 | backward: 16899.97 | allreduce: 0.00 | optimizer: 83.72 | data loader: 4.43
[2025-03-17 03:16:05,811] [INFO] [RANK 0]  iteration       36/   30000 | elapsed time per iteration (ms): 62129.7 | learning rate 5.000E-07 | total loss 1.341122E-01 | loss 1.341122E-01 |speed 0.97 samples/(min*GPU)
[2025-03-17 03:16:05,826] [INFO] [RANK 0] time (ms) | forward: 41219.93 | backward: 20308.66 | allreduce: 0.00 | optimizer: 168.75 | data loader: 0.30
[2025-03-17 03:17:05,880] [INFO] [RANK 0]  iteration       37/   30000 | elapsed time per iteration (ms): 60022.9 | learning rate 5.000E-07 | total loss 6.988159E-02 | loss 6.988159E-02 |speed 1.00 samples/(min*GPU)
[2025-03-17 03:17:05,958] [INFO] [RANK 0] time (ms) | forward: 34903.75 | backward: 18616.02 | allreduce: 0.00 | optimizer: 103.27 | data loader: 0.82
[2025-03-17 03:18:08,920] [INFO] [RANK 0]  iteration       38/   30000 | elapsed time per iteration (ms): 63086.4 | learning rate 5.000E-07 | total loss 7.359318E-02 | loss 7.359318E-02 |speed 0.95 samples/(min*GPU)
[2025-03-17 03:18:08,934] [INFO] [RANK 0] time (ms) | forward: 39675.25 | backward: 16172.97 | allreduce: 0.00 | optimizer: 124.59 | data loader: 0.93
[2025-03-17 03:19:13,137] [INFO] [RANK 0]  iteration       39/   30000 | elapsed time per iteration (ms): 64217.1 | learning rate 5.000E-07 | total loss 9.175147E-02 | loss 9.175147E-02 |speed 0.93 samples/(min*GPU)
[2025-03-17 03:19:13,289] [INFO] [RANK 0] time (ms) | forward: 44261.24 | backward: 16303.27 | allreduce: 0.00 | optimizer: 48.49 | data loader: 7.52
[2025-03-17 03:20:19,026] [INFO] [RANK 0]  iteration       40/   30000 | elapsed time per iteration (ms): 65888.4 | learning rate 5.000E-07 | total loss 6.762700E-02 | loss 6.762700E-02 |speed 0.91 samples/(min*GPU)
[2025-03-17 03:20:19,220] [INFO] [RANK 0] time (ms) | forward: 41936.57 | backward: 19806.27 | allreduce: 0.00 | optimizer: 76.39 | data loader: 0.97
[2025-03-17 03:21:17,040] [INFO] [RANK 0]  iteration       41/   30000 | elapsed time per iteration (ms): 58014.0 | learning rate 5.000E-07 | total loss 1.342308E-01 | loss 1.342308E-01 |speed 1.03 samples/(min*GPU)
[2025-03-17 03:21:17,115] [INFO] [RANK 0] time (ms) | forward: 32005.55 | backward: 18494.43 | allreduce: 0.00 | optimizer: 134.22 | data loader: 1.84
[2025-03-17 03:22:16,290] [INFO] [RANK 0]  iteration       42/   30000 | elapsed time per iteration (ms): 59241.2 | learning rate 5.000E-07 | total loss 6.804673E-02 | loss 6.804673E-02 |speed 1.01 samples/(min*GPU)
[2025-03-17 03:22:16,321] [INFO] [RANK 0] time (ms) | forward: 39647.58 | backward: 14936.78 | allreduce: 0.00 | optimizer: 173.46 | data loader: 10.13
[2025-03-17 03:23:21,218] [INFO] [RANK 0]  iteration       43/   30000 | elapsed time per iteration (ms): 64936.3 | learning rate 5.000E-07 | total loss 7.195623E-02 | loss 7.195623E-02 |speed 0.92 samples/(min*GPU)
[2025-03-17 03:23:21,228] [INFO] [RANK 0] time (ms) | forward: 43191.55 | backward: 17645.55 | allreduce: 0.00 | optimizer: 143.07 | data loader: 1.02
[2025-03-17 03:24:28,626] [INFO] [RANK 0]  iteration       44/   30000 | elapsed time per iteration (ms): 67408.4 | learning rate 5.000E-07 | total loss 7.789496E-02 | loss 7.789496E-02 |speed 0.89 samples/(min*GPU)
[2025-03-17 03:24:28,797] [INFO] [RANK 0] time (ms) | forward: 44401.16 | backward: 20130.86 | allreduce: 0.00 | optimizer: 115.31 | data loader: 1.56
[2025-03-17 03:25:30,172] [INFO] [RANK 0]  iteration       45/   30000 | elapsed time per iteration (ms): 61545.4 | learning rate 5.000E-07 | total loss 8.231224E-02 | loss 8.231224E-02 |speed 0.97 samples/(min*GPU)
[2025-03-17 03:25:30,177] [INFO] [RANK 0] time (ms) | forward: 41847.29 | backward: 18103.62 | allreduce: 0.00 | optimizer: 133.94 | data loader: 1.33
[2025-03-17 03:26:28,981] [INFO] [RANK 0]  iteration       46/   30000 | elapsed time per iteration (ms): 58809.6 | learning rate 5.000E-07 | total loss 6.534215E-02 | loss 6.534215E-02 |speed 1.02 samples/(min*GPU)
[2025-03-17 03:26:29,000] [INFO] [RANK 0] time (ms) | forward: 38365.15 | backward: 16772.09 | allreduce: 0.00 | optimizer: 49.57 | data loader: 55.19
[2025-03-17 03:27:35,115] [INFO] [RANK 0]  iteration       47/   30000 | elapsed time per iteration (ms): 66134.4 | learning rate 5.000E-07 | total loss 9.421797E-02 | loss 9.421797E-02 |speed 0.91 samples/(min*GPU)
[2025-03-17 03:27:35,120] [INFO] [RANK 0] time (ms) | forward: 48057.04 | backward: 17266.40 | allreduce: 0.00 | optimizer: 86.30 | data loader: 1.73
[2025-03-17 03:28:43,880] [INFO] [RANK 0]  iteration       48/   30000 | elapsed time per iteration (ms): 68765.0 | learning rate 5.000E-07 | total loss 7.203051E-02 | loss 7.203051E-02 |speed 0.87 samples/(min*GPU)
[2025-03-17 03:28:43,885] [INFO] [RANK 0] time (ms) | forward: 47303.28 | backward: 20278.34 | allreduce: 0.00 | optimizer: 60.37 | data loader: 3.21
[2025-03-17 03:29:44,592] [INFO] [RANK 0]  iteration       49/   30000 | elapsed time per iteration (ms): 60710.6 | learning rate 5.000E-07 | total loss 9.773209E-02 | loss 9.773209E-02 |speed 0.99 samples/(min*GPU)
[2025-03-17 03:29:44,612] [INFO] [RANK 0] time (ms) | forward: 40346.20 | backward: 17513.53 | allreduce: 0.00 | optimizer: 183.14 | data loader: 2.49
[2025-03-17 03:30:46,180] [INFO] [logging.py:128:log_dist] [Rank 0] step=50, skipped=0, lr=[5.000000000000001e-07, 5.000000000000001e-07], mom=[[0.9, 0.95], [0.9, 0.95]]
[2025-03-17 03:30:46,206] [INFO] [RANK 0]  iteration       50/   30000 | elapsed time per iteration (ms): 61615.2 | learning rate 5.000E-07 | total loss 7.022890E-02 | loss 7.022890E-02 |speed 0.97 samples/(min*GPU)
[2025-03-17 03:30:46,215] [INFO] [RANK 0] time (ms) | forward: 38981.78 | backward: 15935.17 | allreduce: 0.00 | optimizer: 58.70 | data loader: 0.60
[2025-03-17 03:31:55,261] [INFO] [RANK 0]  iteration       51/   30000 | elapsed time per iteration (ms): 69054.5 | learning rate 5.000E-07 | total loss 1.102795E-01 | loss 1.102795E-01 |speed 0.87 samples/(min*GPU)
[2025-03-17 03:31:55,271] [INFO] [RANK 0] time (ms) | forward: 43433.34 | backward: 19872.49 | allreduce: 0.00 | optimizer: 149.46 | data loader: 4.42
[2025-03-17 03:32:57,992] [INFO] [RANK 0]  iteration       52/   30000 | elapsed time per iteration (ms): 62731.0 | learning rate 5.000E-07 | total loss 6.593950E-02 | loss 6.593950E-02 |speed 0.96 samples/(min*GPU)
[2025-03-17 03:32:58,008] [INFO] [RANK 0] time (ms) | forward: 43266.16 | backward: 16868.41 | allreduce: 0.00 | optimizer: 89.31 | data loader: 0.44
[2025-03-17 03:34:01,332] [INFO] [RANK 0]  iteration       53/   30000 | elapsed time per iteration (ms): 63340.3 | learning rate 5.000E-07 | total loss 9.575514E-02 | loss 9.575514E-02 |speed 0.95 samples/(min*GPU)
[2025-03-17 03:34:01,347] [INFO] [RANK 0] time (ms) | forward: 37772.57 | backward: 16947.04 | allreduce: 0.00 | optimizer: 380.56 | data loader: 0.92
[2025-03-17 03:35:06,098] [INFO] [RANK 0]  iteration       54/   30000 | elapsed time per iteration (ms): 64765.9 | learning rate 5.000E-07 | total loss 6.555314E-02 | loss 6.555314E-02 |speed 0.93 samples/(min*GPU)
[2025-03-17 03:35:06,118] [INFO] [RANK 0] time (ms) | forward: 39885.30 | backward: 15998.04 | allreduce: 0.00 | optimizer: 165.85 | data loader: 4.30
[2025-03-17 03:36:14,836] [INFO] [RANK 0]  iteration       55/   30000 | elapsed time per iteration (ms): 68737.6 | learning rate 5.000E-07 | total loss 6.585111E-02 | loss 6.585111E-02 |speed 0.87 samples/(min*GPU)
[2025-03-17 03:36:14,859] [INFO] [RANK 0] time (ms) | forward: 48566.19 | backward: 19209.57 | allreduce: 0.00 | optimizer: 118.27 | data loader: 0.65
[2025-03-17 03:37:15,409] [INFO] [RANK 0]  iteration       56/   30000 | elapsed time per iteration (ms): 60573.1 | learning rate 5.000E-07 | total loss 7.098570E-02 | loss 7.098570E-02 |speed 0.99 samples/(min*GPU)
[2025-03-17 03:37:15,425] [INFO] [RANK 0] time (ms) | forward: 41931.90 | backward: 18450.31 | allreduce: 0.00 | optimizer: 107.61 | data loader: 2.06
[2025-03-17 03:38:20,894] [INFO] [RANK 0]  iteration       57/   30000 | elapsed time per iteration (ms): 65485.9 | learning rate 5.000E-07 | total loss 8.023363E-02 | loss 8.023363E-02 |speed 0.92 samples/(min*GPU)
[2025-03-17 03:38:20,900] [INFO] [RANK 0] time (ms) | forward: 41199.21 | backward: 17011.01 | allreduce: 0.00 | optimizer: 96.82 | data loader: 0.81
[2025-03-17 03:39:30,305] [INFO] [RANK 0]  iteration       58/   30000 | elapsed time per iteration (ms): 69386.5 | learning rate 5.000E-07 | total loss 8.090990E-02 | loss 8.090990E-02 |speed 0.86 samples/(min*GPU)
[2025-03-17 03:39:30,334] [INFO] [RANK 0] time (ms) | forward: 44997.56 | backward: 21105.50 | allreduce: 0.00 | optimizer: 158.88 | data loader: 2.27
[2025-03-17 03:40:31,129] [INFO] [RANK 0]  iteration       59/   30000 | elapsed time per iteration (ms): 60847.7 | learning rate 5.000E-07 | total loss 7.634687E-02 | loss 7.634687E-02 |speed 0.99 samples/(min*GPU)
[2025-03-17 03:40:31,136] [INFO] [RANK 0] time (ms) | forward: 39369.06 | backward: 19354.39 | allreduce: 0.00 | optimizer: 99.51 | data loader: 6.81
[2025-03-17 03:41:30,296] [INFO] [RANK 0]  iteration       60/   30000 | elapsed time per iteration (ms): 59167.8 | learning rate 5.000E-07 | total loss 7.626916E-02 | loss 7.626916E-02 |speed 1.01 samples/(min*GPU)
[2025-03-17 03:41:30,304] [INFO] [RANK 0] time (ms) | forward: 41772.19 | backward: 16334.10 | allreduce: 0.00 | optimizer: 180.42 | data loader: 0.85
[2025-03-17 03:42:38,320] [INFO] [RANK 0]  iteration       61/   30000 | elapsed time per iteration (ms): 68023.8 | learning rate 5.000E-07 | total loss 7.556374E-02 | loss 7.556374E-02 |speed 0.88 samples/(min*GPU)
[2025-03-17 03:42:38,332] [INFO] [RANK 0] time (ms) | forward: 45232.82 | backward: 18048.70 | allreduce: 0.00 | optimizer: 153.92 | data loader: 1.30
[2025-03-17 03:43:47,018] [INFO] [RANK 0]  iteration       62/   30000 | elapsed time per iteration (ms): 68697.3 | learning rate 5.000E-07 | total loss 7.679803E-02 | loss 7.679803E-02 |speed 0.87 samples/(min*GPU)
[2025-03-17 03:43:47,039] [INFO] [RANK 0] time (ms) | forward: 42795.79 | backward: 19116.16 | allreduce: 0.00 | optimizer: 88.87 | data loader: 1.36
[2025-03-17 03:44:47,821] [INFO] [RANK 0]  iteration       63/   30000 | elapsed time per iteration (ms): 60803.1 | learning rate 5.000E-07 | total loss 9.666124E-02 | loss 9.666124E-02 |speed 0.99 samples/(min*GPU)
[2025-03-17 03:44:47,841] [INFO] [RANK 0] time (ms) | forward: 35228.01 | backward: 18514.93 | allreduce: 0.00 | optimizer: 94.08 | data loader: 2.05
[2025-03-17 03:45:51,390] [INFO] [RANK 0]  iteration       64/   30000 | elapsed time per iteration (ms): 63569.4 | learning rate 5.000E-07 | total loss 8.512194E-02 | loss 8.512194E-02 |speed 0.94 samples/(min*GPU)
[2025-03-17 03:45:51,410] [INFO] [RANK 0] time (ms) | forward: 34373.17 | backward: 17474.42 | allreduce: 0.00 | optimizer: 86.60 | data loader: 348.76
[2025-03-17 03:46:59,296] [INFO] [RANK 0]  iteration       65/   30000 | elapsed time per iteration (ms): 67905.5 | learning rate 5.000E-07 | total loss 7.169657E-02 | loss 7.169657E-02 |speed 0.88 samples/(min*GPU)
[2025-03-17 03:46:59,302] [INFO] [RANK 0] time (ms) | forward: 39975.49 | backward: 19686.79 | allreduce: 0.00 | optimizer: 47.17 | data loader: 0.54
[2025-03-17 03:48:02,032] [INFO] [RANK 0]  iteration       66/   30000 | elapsed time per iteration (ms): 62736.1 | learning rate 5.000E-07 | total loss 8.610523E-02 | loss 8.610523E-02 |speed 0.96 samples/(min*GPU)
[2025-03-17 03:48:02,091] [INFO] [RANK 0] time (ms) | forward: 40146.46 | backward: 17753.26 | allreduce: 0.00 | optimizer: 177.75 | data loader: 1.44
[2025-03-17 03:49:06,690] [INFO] [RANK 0]  iteration       67/   30000 | elapsed time per iteration (ms): 64658.5 | learning rate 5.000E-07 | total loss 7.303333E-02 | loss 7.303333E-02 |speed 0.93 samples/(min*GPU)
[2025-03-17 03:49:06,703] [INFO] [RANK 0] time (ms) | forward: 40503.01 | backward: 18153.95 | allreduce: 0.00 | optimizer: 97.00 | data loader: 0.26
[2025-03-17 03:50:12,802] [INFO] [RANK 0]  iteration       68/   30000 | elapsed time per iteration (ms): 66111.7 | learning rate 5.000E-07 | total loss 8.740635E-02 | loss 8.740635E-02 |speed 0.91 samples/(min*GPU)
[2025-03-17 03:50:12,823] [INFO] [RANK 0] time (ms) | forward: 45681.01 | backward: 16587.02 | allreduce: 0.00 | optimizer: 88.30 | data loader: 0.82
[2025-03-17 03:51:18,654] [INFO] [RANK 0]  iteration       69/   30000 | elapsed time per iteration (ms): 65852.3 | learning rate 5.000E-07 | total loss 7.805173E-02 | loss 7.805173E-02 |speed 0.91 samples/(min*GPU)
[2025-03-17 03:51:18,682] [INFO] [RANK 0] time (ms) | forward: 44423.23 | backward: 20929.87 | allreduce: 0.00 | optimizer: 57.19 | data loader: 0.95
[2025-03-17 03:52:22,745] [INFO] [RANK 0]  iteration       70/   30000 | elapsed time per iteration (ms): 64090.6 | learning rate 5.000E-07 | total loss 8.583106E-02 | loss 8.583106E-02 |speed 0.94 samples/(min*GPU)
[2025-03-17 03:52:22,761] [INFO] [RANK 0] time (ms) | forward: 40706.22 | backward: 18066.87 | allreduce: 0.00 | optimizer: 49.25 | data loader: 6.15
[2025-03-17 03:53:28,442] [INFO] [RANK 0]  iteration       71/   30000 | elapsed time per iteration (ms): 65696.5 | learning rate 5.000E-07 | total loss 8.572663E-02 | loss 8.572663E-02 |speed 0.91 samples/(min*GPU)
[2025-03-17 03:53:28,456] [INFO] [RANK 0] time (ms) | forward: 33842.51 | backward: 17272.32 | allreduce: 0.00 | optimizer: 118.89 | data loader: 2.66
[2025-03-17 03:54:39,771] [INFO] [RANK 0]  iteration       72/   30000 | elapsed time per iteration (ms): 71329.1 | learning rate 5.000E-07 | total loss 6.998655E-02 | loss 6.998655E-02 |speed 0.84 samples/(min*GPU)
[2025-03-17 03:54:39,796] [INFO] [RANK 0] time (ms) | forward: 48002.40 | backward: 20343.21 | allreduce: 0.00 | optimizer: 138.91 | data loader: 3.00
[2025-03-17 03:55:37,991] [INFO] [RANK 0]  iteration       73/   30000 | elapsed time per iteration (ms): 58220.7 | learning rate 5.000E-07 | total loss 7.848934E-02 | loss 7.848934E-02 |speed 1.03 samples/(min*GPU)
[2025-03-17 03:55:37,997] [INFO] [RANK 0] time (ms) | forward: 33315.94 | backward: 19417.56 | allreduce: 0.00 | optimizer: 80.27 | data loader: 0.45
[2025-03-17 03:56:45,850] [INFO] [RANK 0]  iteration       74/   30000 | elapsed time per iteration (ms): 67834.3 | learning rate 5.000E-07 | total loss 1.038758E-01 | loss 1.038758E-01 |speed 0.88 samples/(min*GPU)
[2025-03-17 03:56:45,891] [INFO] [RANK 0] time (ms) | forward: 35124.11 | backward: 19674.46 | allreduce: 0.00 | optimizer: 123.32 | data loader: 1.44
[2025-03-17 03:57:49,536] [INFO] [RANK 0]  iteration       75/   30000 | elapsed time per iteration (ms): 63710.3 | learning rate 5.000E-07 | total loss 1.057357E-01 | loss 1.057357E-01 |speed 0.94 samples/(min*GPU)
[2025-03-17 03:57:49,538] [INFO] [RANK 0] time (ms) | forward: 38644.07 | backward: 17276.57 | allreduce: 0.00 | optimizer: 50.91 | data loader: 3.11
[2025-03-17 03:58:57,024] [INFO] [RANK 0]  iteration       76/   30000 | elapsed time per iteration (ms): 67487.7 | learning rate 5.000E-07 | total loss 8.878674E-02 | loss 8.878674E-02 |speed 0.89 samples/(min*GPU)
[2025-03-17 03:58:57,058] [INFO] [RANK 0] time (ms) | forward: 39394.62 | backward: 20310.45 | allreduce: 0.00 | optimizer: 303.27 | data loader: 0.28
[2025-03-17 03:59:57,881] [INFO] [RANK 0]  iteration       77/   30000 | elapsed time per iteration (ms): 60857.2 | learning rate 5.000E-07 | total loss 7.712173E-02 | loss 7.712173E-02 |speed 0.99 samples/(min*GPU)
[2025-03-17 03:59:57,883] [INFO] [RANK 0] time (ms) | forward: 40082.42 | backward: 17601.28 | allreduce: 0.00 | optimizer: 77.93 | data loader: 0.41
[2025-03-17 04:01:00,655] [INFO] [RANK 0]  iteration       78/   30000 | elapsed time per iteration (ms): 62773.9 | learning rate 5.000E-07 | total loss 7.624352E-02 | loss 7.624352E-02 |speed 0.96 samples/(min*GPU)
[2025-03-17 04:01:00,658] [INFO] [RANK 0] time (ms) | forward: 46024.38 | backward: 15987.81 | allreduce: 0.00 | optimizer: 314.14 | data loader: 0.31
[2025-03-17 04:02:05,076] [INFO] [RANK 0]  iteration       79/   30000 | elapsed time per iteration (ms): 64421.5 | learning rate 5.000E-07 | total loss 1.069900E-01 | loss 1.069900E-01 |speed 0.93 samples/(min*GPU)
[2025-03-17 04:02:05,106] [INFO] [RANK 0] time (ms) | forward: 43546.84 | backward: 17397.80 | allreduce: 0.00 | optimizer: 172.35 | data loader: 1.70
[2025-03-17 04:03:11,828] [INFO] [RANK 0]  iteration       80/   30000 | elapsed time per iteration (ms): 66751.3 | learning rate 5.000E-07 | total loss 1.215056E-01 | loss 1.215056E-01 |speed 0.90 samples/(min*GPU)
[2025-03-17 04:03:11,837] [INFO] [RANK 0] time (ms) | forward: 44023.44 | backward: 19296.75 | allreduce: 0.00 | optimizer: 102.75 | data loader: 0.73
[2025-03-17 04:04:16,025] [INFO] [RANK 0]  iteration       81/   30000 | elapsed time per iteration (ms): 64197.4 | learning rate 5.000E-07 | total loss 7.681148E-02 | loss 7.681148E-02 |speed 0.93 samples/(min*GPU)
[2025-03-17 04:04:16,137] [INFO] [RANK 0] time (ms) | forward: 44011.06 | backward: 16391.19 | allreduce: 0.00 | optimizer: 50.34 | data loader: 59.77
[2025-03-17 04:05:22,497] [INFO] [RANK 0]  iteration       82/   30000 | elapsed time per iteration (ms): 66471.4 | learning rate 5.000E-07 | total loss 7.420942E-02 | loss 7.420942E-02 |speed 0.90 samples/(min*GPU)
[2025-03-17 04:05:22,501] [INFO] [RANK 0] time (ms) | forward: 46282.49 | backward: 18733.60 | allreduce: 0.00 | optimizer: 56.05 | data loader: 1.01
[2025-03-17 04:06:31,506] [INFO] [RANK 0]  iteration       83/   30000 | elapsed time per iteration (ms): 69009.2 | learning rate 5.000E-07 | total loss 7.228632E-02 | loss 7.228632E-02 |speed 0.87 samples/(min*GPU)
[2025-03-17 04:06:31,532] [INFO] [RANK 0] time (ms) | forward: 47090.56 | backward: 20243.78 | allreduce: 0.00 | optimizer: 58.11 | data loader: 1.03
[2025-03-17 04:07:32,140] [INFO] [RANK 0]  iteration       84/   30000 | elapsed time per iteration (ms): 60634.5 | learning rate 5.000E-07 | total loss 9.386270E-02 | loss 9.386270E-02 |speed 0.99 samples/(min*GPU)
[2025-03-17 04:07:32,145] [INFO] [RANK 0] time (ms) | forward: 36426.30 | backward: 17833.87 | allreduce: 0.00 | optimizer: 195.82 | data loader: 0.48
[2025-03-17 04:08:33,887] [INFO] [RANK 0]  iteration       85/   30000 | elapsed time per iteration (ms): 61746.1 | learning rate 5.000E-07 | total loss 9.509331E-02 | loss 9.509331E-02 |speed 0.97 samples/(min*GPU)
[2025-03-17 04:08:33,898] [INFO] [RANK 0] time (ms) | forward: 36558.52 | backward: 15755.51 | allreduce: 0.00 | optimizer: 103.26 | data loader: 0.87
[2025-03-17 04:09:41,302] [INFO] [RANK 0]  iteration       86/   30000 | elapsed time per iteration (ms): 67415.0 | learning rate 5.000E-07 | total loss 9.173581E-02 | loss 9.173581E-02 |speed 0.89 samples/(min*GPU)
[2025-03-17 04:09:41,309] [INFO] [RANK 0] time (ms) | forward: 41451.80 | backward: 18688.56 | allreduce: 0.00 | optimizer: 138.59 | data loader: 2.81
[2025-03-17 04:10:48,281] [INFO] [RANK 0]  iteration       87/   30000 | elapsed time per iteration (ms): 66979.7 | learning rate 5.000E-07 | total loss 8.303212E-02 | loss 8.303212E-02 |speed 0.90 samples/(min*GPU)
[2025-03-17 04:10:48,397] [INFO] [RANK 0] time (ms) | forward: 46537.93 | backward: 18648.12 | allreduce: 0.00 | optimizer: 174.92 | data loader: 2.27
[2025-03-17 04:11:53,533] [INFO] [RANK 0]  iteration       88/   30000 | elapsed time per iteration (ms): 65252.3 | learning rate 5.000E-07 | total loss 6.361458E-02 | loss 6.361458E-02 |speed 0.92 samples/(min*GPU)
[2025-03-17 04:11:53,535] [INFO] [RANK 0] time (ms) | forward: 42971.53 | backward: 19743.15 | allreduce: 0.00 | optimizer: 49.22 | data loader: 0.87
[2025-03-17 04:12:54,170] [INFO] [RANK 0]  iteration       89/   30000 | elapsed time per iteration (ms): 60636.0 | learning rate 5.000E-07 | total loss 7.057750E-02 | loss 7.057750E-02 |speed 0.99 samples/(min*GPU)
[2025-03-17 04:12:54,203] [INFO] [RANK 0] time (ms) | forward: 37941.48 | backward: 16179.83 | allreduce: 0.00 | optimizer: 49.90 | data loader: 0.25
[2025-03-17 04:14:03,151] [INFO] [RANK 0]  iteration       90/   30000 | elapsed time per iteration (ms): 68981.8 | learning rate 5.000E-07 | total loss 7.185219E-02 | loss 7.185219E-02 |speed 0.87 samples/(min*GPU)
[2025-03-17 04:14:03,195] [INFO] [RANK 0] time (ms) | forward: 47714.18 | backward: 20019.82 | allreduce: 0.00 | optimizer: 273.98 | data loader: 1.01
[2025-03-17 04:15:06,416] [INFO] [RANK 0]  iteration       91/   30000 | elapsed time per iteration (ms): 63264.3 | learning rate 5.000E-07 | total loss 7.509298E-02 | loss 7.509298E-02 |speed 0.95 samples/(min*GPU)
[2025-03-17 04:15:06,423] [INFO] [RANK 0] time (ms) | forward: 42858.41 | backward: 17444.05 | allreduce: 0.00 | optimizer: 48.41 | data loader: 1.42
[2025-03-17 04:16:04,547] [INFO] [RANK 0]  iteration       92/   30000 | elapsed time per iteration (ms): 58131.0 | learning rate 5.000E-07 | total loss 7.770976E-02 | loss 7.770976E-02 |speed 1.03 samples/(min*GPU)
[2025-03-17 04:16:04,556] [INFO] [RANK 0] time (ms) | forward: 39692.65 | backward: 16110.68 | allreduce: 0.00 | optimizer: 125.81 | data loader: 5.41
[2025-03-17 04:17:11,098] [INFO] [RANK 0]  iteration       93/   30000 | elapsed time per iteration (ms): 66551.0 | learning rate 5.000E-07 | total loss 8.752114E-02 | loss 8.752114E-02 |speed 0.90 samples/(min*GPU)
[2025-03-17 04:17:11,112] [INFO] [RANK 0] time (ms) | forward: 49330.35 | backward: 16936.62 | allreduce: 0.00 | optimizer: 268.71 | data loader: 1.23
[2025-03-17 04:18:17,582] [INFO] [RANK 0]  iteration       94/   30000 | elapsed time per iteration (ms): 66484.5 | learning rate 5.000E-07 | total loss 8.473639E-02 | loss 8.473639E-02 |speed 0.90 samples/(min*GPU)
[2025-03-17 04:18:17,612] [INFO] [RANK 0] time (ms) | forward: 43744.03 | backward: 18840.93 | allreduce: 0.00 | optimizer: 66.80 | data loader: 4.63
[2025-03-17 04:19:20,382] [INFO] [RANK 0]  iteration       95/   30000 | elapsed time per iteration (ms): 62799.1 | learning rate 5.000E-07 | total loss 6.542028E-02 | loss 6.542028E-02 |speed 0.96 samples/(min*GPU)
[2025-03-17 04:19:20,385] [INFO] [RANK 0] time (ms) | forward: 36783.99 | backward: 18488.38 | allreduce: 0.00 | optimizer: 195.41 | data loader: 10.87
[2025-03-17 04:20:21,458] [INFO] [RANK 0]  iteration       96/   30000 | elapsed time per iteration (ms): 61076.6 | learning rate 5.000E-07 | total loss 8.786526E-02 | loss 8.786526E-02 |speed 0.98 samples/(min*GPU)
[2025-03-17 04:20:21,565] [INFO] [RANK 0] time (ms) | forward: 44745.60 | backward: 15129.51 | allreduce: 0.00 | optimizer: 120.70 | data loader: 10.17
[2025-03-17 04:21:29,058] [INFO] [RANK 0]  iteration       97/   30000 | elapsed time per iteration (ms): 67599.9 | learning rate 5.000E-07 | total loss 6.560121E-02 | loss 6.560121E-02 |speed 0.89 samples/(min*GPU)
[2025-03-17 04:21:29,086] [INFO] [RANK 0] time (ms) | forward: 43864.66 | backward: 17065.36 | allreduce: 0.00 | optimizer: 206.12 | data loader: 2.34
[2025-03-17 04:22:36,355] [INFO] [RANK 0]  iteration       98/   30000 | elapsed time per iteration (ms): 67296.6 | learning rate 5.000E-07 | total loss 9.367159E-02 | loss 9.367159E-02 |speed 0.89 samples/(min*GPU)
[2025-03-17 04:22:36,361] [INFO] [RANK 0] time (ms) | forward: 44439.78 | backward: 19580.84 | allreduce: 0.00 | optimizer: 239.67 | data loader: 0.78
[2025-03-17 04:23:38,337] [INFO] [RANK 0]  iteration       99/   30000 | elapsed time per iteration (ms): 61982.1 | learning rate 5.000E-07 | total loss 8.393925E-02 | loss 8.393925E-02 |speed 0.97 samples/(min*GPU)
[2025-03-17 04:23:38,362] [INFO] [RANK 0] time (ms) | forward: 36368.28 | backward: 17986.45 | allreduce: 0.00 | optimizer: 305.64 | data loader: 0.95
[2025-03-17 04:24:43,837] [INFO] [logging.py:128:log_dist] [Rank 0] step=100, skipped=0, lr=[5.000000000000001e-07, 5.000000000000001e-07], mom=[[0.9, 0.95], [0.9, 0.95]]
[2025-03-17 04:24:43,900] [INFO] [RANK 0]  iteration      100/   30000 | elapsed time per iteration (ms): 65562.8 | learning rate 3.367E-06 | total loss 7.208045E-02 | loss 7.208045E-02 |speed 0.92 samples/(min*GPU)
[2025-03-17 04:24:43,918] [INFO] [RANK 0] time (ms) | forward: 40744.85 | backward: 16696.96 | allreduce: 0.00 | optimizer: 216.50 | data loader: 0.69
[2025-03-17 04:25:48,614] [INFO] [RANK 0]  iteration      101/   30000 | elapsed time per iteration (ms): 64714.0 | learning rate 3.400E-06 | total loss 7.641569E-02 | loss 7.641569E-02 |speed 0.93 samples/(min*GPU)
[2025-03-17 04:25:48,701] [INFO] [RANK 0] time (ms) | forward: 42879.77 | backward: 19221.07 | allreduce: 0.00 | optimizer: 49.96 | data loader: 1.24
[2025-03-17 04:26:52,000] [INFO] [RANK 0]  iteration      102/   30000 | elapsed time per iteration (ms): 63386.0 | learning rate 3.433E-06 | total loss 7.741643E-02 | loss 7.741643E-02 |speed 0.95 samples/(min*GPU)
[2025-03-17 04:26:52,039] [INFO] [RANK 0] time (ms) | forward: 42836.98 | backward: 17326.13 | allreduce: 0.00 | optimizer: 172.32 | data loader: 5.26
[2025-03-17 04:27:51,585] [INFO] [RANK 0]  iteration      103/   30000 | elapsed time per iteration (ms): 59585.3 | learning rate 3.467E-06 | total loss 8.929726E-02 | loss 8.929726E-02 |speed 1.01 samples/(min*GPU)
[2025-03-17 04:27:51,592] [INFO] [RANK 0] time (ms) | forward: 35539.10 | backward: 15725.77 | allreduce: 0.00 | optimizer: 151.22 | data loader: 1.02
[2025-03-17 04:28:56,321] [INFO] [RANK 0]  iteration      104/   30000 | elapsed time per iteration (ms): 64735.9 | learning rate 3.500E-06 | total loss 8.934949E-02 | loss 8.934949E-02 |speed 0.93 samples/(min*GPU)
[2025-03-17 04:28:56,396] [INFO] [RANK 0] time (ms) | forward: 37207.78 | backward: 16626.64 | allreduce: 0.00 | optimizer: 78.28 | data loader: 1.95
[2025-03-17 04:30:03,608] [INFO] [RANK 0]  iteration      105/   30000 | elapsed time per iteration (ms): 67287.2 | learning rate 3.533E-06 | total loss 6.546517E-02 | loss 6.546517E-02 |speed 0.89 samples/(min*GPU)
[2025-03-17 04:30:03,648] [INFO] [RANK 0] time (ms) | forward: 41017.56 | backward: 18988.21 | allreduce: 0.00 | optimizer: 192.34 | data loader: 0.96
[2025-03-17 04:31:04,855] [INFO] [RANK 0]  iteration      106/   30000 | elapsed time per iteration (ms): 61247.0 | learning rate 3.567E-06 | total loss 1.223054E-01 | loss 1.223054E-01 |speed 0.98 samples/(min*GPU)
[2025-03-17 04:31:04,891] [INFO] [RANK 0] time (ms) | forward: 39366.27 | backward: 18172.45 | allreduce: 0.00 | optimizer: 113.85 | data loader: 2.42
[2025-03-17 04:32:11,192] [INFO] [RANK 0]  iteration      107/   30000 | elapsed time per iteration (ms): 66336.4 | learning rate 3.600E-06 | total loss 9.118082E-02 | loss 9.118082E-02 |speed 0.90 samples/(min*GPU)
[2025-03-17 04:32:11,212] [INFO] [RANK 0] time (ms) | forward: 34855.15 | backward: 16279.82 | allreduce: 0.00 | optimizer: 142.75 | data loader: 6.12
[2025-03-17 04:33:13,427] [INFO] [RANK 0]  iteration      108/   30000 | elapsed time per iteration (ms): 62235.5 | learning rate 3.633E-06 | total loss 7.151332E-02 | loss 7.151332E-02 |speed 0.96 samples/(min*GPU)
[2025-03-17 04:33:13,434] [INFO] [RANK 0] time (ms) | forward: 43114.91 | backward: 16366.62 | allreduce: 0.00 | optimizer: 117.26 | data loader: 2.81
[2025-03-17 04:34:17,898] [INFO] [RANK 0]  iteration      109/   30000 | elapsed time per iteration (ms): 64470.4 | learning rate 3.667E-06 | total loss 8.923161E-02 | loss 8.923161E-02 |speed 0.93 samples/(min*GPU)
[2025-03-17 04:34:17,915] [INFO] [RANK 0] time (ms) | forward: 41503.18 | backward: 17842.66 | allreduce: 0.00 | optimizer: 133.59 | data loader: 1.15
[2025-03-17 04:35:19,141] [INFO] [RANK 0]  iteration      110/   30000 | elapsed time per iteration (ms): 61243.3 | learning rate 3.700E-06 | total loss 6.701352E-02 | loss 6.701352E-02 |speed 0.98 samples/(min*GPU)
[2025-03-17 04:35:19,152] [INFO] [RANK 0] time (ms) | forward: 41092.99 | backward: 17341.58 | allreduce: 0.00 | optimizer: 190.69 | data loader: 1.83
[2025-03-17 04:36:26,655] [INFO] [RANK 0]  iteration      111/   30000 | elapsed time per iteration (ms): 67440.2 | learning rate 3.733E-06 | total loss 7.515231E-02 | loss 7.515231E-02 |speed 0.89 samples/(min*GPU)
[2025-03-17 04:36:26,659] [INFO] [RANK 0] time (ms) | forward: 49165.01 | backward: 18006.19 | allreduce: 0.00 | optimizer: 252.21 | data loader: 1.13
[2025-03-17 04:37:31,627] [INFO] [RANK 0]  iteration      112/   30000 | elapsed time per iteration (ms): 65046.2 | learning rate 3.767E-06 | total loss 7.699319E-02 | loss 7.699319E-02 |speed 0.92 samples/(min*GPU)
[2025-03-17 04:37:31,647] [INFO] [RANK 0] time (ms) | forward: 43171.47 | backward: 17393.02 | allreduce: 0.00 | optimizer: 121.55 | data loader: 1.16
[2025-03-17 04:38:39,821] [INFO] [RANK 0]  iteration      113/   30000 | elapsed time per iteration (ms): 68192.1 | learning rate 3.800E-06 | total loss 8.457487E-02 | loss 8.457487E-02 |speed 0.88 samples/(min*GPU)
[2025-03-17 04:38:39,831] [INFO] [RANK 0] time (ms) | forward: 38980.60 | backward: 21606.31 | allreduce: 0.00 | optimizer: 199.18 | data loader: 0.66
[2025-03-17 04:39:41,702] [INFO] [RANK 0]  iteration      114/   30000 | elapsed time per iteration (ms): 61882.3 | learning rate 3.833E-06 | total loss 8.373623E-02 | loss 8.373623E-02 |speed 0.97 samples/(min*GPU)
[2025-03-17 04:39:41,714] [INFO] [RANK 0] time (ms) | forward: 43171.56 | backward: 17965.51 | allreduce: 0.00 | optimizer: 48.63 | data loader: 1.04
[2025-03-17 04:40:46,834] [INFO] [RANK 0]  iteration      115/   30000 | elapsed time per iteration (ms): 65132.5 | learning rate 3.867E-06 | total loss 1.107445E-01 | loss 1.107445E-01 |speed 0.92 samples/(min*GPU)
[2025-03-17 04:40:46,840] [INFO] [RANK 0] time (ms) | forward: 46609.68 | backward: 18380.45 | allreduce: 0.00 | optimizer: 113.65 | data loader: 5.06
[2025-03-17 04:41:52,783] [INFO] [RANK 0]  iteration      116/   30000 | elapsed time per iteration (ms): 65948.7 | learning rate 3.900E-06 | total loss 9.137705E-02 | loss 9.137705E-02 |speed 0.91 samples/(min*GPU)
[2025-03-17 04:41:52,791] [INFO] [RANK 0] time (ms) | forward: 46168.88 | backward: 18747.23 | allreduce: 0.00 | optimizer: 140.22 | data loader: 0.45
[2025-03-17 04:42:56,448] [INFO] [RANK 0]  iteration      117/   30000 | elapsed time per iteration (ms): 63665.3 | learning rate 3.933E-06 | total loss 6.759285E-02 | loss 6.759285E-02 |speed 0.94 samples/(min*GPU)
[2025-03-17 04:42:56,582] [INFO] [RANK 0] time (ms) | forward: 44117.80 | backward: 16789.28 | allreduce: 0.00 | optimizer: 103.74 | data loader: 1.37
[2025-03-17 04:43:56,649] [INFO] [RANK 0]  iteration      118/   30000 | elapsed time per iteration (ms): 60201.2 | learning rate 3.967E-06 | total loss 1.004592E-01 | loss 1.004592E-01 |speed 1.00 samples/(min*GPU)
[2025-03-17 04:43:56,661] [INFO] [RANK 0] time (ms) | forward: 39227.07 | backward: 18682.70 | allreduce: 0.00 | optimizer: 53.49 | data loader: 247.93
[2025-03-17 04:45:00,492] [INFO] [RANK 0]  iteration      119/   30000 | elapsed time per iteration (ms): 63842.1 | learning rate 4.000E-06 | total loss 7.687873E-02 | loss 7.687873E-02 |speed 0.94 samples/(min*GPU)
[2025-03-17 04:45:00,503] [INFO] [RANK 0] time (ms) | forward: 42881.72 | backward: 16128.78 | allreduce: 0.00 | optimizer: 110.00 | data loader: 2.51
[2025-03-17 04:46:06,601] [INFO] [RANK 0]  iteration      120/   30000 | elapsed time per iteration (ms): 66109.9 | learning rate 4.033E-06 | total loss 7.658047E-02 | loss 7.658047E-02 |speed 0.91 samples/(min*GPU)
[2025-03-17 04:46:06,616] [INFO] [RANK 0] time (ms) | forward: 47117.47 | backward: 17171.22 | allreduce: 0.00 | optimizer: 89.95 | data loader: 1.29
[2025-03-17 04:47:13,737] [INFO] [RANK 0]  iteration      121/   30000 | elapsed time per iteration (ms): 67135.7 | learning rate 4.067E-06 | total loss 6.807730E-02 | loss 6.807730E-02 |speed 0.89 samples/(min*GPU)
[2025-03-17 04:47:14,043] [INFO] [RANK 0] time (ms) | forward: 42862.27 | backward: 18384.23 | allreduce: 0.00 | optimizer: 107.28 | data loader: 1.04
[2025-03-17 04:48:14,687] [INFO] [RANK 0]  iteration      122/   30000 | elapsed time per iteration (ms): 60949.6 | learning rate 4.100E-06 | total loss 6.826676E-02 | loss 6.826676E-02 |speed 0.98 samples/(min*GPU)
[2025-03-17 04:48:14,694] [INFO] [RANK 0] time (ms) | forward: 36473.68 | backward: 18064.13 | allreduce: 0.00 | optimizer: 141.68 | data loader: 1.32
[2025-03-17 04:49:21,292] [INFO] [RANK 0]  iteration      123/   30000 | elapsed time per iteration (ms): 66604.7 | learning rate 4.133E-06 | total loss 1.190841E-01 | loss 1.190841E-01 |speed 0.90 samples/(min*GPU)
[2025-03-17 04:49:21,311] [INFO] [RANK 0] time (ms) | forward: 43636.31 | backward: 17177.68 | allreduce: 0.00 | optimizer: 128.83 | data loader: 1.75
[2025-03-17 04:50:30,792] [INFO] [RANK 0]  iteration      124/   30000 | elapsed time per iteration (ms): 69499.9 | learning rate 4.167E-06 | total loss 1.059941E-01 | loss 1.059941E-01 |speed 0.86 samples/(min*GPU)
[2025-03-17 04:50:30,800] [INFO] [RANK 0] time (ms) | forward: 38733.05 | backward: 21568.22 | allreduce: 0.00 | optimizer: 191.05 | data loader: 3.18
[2025-03-17 04:51:36,157] [INFO] [RANK 0]  iteration      125/   30000 | elapsed time per iteration (ms): 65365.7 | learning rate 4.200E-06 | total loss 8.979811E-02 | loss 8.979811E-02 |speed 0.92 samples/(min*GPU)
[2025-03-17 04:51:36,182] [INFO] [RANK 0] time (ms) | forward: 39035.27 | backward: 18405.86 | allreduce: 0.00 | optimizer: 125.96 | data loader: 2.35
[2025-03-17 04:52:41,852] [INFO] [RANK 0]  iteration      126/   30000 | elapsed time per iteration (ms): 65694.5 | learning rate 4.233E-06 | total loss 6.751819E-02 | loss 6.751819E-02 |speed 0.91 samples/(min*GPU)
[2025-03-17 04:52:41,858] [INFO] [RANK 0] time (ms) | forward: 40024.01 | backward: 17920.15 | allreduce: 0.00 | optimizer: 426.07 | data loader: 0.36
[2025-03-17 04:53:52,461] [INFO] [RANK 0]  iteration      127/   30000 | elapsed time per iteration (ms): 70608.9 | learning rate 4.267E-06 | total loss 8.957011E-02 | loss 8.957011E-02 |speed 0.85 samples/(min*GPU)
[2025-03-17 04:53:52,531] [INFO] [RANK 0] time (ms) | forward: 43374.70 | backward: 20622.55 | allreduce: 0.00 | optimizer: 107.29 | data loader: 4.15
[2025-03-17 04:54:56,797] [INFO] [RANK 0]  iteration      128/   30000 | elapsed time per iteration (ms): 64336.1 | learning rate 4.300E-06 | total loss 7.305806E-02 | loss 7.305806E-02 |speed 0.93 samples/(min*GPU)
[2025-03-17 04:54:56,803] [INFO] [RANK 0] time (ms) | forward: 38478.38 | backward: 19195.27 | allreduce: 0.00 | optimizer: 85.66 | data loader: 3.73
[2025-03-17 04:56:00,714] [INFO] [RANK 0]  iteration      129/   30000 | elapsed time per iteration (ms): 63916.9 | learning rate 4.333E-06 | total loss 1.122410E-01 | loss 1.122410E-01 |speed 0.94 samples/(min*GPU)
[2025-03-17 04:56:00,729] [INFO] [RANK 0] time (ms) | forward: 40863.56 | backward: 17259.83 | allreduce: 0.00 | optimizer: 55.80 | data loader: 1.94
[2025-03-17 04:57:08,632] [INFO] [RANK 0]  iteration      130/   30000 | elapsed time per iteration (ms): 67918.7 | learning rate 4.367E-06 | total loss 1.184631E-01 | loss 1.184631E-01 |speed 0.88 samples/(min*GPU)
[2025-03-17 04:57:08,699] [INFO] [RANK 0] time (ms) | forward: 45196.67 | backward: 19467.38 | allreduce: 0.00 | optimizer: 72.55 | data loader: 4.17
[2025-03-17 04:58:16,881] [INFO] [RANK 0]  iteration      131/   30000 | elapsed time per iteration (ms): 68248.7 | learning rate 4.400E-06 | total loss 7.228199E-02 | loss 7.228199E-02 |speed 0.88 samples/(min*GPU)
[2025-03-17 04:58:16,883] [INFO] [RANK 0] time (ms) | forward: 39170.97 | backward: 20090.64 | allreduce: 0.00 | optimizer: 183.32 | data loader: 5.21
[2025-03-17 04:59:24,593] [INFO] [RANK 0]  iteration      132/   30000 | elapsed time per iteration (ms): 67711.5 | learning rate 4.433E-06 | total loss 8.000488E-02 | loss 8.000488E-02 |speed 0.89 samples/(min*GPU)
[2025-03-17 04:59:24,603] [INFO] [RANK 0] time (ms) | forward: 43042.33 | backward: 17646.27 | allreduce: 0.00 | optimizer: 97.56 | data loader: 0.48
[2025-03-17 05:00:33,913] [INFO] [RANK 0]  iteration      133/   30000 | elapsed time per iteration (ms): 69320.2 | learning rate 4.467E-06 | total loss 8.846243E-02 | loss 8.846243E-02 |speed 0.87 samples/(min*GPU)
[2025-03-17 05:00:33,920] [INFO] [RANK 0] time (ms) | forward: 43090.23 | backward: 21022.61 | allreduce: 0.00 | optimizer: 68.61 | data loader: 1.09
[2025-03-17 05:01:35,606] [INFO] [RANK 0]  iteration      134/   30000 | elapsed time per iteration (ms): 61693.4 | learning rate 4.500E-06 | total loss 9.287240E-02 | loss 9.287240E-02 |speed 0.97 samples/(min*GPU)
[2025-03-17 05:01:35,611] [INFO] [RANK 0] time (ms) | forward: 34437.00 | backward: 19508.37 | allreduce: 0.00 | optimizer: 104.35 | data loader: 1.29
[2025-03-17 05:02:41,702] [INFO] [RANK 0]  iteration      135/   30000 | elapsed time per iteration (ms): 66095.3 | learning rate 4.533E-06 | total loss 6.838556E-02 | loss 6.838556E-02 |speed 0.91 samples/(min*GPU)
[2025-03-17 05:02:41,707] [INFO] [RANK 0] time (ms) | forward: 38032.03 | backward: 17198.31 | allreduce: 0.00 | optimizer: 169.58 | data loader: 1.08
[2025-03-17 05:03:44,906] [INFO] [RANK 0]  iteration      136/   30000 | elapsed time per iteration (ms): 63204.1 | learning rate 4.567E-06 | total loss 7.166666E-02 | loss 7.166666E-02 |speed 0.95 samples/(min*GPU)
[2025-03-17 05:03:44,922] [INFO] [RANK 0] time (ms) | forward: 39411.95 | backward: 17122.15 | allreduce: 0.00 | optimizer: 58.44 | data loader: 1.52
[2025-03-17 05:04:51,618] [INFO] [RANK 0]  iteration      137/   30000 | elapsed time per iteration (ms): 66712.1 | learning rate 4.600E-06 | total loss 7.943242E-02 | loss 7.943242E-02 |speed 0.90 samples/(min*GPU)
[2025-03-17 05:04:51,640] [INFO] [RANK 0] time (ms) | forward: 40379.26 | backward: 20475.17 | allreduce: 0.00 | optimizer: 98.64 | data loader: 3.88
[2025-03-17 05:05:53,596] [INFO] [RANK 0]  iteration      138/   30000 | elapsed time per iteration (ms): 61978.1 | learning rate 4.633E-06 | total loss 9.012792E-02 | loss 9.012792E-02 |speed 0.97 samples/(min*GPU)
[2025-03-17 05:05:53,598] [INFO] [RANK 0] time (ms) | forward: 34535.90 | backward: 18595.80 | allreduce: 0.00 | optimizer: 302.54 | data loader: 1.21
[2025-03-17 05:06:58,431] [INFO] [RANK 0]  iteration      139/   30000 | elapsed time per iteration (ms): 64835.4 | learning rate 4.667E-06 | total loss 7.290463E-02 | loss 7.290463E-02 |speed 0.93 samples/(min*GPU)
[2025-03-17 05:06:58,435] [INFO] [RANK 0] time (ms) | forward: 46603.53 | backward: 16778.15 | allreduce: 0.00 | optimizer: 668.24 | data loader: 0.29
[2025-03-17 05:07:59,510] [INFO] [RANK 0]  iteration      140/   30000 | elapsed time per iteration (ms): 61054.5 | learning rate 4.700E-06 | total loss 9.088317E-02 | loss 9.088317E-02 |speed 0.98 samples/(min*GPU)
[2025-03-17 05:07:59,524] [INFO] [RANK 0] time (ms) | forward: 38092.49 | backward: 16418.94 | allreduce: 0.00 | optimizer: 135.75 | data loader: 0.63
[2025-03-17 05:09:04,317] [INFO] [RANK 0]  iteration      141/   30000 | elapsed time per iteration (ms): 64830.9 | learning rate 4.733E-06 | total loss 6.987749E-02 | loss 6.987749E-02 |speed 0.93 samples/(min*GPU)
[2025-03-17 05:09:04,323] [INFO] [RANK 0] time (ms) | forward: 42137.62 | backward: 19047.96 | allreduce: 0.00 | optimizer: 132.06 | data loader: 1.05
[2025-03-17 05:10:10,506] [INFO] [RANK 0]  iteration      142/   30000 | elapsed time per iteration (ms): 66189.0 | learning rate 4.767E-06 | total loss 6.526944E-02 | loss 6.526944E-02 |speed 0.91 samples/(min*GPU)
[2025-03-17 05:10:10,514] [INFO] [RANK 0] time (ms) | forward: 36818.21 | backward: 17831.65 | allreduce: 0.00 | optimizer: 61.41 | data loader: 0.76
[2025-03-17 05:11:18,032] [INFO] [RANK 0]  iteration      143/   30000 | elapsed time per iteration (ms): 67525.6 | learning rate 4.800E-06 | total loss 9.169148E-02 | loss 9.169148E-02 |speed 0.89 samples/(min*GPU)
[2025-03-17 05:11:18,037] [INFO] [RANK 0] time (ms) | forward: 46701.34 | backward: 16518.92 | allreduce: 0.00 | optimizer: 118.26 | data loader: 2.35
[2025-03-17 05:12:23,282] [INFO] [RANK 0]  iteration      144/   30000 | elapsed time per iteration (ms): 65250.1 | learning rate 4.833E-06 | total loss 1.387764E-01 | loss 1.387764E-01 |speed 0.92 samples/(min*GPU)
[2025-03-17 05:12:23,413] [INFO] [RANK 0] time (ms) | forward: 44112.76 | backward: 17283.82 | allreduce: 0.00 | optimizer: 182.64 | data loader: 2.95
[2025-03-17 05:13:22,500] [INFO] [RANK 0]  iteration      145/   30000 | elapsed time per iteration (ms): 59218.4 | learning rate 4.867E-06 | total loss 8.406849E-02 | loss 8.406849E-02 |speed 1.01 samples/(min*GPU)
[2025-03-17 05:13:22,510] [INFO] [RANK 0] time (ms) | forward: 39281.57 | backward: 17693.89 | allreduce: 0.00 | optimizer: 58.20 | data loader: 0.81
[2025-03-17 05:14:25,697] [INFO] [RANK 0]  iteration      146/   30000 | elapsed time per iteration (ms): 63196.3 | learning rate 4.900E-06 | total loss 1.145123E-01 | loss 1.145123E-01 |speed 0.95 samples/(min*GPU)
[2025-03-17 05:14:25,709] [INFO] [RANK 0] time (ms) | forward: 37075.93 | backward: 16854.29 | allreduce: 0.00 | optimizer: 121.31 | data loader: 1.34
[2025-03-17 05:15:32,546] [INFO] [RANK 0]  iteration      147/   30000 | elapsed time per iteration (ms): 66849.2 | learning rate 4.933E-06 | total loss 7.384167E-02 | loss 7.384167E-02 |speed 0.90 samples/(min*GPU)
[2025-03-17 05:15:32,550] [INFO] [RANK 0] time (ms) | forward: 37644.31 | backward: 19031.75 | allreduce: 0.00 | optimizer: 97.42 | data loader: 1.82
[2025-03-17 05:16:33,188] [INFO] [RANK 0]  iteration      148/   30000 | elapsed time per iteration (ms): 60642.4 | learning rate 4.967E-06 | total loss 1.262468E-01 | loss 1.262468E-01 |speed 0.99 samples/(min*GPU)
[2025-03-17 05:16:33,201] [INFO] [RANK 0] time (ms) | forward: 41178.86 | backward: 19378.92 | allreduce: 0.00 | optimizer: 67.37 | data loader: 1.17
[2025-03-17 05:17:33,890] [INFO] [RANK 0]  iteration      149/   30000 | elapsed time per iteration (ms): 60702.2 | learning rate 5.000E-06 | total loss 7.206658E-02 | loss 7.206658E-02 |speed 0.99 samples/(min*GPU)
[2025-03-17 05:17:33,895] [INFO] [RANK 0] time (ms) | forward: 39117.81 | backward: 17312.76 | allreduce: 0.00 | optimizer: 155.80 | data loader: 3.36
[2025-03-17 05:18:39,227] [INFO] [logging.py:128:log_dist] [Rank 0] step=150, skipped=0, lr=[5e-06, 5e-06], mom=[[0.9, 0.95], [0.9, 0.95]]
[2025-03-17 05:18:39,297] [INFO] [RANK 0]  iteration      150/   30000 | elapsed time per iteration (ms): 65406.5 | learning rate 5.033E-06 | total loss 7.477359E-02 | loss 7.477359E-02 |speed 0.92 samples/(min*GPU)
[2025-03-17 05:18:39,303] [INFO] [RANK 0] time (ms) | forward: 43697.23 | backward: 16719.18 | allreduce: 0.00 | optimizer: 237.13 | data loader: 2.50
[2025-03-17 05:19:49,079] [INFO] [RANK 0]  iteration      151/   30000 | elapsed time per iteration (ms): 69782.2 | learning rate 5.067E-06 | total loss 7.195675E-02 | loss 7.195675E-02 |speed 0.86 samples/(min*GPU)
[2025-03-17 05:19:49,087] [INFO] [RANK 0] time (ms) | forward: 48592.48 | backward: 19490.15 | allreduce: 0.00 | optimizer: 56.98 | data loader: 2.28
[2025-03-17 05:20:51,892] [INFO] [RANK 0]  iteration      152/   30000 | elapsed time per iteration (ms): 62812.5 | learning rate 5.100E-06 | total loss 6.774916E-02 | loss 6.774916E-02 |speed 0.96 samples/(min*GPU)
[2025-03-17 05:20:51,916] [INFO] [RANK 0] time (ms) | forward: 37865.52 | backward: 19613.11 | allreduce: 0.00 | optimizer: 71.50 | data loader: 4.98
[2025-03-17 05:21:56,907] [INFO] [RANK 0]  iteration      153/   30000 | elapsed time per iteration (ms): 65015.1 | learning rate 5.133E-06 | total loss 8.151314E-02 | loss 8.151314E-02 |speed 0.92 samples/(min*GPU)
[2025-03-17 05:21:56,917] [INFO] [RANK 0] time (ms) | forward: 36847.01 | backward: 18192.94 | allreduce: 0.00 | optimizer: 73.36 | data loader: 2.55
[2025-03-17 05:23:07,243] [INFO] [RANK 0]  iteration      154/   30000 | elapsed time per iteration (ms): 70336.6 | learning rate 5.167E-06 | total loss 1.216648E-01 | loss 1.216648E-01 |speed 0.85 samples/(min*GPU)
[2025-03-17 05:23:07,245] [INFO] [RANK 0] time (ms) | forward: 48924.45 | backward: 21337.20 | allreduce: 0.00 | optimizer: 58.55 | data loader: 1.34
[2025-03-17 05:24:10,781] [INFO] [RANK 0]  iteration      155/   30000 | elapsed time per iteration (ms): 63538.1 | learning rate 5.200E-06 | total loss 7.322173E-02 | loss 7.322173E-02 |speed 0.94 samples/(min*GPU)
[2025-03-17 05:24:10,783] [INFO] [RANK 0] time (ms) | forward: 37300.90 | backward: 19845.65 | allreduce: 0.00 | optimizer: 191.30 | data loader: 0.29
[2025-03-17 05:25:08,702] [INFO] [RANK 0]  iteration      156/   30000 | elapsed time per iteration (ms): 57920.4 | learning rate 5.233E-06 | total loss 7.115084E-02 | loss 7.115084E-02 |speed 1.04 samples/(min*GPU)
[2025-03-17 05:25:08,723] [INFO] [RANK 0] time (ms) | forward: 38610.45 | backward: 17916.77 | allreduce: 0.00 | optimizer: 272.82 | data loader: 0.26
[2025-03-17 05:26:11,098] [INFO] [RANK 0]  iteration      157/   30000 | elapsed time per iteration (ms): 62395.9 | learning rate 5.267E-06 | total loss 8.233538E-02 | loss 8.233538E-02 |speed 0.96 samples/(min*GPU)
[2025-03-17 05:26:11,102] [INFO] [RANK 0] time (ms) | forward: 39292.07 | backward: 15326.79 | allreduce: 0.00 | optimizer: 218.64 | data loader: 0.48
[2025-03-17 05:27:20,202] [INFO] [RANK 0]  iteration      158/   30000 | elapsed time per iteration (ms): 69103.8 | learning rate 5.300E-06 | total loss 1.102079E-01 | loss 1.102079E-01 |speed 0.87 samples/(min*GPU)
[2025-03-17 05:27:20,211] [INFO] [RANK 0] time (ms) | forward: 41219.04 | backward: 20385.40 | allreduce: 0.00 | optimizer: 102.75 | data loader: 8.62
[2025-03-17 05:28:25,531] [INFO] [RANK 0]  iteration      159/   30000 | elapsed time per iteration (ms): 65329.3 | learning rate 5.333E-06 | total loss 1.514122E-01 | loss 1.514122E-01 |speed 0.92 samples/(min*GPU)
[2025-03-17 05:28:25,588] [INFO] [RANK 0] time (ms) | forward: 34917.25 | backward: 18928.78 | allreduce: 0.00 | optimizer: 74.13 | data loader: 2.79
[2025-03-17 05:29:32,202] [INFO] [RANK 0]  iteration      160/   30000 | elapsed time per iteration (ms): 66670.8 | learning rate 5.367E-06 | total loss 9.450409E-02 | loss 9.450409E-02 |speed 0.90 samples/(min*GPU)
[2025-03-17 05:29:32,226] [INFO] [RANK 0] time (ms) | forward: 45427.78 | backward: 17880.00 | allreduce: 0.00 | optimizer: 68.26 | data loader: 2.82
[2025-03-17 05:30:34,134] [INFO] [RANK 0]  iteration      161/   30000 | elapsed time per iteration (ms): 61932.0 | learning rate 5.400E-06 | total loss 8.415093E-02 | loss 8.415093E-02 |speed 0.97 samples/(min*GPU)
[2025-03-17 05:30:34,139] [INFO] [RANK 0] time (ms) | forward: 39499.64 | backward: 15826.67 | allreduce: 0.00 | optimizer: 193.73 | data loader: 0.83
[2025-03-17 05:31:38,482] [INFO] [RANK 0]  iteration      162/   30000 | elapsed time per iteration (ms): 64348.2 | learning rate 5.433E-06 | total loss 7.771808E-02 | loss 7.771808E-02 |speed 0.93 samples/(min*GPU)
[2025-03-17 05:31:38,498] [INFO] [RANK 0] time (ms) | forward: 41009.60 | backward: 19756.92 | allreduce: 0.00 | optimizer: 140.04 | data loader: 0.65
[2025-03-17 05:32:39,887] [INFO] [RANK 0]  iteration      163/   30000 | elapsed time per iteration (ms): 61404.9 | learning rate 5.467E-06 | total loss 7.417573E-02 | loss 7.417573E-02 |speed 0.98 samples/(min*GPU)
[2025-03-17 05:32:39,895] [INFO] [RANK 0] time (ms) | forward: 37224.19 | backward: 19880.55 | allreduce: 0.00 | optimizer: 81.95 | data loader: 2.54
[2025-03-17 05:33:48,192] [INFO] [RANK 0]  iteration      164/   30000 | elapsed time per iteration (ms): 68305.0 | learning rate 5.500E-06 | total loss 6.980145E-02 | loss 6.980145E-02 |speed 0.88 samples/(min*GPU)
[2025-03-17 05:33:48,196] [INFO] [RANK 0] time (ms) | forward: 40817.06 | backward: 17355.91 | allreduce: 0.00 | optimizer: 96.05 | data loader: 3.42
[2025-03-17 05:34:58,027] [INFO] [RANK 0]  iteration      165/   30000 | elapsed time per iteration (ms): 69834.6 | learning rate 5.533E-06 | total loss 7.284295E-02 | loss 7.284295E-02 |speed 0.86 samples/(min*GPU)
[2025-03-17 05:34:58,040] [INFO] [RANK 0] time (ms) | forward: 38992.26 | backward: 21429.51 | allreduce: 0.00 | optimizer: 81.46 | data loader: 0.70
[2025-03-17 05:36:01,656] [INFO] [RANK 0]  iteration      166/   30000 | elapsed time per iteration (ms): 63628.9 | learning rate 5.567E-06 | total loss 6.941958E-02 | loss 6.941958E-02 |speed 0.94 samples/(min*GPU)
[2025-03-17 05:36:01,670] [INFO] [RANK 0] time (ms) | forward: 41599.83 | backward: 18850.65 | allreduce: 0.00 | optimizer: 242.29 | data loader: 2.86
[2025-03-17 05:37:06,092] [INFO] [RANK 0]  iteration      167/   30000 | elapsed time per iteration (ms): 64436.1 | learning rate 5.600E-06 | total loss 1.456732E-01 | loss 1.456732E-01 |speed 0.93 samples/(min*GPU)
[2025-03-17 05:37:06,109] [INFO] [RANK 0] time (ms) | forward: 39855.30 | backward: 17013.24 | allreduce: 0.00 | optimizer: 133.50 | data loader: 1.18
[2025-03-17 05:38:11,535] [INFO] [RANK 0]  iteration      168/   30000 | elapsed time per iteration (ms): 65443.2 | learning rate 5.633E-06 | total loss 1.136280E-01 | loss 1.136280E-01 |speed 0.92 samples/(min*GPU)
[2025-03-17 05:38:11,713] [INFO] [RANK 0] time (ms) | forward: 43311.79 | backward: 16831.06 | allreduce: 0.00 | optimizer: 70.70 | data loader: 2.96
[2025-03-17 05:39:16,007] [INFO] [RANK 0]  iteration      169/   30000 | elapsed time per iteration (ms): 64472.2 | learning rate 5.667E-06 | total loss 7.167887E-02 | loss 7.167887E-02 |speed 0.93 samples/(min*GPU)
[2025-03-17 05:39:16,018] [INFO] [RANK 0] time (ms) | forward: 44111.06 | backward: 20077.46 | allreduce: 0.00 | optimizer: 99.23 | data loader: 0.58
[2025-03-17 05:40:20,045] [INFO] [RANK 0]  iteration      170/   30000 | elapsed time per iteration (ms): 64038.0 | learning rate 5.700E-06 | total loss 1.063655E-01 | loss 1.063655E-01 |speed 0.94 samples/(min*GPU)
[2025-03-17 05:40:20,060] [INFO] [RANK 0] time (ms) | forward: 42393.04 | backward: 19368.44 | allreduce: 0.00 | optimizer: 205.37 | data loader: 2.76
[2025-03-17 05:41:28,306] [INFO] [RANK 0]  iteration      171/   30000 | elapsed time per iteration (ms): 68260.8 | learning rate 5.733E-06 | total loss 7.853527E-02 | loss 7.853527E-02 |speed 0.88 samples/(min*GPU)
[2025-03-17 05:41:28,314] [INFO] [RANK 0] time (ms) | forward: 42956.06 | backward: 16834.31 | allreduce: 0.00 | optimizer: 246.82 | data loader: 7.15
[2025-03-17 05:42:37,507] [INFO] [RANK 0]  iteration      172/   30000 | elapsed time per iteration (ms): 69200.5 | learning rate 5.767E-06 | total loss 9.289566E-02 | loss 9.289566E-02 |speed 0.87 samples/(min*GPU)
[2025-03-17 05:42:37,511] [INFO] [RANK 0] time (ms) | forward: 45744.35 | backward: 20023.99 | allreduce: 0.00 | optimizer: 112.87 | data loader: 2.38
[2025-03-17 05:43:40,481] [INFO] [RANK 0]  iteration      173/   30000 | elapsed time per iteration (ms): 62974.4 | learning rate 5.800E-06 | total loss 6.857565E-02 | loss 6.857565E-02 |speed 0.95 samples/(min*GPU)
[2025-03-17 05:43:40,483] [INFO] [RANK 0] time (ms) | forward: 41294.71 | backward: 17086.21 | allreduce: 0.00 | optimizer: 143.04 | data loader: 0.70
[2025-03-17 05:44:47,071] [INFO] [RANK 0]  iteration      174/   30000 | elapsed time per iteration (ms): 66590.0 | learning rate 5.833E-06 | total loss 8.026610E-02 | loss 8.026610E-02 |speed 0.90 samples/(min*GPU)
[2025-03-17 05:44:47,078] [INFO] [RANK 0] time (ms) | forward: 45441.20 | backward: 17406.79 | allreduce: 0.00 | optimizer: 50.87 | data loader: 0.27
[2025-03-17 05:45:56,693] [INFO] [RANK 0]  iteration      175/   30000 | elapsed time per iteration (ms): 69621.4 | learning rate 5.867E-06 | total loss 1.337702E-01 | loss 1.337702E-01 |speed 0.86 samples/(min*GPU)
[2025-03-17 05:45:56,728] [INFO] [RANK 0] time (ms) | forward: 48870.33 | backward: 20628.75 | allreduce: 0.00 | optimizer: 97.18 | data loader: 0.96
[2025-03-17 05:46:58,652] [INFO] [RANK 0]  iteration      176/   30000 | elapsed time per iteration (ms): 61959.4 | learning rate 5.900E-06 | total loss 8.130740E-02 | loss 8.130740E-02 |speed 0.97 samples/(min*GPU)
[2025-03-17 05:46:58,653] [INFO] [RANK 0] time (ms) | forward: 45029.26 | backward: 15843.09 | allreduce: 0.00 | optimizer: 63.56 | data loader: 3.20
[2025-03-17 05:48:07,787] [INFO] [RANK 0]  iteration      177/   30000 | elapsed time per iteration (ms): 69134.7 | learning rate 5.933E-06 | total loss 7.655120E-02 | loss 7.655120E-02 |speed 0.87 samples/(min*GPU)
[2025-03-17 05:48:07,792] [INFO] [RANK 0] time (ms) | forward: 46409.26 | backward: 18022.64 | allreduce: 0.00 | optimizer: 105.67 | data loader: 0.29
[2025-03-17 05:49:15,659] [INFO] [RANK 0]  iteration      178/   30000 | elapsed time per iteration (ms): 67872.3 | learning rate 5.967E-06 | total loss 7.052594E-02 | loss 7.052594E-02 |speed 0.88 samples/(min*GPU)
[2025-03-17 05:49:15,662] [INFO] [RANK 0] time (ms) | forward: 42329.12 | backward: 20998.52 | allreduce: 0.00 | optimizer: 125.92 | data loader: 1.07
[2025-03-17 05:50:17,495] [INFO] [RANK 0]  iteration      179/   30000 | elapsed time per iteration (ms): 61836.2 | learning rate 6.000E-06 | total loss 8.800101E-02 | loss 8.800101E-02 |speed 0.97 samples/(min*GPU)
[2025-03-17 05:50:17,501] [INFO] [RANK 0] time (ms) | forward: 40594.75 | backward: 18351.25 | allreduce: 0.00 | optimizer: 52.66 | data loader: 2.03
[2025-03-17 05:51:23,453] [INFO] [RANK 0]  iteration      180/   30000 | elapsed time per iteration (ms): 65958.0 | learning rate 6.033E-06 | total loss 1.037130E-01 | loss 1.037130E-01 |speed 0.91 samples/(min*GPU)
[2025-03-17 05:51:23,466] [INFO] [RANK 0] time (ms) | forward: 37065.61 | backward: 17715.83 | allreduce: 0.00 | optimizer: 212.98 | data loader: 6.22
[2025-03-17 05:52:32,311] [INFO] [RANK 0]  iteration      181/   30000 | elapsed time per iteration (ms): 68827.8 | learning rate 6.067E-06 | total loss 7.599064E-02 | loss 7.599064E-02 |speed 0.87 samples/(min*GPU)
[2025-03-17 05:52:32,315] [INFO] [RANK 0] time (ms) | forward: 38114.92 | backward: 19727.95 | allreduce: 0.00 | optimizer: 64.28 | data loader: 1.25
[2025-03-17 05:53:37,152] [INFO] [RANK 0]  iteration      182/   30000 | elapsed time per iteration (ms): 64871.5 | learning rate 6.100E-06 | total loss 1.204025E-01 | loss 1.204025E-01 |speed 0.92 samples/(min*GPU)
[2025-03-17 05:53:37,156] [INFO] [RANK 0] time (ms) | forward: 42314.22 | backward: 18116.14 | allreduce: 0.00 | optimizer: 114.23 | data loader: 1.05
[2025-03-17 05:54:43,116] [INFO] [RANK 0]  iteration      183/   30000 | elapsed time per iteration (ms): 65963.7 | learning rate 6.133E-06 | total loss 7.487836E-02 | loss 7.487836E-02 |speed 0.91 samples/(min*GPU)
[2025-03-17 05:54:43,123] [INFO] [RANK 0] time (ms) | forward: 47435.02 | backward: 18307.00 | allreduce: 0.00 | optimizer: 211.04 | data loader: 0.91
[2025-03-17 05:55:49,477] [INFO] [RANK 0]  iteration      184/   30000 | elapsed time per iteration (ms): 66361.0 | learning rate 6.167E-06 | total loss 6.308104E-02 | loss 6.308104E-02 |speed 0.90 samples/(min*GPU)
[2025-03-17 05:55:49,482] [INFO] [RANK 0] time (ms) | forward: 41556.49 | backward: 17839.12 | allreduce: 0.00 | optimizer: 48.80 | data loader: 1.87
[2025-03-17 05:56:52,320] [INFO] [RANK 0]  iteration      185/   30000 | elapsed time per iteration (ms): 62842.9 | learning rate 6.200E-06 | total loss 8.661517E-02 | loss 8.661517E-02 |speed 0.95 samples/(min*GPU)
[2025-03-17 05:56:52,330] [INFO] [RANK 0] time (ms) | forward: 43141.60 | backward: 16871.17 | allreduce: 0.00 | optimizer: 103.39 | data loader: 1.17
[2025-03-17 05:57:55,982] [INFO] [RANK 0]  iteration      186/   30000 | elapsed time per iteration (ms): 63661.9 | learning rate 6.233E-06 | total loss 7.477074E-02 | loss 7.477074E-02 |speed 0.94 samples/(min*GPU)
[2025-03-17 05:57:55,988] [INFO] [RANK 0] time (ms) | forward: 36166.80 | backward: 18148.83 | allreduce: 0.00 | optimizer: 96.07 | data loader: 98.10
[2025-03-17 05:59:03,419] [INFO] [RANK 0]  iteration      187/   30000 | elapsed time per iteration (ms): 67436.5 | learning rate 6.267E-06 | total loss 1.213793E-01 | loss 1.213793E-01 |speed 0.89 samples/(min*GPU)
[2025-03-17 05:59:03,434] [INFO] [RANK 0] time (ms) | forward: 48997.53 | backward: 18149.53 | allreduce: 0.00 | optimizer: 127.23 | data loader: 3.86
[2025-03-17 06:00:12,765] [INFO] [RANK 0]  iteration      188/   30000 | elapsed time per iteration (ms): 69345.8 | learning rate 6.300E-06 | total loss 6.927467E-02 | loss 6.927467E-02 |speed 0.87 samples/(min*GPU)
[2025-03-17 06:00:12,776] [INFO] [RANK 0] time (ms) | forward: 49688.98 | backward: 19414.98 | allreduce: 0.00 | optimizer: 130.49 | data loader: 2.24
[2025-03-17 06:01:18,696] [INFO] [RANK 0]  iteration      189/   30000 | elapsed time per iteration (ms): 65931.7 | learning rate 6.333E-06 | total loss 7.045243E-02 | loss 7.045243E-02 |speed 0.91 samples/(min*GPU)
[2025-03-17 06:01:18,701] [INFO] [RANK 0] time (ms) | forward: 47723.24 | backward: 17932.04 | allreduce: 0.00 | optimizer: 251.62 | data loader: 23.19
[2025-03-17 06:02:22,695] [INFO] [RANK 0]  iteration      190/   30000 | elapsed time per iteration (ms): 63998.3 | learning rate 6.367E-06 | total loss 1.142249E-01 | loss 1.142249E-01 |speed 0.94 samples/(min*GPU)
[2025-03-17 06:02:22,713] [INFO] [RANK 0] time (ms) | forward: 43522.66 | backward: 17474.67 | allreduce: 0.00 | optimizer: 56.76 | data loader: 4.72
[2025-03-17 06:03:32,282] [INFO] [RANK 0]  iteration      191/   30000 | elapsed time per iteration (ms): 69587.2 | learning rate 6.400E-06 | total loss 6.840146E-02 | loss 6.840146E-02 |speed 0.86 samples/(min*GPU)
[2025-03-17 06:03:32,289] [INFO] [RANK 0] time (ms) | forward: 44126.60 | backward: 20419.33 | allreduce: 0.00 | optimizer: 149.24 | data loader: 0.52
[2025-03-17 06:04:34,885] [INFO] [RANK 0]  iteration      192/   30000 | elapsed time per iteration (ms): 62577.0 | learning rate 6.433E-06 | total loss 6.872813E-02 | loss 6.872813E-02 |speed 0.96 samples/(min*GPU)
[2025-03-17 06:04:34,892] [INFO] [RANK 0] time (ms) | forward: 34812.50 | backward: 18935.22 | allreduce: 0.00 | optimizer: 100.87 | data loader: 8.04
[2025-03-17 06:05:38,896] [INFO] [RANK 0]  iteration      193/   30000 | elapsed time per iteration (ms): 64037.0 | learning rate 6.467E-06 | total loss 8.995162E-02 | loss 8.995162E-02 |speed 0.94 samples/(min*GPU)
[2025-03-17 06:05:38,897] [INFO] [RANK 0] time (ms) | forward: 40897.23 | backward: 15575.87 | allreduce: 0.00 | optimizer: 105.48 | data loader: 4.37
[2025-03-17 06:06:47,302] [INFO] [RANK 0]  iteration      194/   30000 | elapsed time per iteration (ms): 68405.7 | learning rate 6.500E-06 | total loss 8.364323E-02 | loss 8.364323E-02 |speed 0.88 samples/(min*GPU)
[2025-03-17 06:06:47,314] [INFO] [RANK 0] time (ms) | forward: 44933.44 | backward: 18903.80 | allreduce: 0.00 | optimizer: 63.42 | data loader: 0.26
[2025-03-17 06:07:48,931] [INFO] [RANK 0]  iteration      195/   30000 | elapsed time per iteration (ms): 61629.1 | learning rate 6.533E-06 | total loss 7.317087E-02 | loss 7.317087E-02 |speed 0.97 samples/(min*GPU)
[2025-03-17 06:07:48,935] [INFO] [RANK 0] time (ms) | forward: 37978.95 | backward: 18298.77 | allreduce: 0.00 | optimizer: 202.82 | data loader: 8.37
[2025-03-17 06:08:50,451] [INFO] [RANK 0]  iteration      196/   30000 | elapsed time per iteration (ms): 61520.4 | learning rate 6.567E-06 | total loss 8.245097E-02 | loss 8.245097E-02 |speed 0.98 samples/(min*GPU)
[2025-03-17 06:08:50,457] [INFO] [RANK 0] time (ms) | forward: 43882.23 | backward: 17351.49 | allreduce: 0.00 | optimizer: 265.43 | data loader: 0.48
[2025-03-17 06:09:55,752] [INFO] [RANK 0]  iteration      197/   30000 | elapsed time per iteration (ms): 65300.2 | learning rate 6.600E-06 | total loss 7.549693E-02 | loss 7.549693E-02 |speed 0.92 samples/(min*GPU)
[2025-03-17 06:09:55,756] [INFO] [RANK 0] time (ms) | forward: 37339.93 | backward: 17997.09 | allreduce: 0.00 | optimizer: 60.61 | data loader: 1.18
[2025-03-17 06:11:02,297] [INFO] [RANK 0]  iteration      198/   30000 | elapsed time per iteration (ms): 66545.0 | learning rate 6.633E-06 | total loss 7.129727E-02 | loss 7.129727E-02 |speed 0.90 samples/(min*GPU)
[2025-03-17 06:11:02,319] [INFO] [RANK 0] time (ms) | forward: 40948.30 | backward: 20017.90 | allreduce: 0.00 | optimizer: 204.90 | data loader: 1.54
[2025-03-17 06:12:08,182] [INFO] [RANK 0]  iteration      199/   30000 | elapsed time per iteration (ms): 65885.2 | learning rate 6.667E-06 | total loss 8.254994E-02 | loss 8.254994E-02 |speed 0.91 samples/(min*GPU)
[2025-03-17 06:12:08,201] [INFO] [RANK 0] time (ms) | forward: 43129.40 | backward: 19069.66 | allreduce: 0.00 | optimizer: 53.64 | data loader: 1.45
[2025-03-17 06:13:14,130] [INFO] [logging.py:128:log_dist] [Rank 0] step=200, skipped=0, lr=[6.666666666666667e-06, 6.666666666666667e-06], mom=[[0.9, 0.95], [0.9, 0.95]]
[2025-03-17 06:13:14,165] [INFO] [RANK 0]  iteration      200/   30000 | elapsed time per iteration (ms): 65982.9 | learning rate 6.700E-06 | total loss 9.023578E-02 | loss 9.023578E-02 |speed 0.91 samples/(min*GPU)
[2025-03-17 06:13:14,174] [INFO] [RANK 0] time (ms) | forward: 40689.91 | backward: 17494.57 | allreduce: 0.00 | optimizer: 57.42 | data loader: 1.85
[2025-03-17 06:14:21,492] [INFO] [RANK 0]  iteration      201/   30000 | elapsed time per iteration (ms): 67327.4 | learning rate 6.733E-06 | total loss 1.086644E-01 | loss 1.086644E-01 |speed 0.89 samples/(min*GPU)
[2025-03-17 06:14:21,505] [INFO] [RANK 0] time (ms) | forward: 45430.62 | backward: 19102.75 | allreduce: 0.00 | optimizer: 150.90 | data loader: 0.97
[2025-03-17 06:15:27,782] [INFO] [RANK 0]  iteration      202/   30000 | elapsed time per iteration (ms): 66289.7 | learning rate 6.767E-06 | total loss 1.217282E-01 | loss 1.217282E-01 |speed 0.91 samples/(min*GPU)
[2025-03-17 06:15:27,789] [INFO] [RANK 0] time (ms) | forward: 44812.00 | backward: 19504.05 | allreduce: 0.00 | optimizer: 200.42 | data loader: 4.41
[2025-03-17 06:16:35,824] [INFO] [RANK 0]  iteration      203/   30000 | elapsed time per iteration (ms): 68041.8 | learning rate 6.800E-06 | total loss 8.279845E-02 | loss 8.279845E-02 |speed 0.88 samples/(min*GPU)
[2025-03-17 06:16:35,828] [INFO] [RANK 0] time (ms) | forward: 42344.67 | backward: 18170.06 | allreduce: 0.00 | optimizer: 219.49 | data loader: 0.99
[2025-03-17 06:17:42,581] [INFO] [RANK 0]  iteration      204/   30000 | elapsed time per iteration (ms): 66757.7 | learning rate 6.833E-06 | total loss 6.854398E-02 | loss 6.854398E-02 |speed 0.90 samples/(min*GPU)
[2025-03-17 06:17:42,598] [INFO] [RANK 0] time (ms) | forward: 44898.48 | backward: 20172.51 | allreduce: 0.00 | optimizer: 97.81 | data loader: 2.36
[2025-03-17 06:18:50,250] [INFO] [RANK 0]  iteration      205/   30000 | elapsed time per iteration (ms): 67668.9 | learning rate 6.867E-06 | total loss 7.032621E-02 | loss 7.032621E-02 |speed 0.89 samples/(min*GPU)
[2025-03-17 06:18:50,299] [INFO] [RANK 0] time (ms) | forward: 45717.11 | backward: 18354.18 | allreduce: 0.00 | optimizer: 106.79 | data loader: 3.42
[2025-03-17 06:19:56,514] [INFO] [RANK 0]  iteration      206/   30000 | elapsed time per iteration (ms): 66263.5 | learning rate 6.900E-06 | total loss 7.533236E-02 | loss 7.533236E-02 |speed 0.91 samples/(min*GPU)
[2025-03-17 06:19:56,523] [INFO] [RANK 0] time (ms) | forward: 46612.87 | backward: 16699.66 | allreduce: 0.00 | optimizer: 210.68 | data loader: 2.33
[2025-03-17 06:21:07,182] [INFO] [RANK 0]  iteration      207/   30000 | elapsed time per iteration (ms): 70667.9 | learning rate 6.933E-06 | total loss 6.200978E-02 | loss 6.200978E-02 |speed 0.85 samples/(min*GPU)
[2025-03-17 06:21:07,188] [INFO] [RANK 0] time (ms) | forward: 48188.65 | backward: 21812.06 | allreduce: 0.00 | optimizer: 251.91 | data loader: 1.44
[2025-03-17 06:22:09,426] [INFO] [RANK 0]  iteration      208/   30000 | elapsed time per iteration (ms): 62244.6 | learning rate 6.967E-06 | total loss 6.587991E-02 | loss 6.587991E-02 |speed 0.96 samples/(min*GPU)
[2025-03-17 06:22:09,430] [INFO] [RANK 0] time (ms) | forward: 37217.75 | backward: 19534.74 | allreduce: 0.00 | optimizer: 142.74 | data loader: 1.03
[2025-03-17 06:23:15,706] [INFO] [RANK 0]  iteration      209/   30000 | elapsed time per iteration (ms): 66279.3 | learning rate 7.000E-06 | total loss 6.987166E-02 | loss 6.987166E-02 |speed 0.91 samples/(min*GPU)
[2025-03-17 06:23:15,717] [INFO] [RANK 0] time (ms) | forward: 36212.80 | backward: 16628.64 | allreduce: 0.00 | optimizer: 63.70 | data loader: 0.75
[2025-03-17 06:24:27,425] [INFO] [RANK 0]  iteration      210/   30000 | elapsed time per iteration (ms): 71719.0 | learning rate 7.033E-06 | total loss 8.025921E-02 | loss 8.025921E-02 |speed 0.84 samples/(min*GPU)
[2025-03-17 06:24:27,434] [INFO] [RANK 0] time (ms) | forward: 41738.05 | backward: 22878.42 | allreduce: 0.00 | optimizer: 56.19 | data loader: 1.91
[2025-03-17 06:25:30,410] [INFO] [RANK 0]  iteration      211/   30000 | elapsed time per iteration (ms): 62985.5 | learning rate 7.067E-06 | total loss 8.826834E-02 | loss 8.826834E-02 |speed 0.95 samples/(min*GPU)
[2025-03-17 06:25:30,417] [INFO] [RANK 0] time (ms) | forward: 37591.44 | backward: 18360.73 | allreduce: 0.00 | optimizer: 111.57 | data loader: 0.50
[2025-03-17 06:26:36,534] [INFO] [RANK 0]  iteration      212/   30000 | elapsed time per iteration (ms): 66123.7 | learning rate 7.100E-06 | total loss 7.073385E-02 | loss 7.073385E-02 |speed 0.91 samples/(min*GPU)
[2025-03-17 06:26:36,551] [INFO] [RANK 0] time (ms) | forward: 43612.84 | backward: 18303.48 | allreduce: 0.00 | optimizer: 136.76 | data loader: 2.46
[2025-03-17 06:27:47,775] [INFO] [RANK 0]  iteration      213/   30000 | elapsed time per iteration (ms): 71240.7 | learning rate 7.133E-06 | total loss 7.391522E-02 | loss 7.391522E-02 |speed 0.84 samples/(min*GPU)
[2025-03-17 06:27:47,782] [INFO] [RANK 0] time (ms) | forward: 48636.27 | backward: 21666.95 | allreduce: 0.00 | optimizer: 144.98 | data loader: 0.73
[2025-03-17 06:28:46,202] [INFO] [RANK 0]  iteration      214/   30000 | elapsed time per iteration (ms): 58427.4 | learning rate 7.167E-06 | total loss 7.798323E-02 | loss 7.798323E-02 |speed 1.03 samples/(min*GPU)
[2025-03-17 06:28:46,210] [INFO] [RANK 0] time (ms) | forward: 39738.92 | backward: 18562.97 | allreduce: 0.00 | optimizer: 110.67 | data loader: 0.56
[2025-03-17 06:29:48,910] [INFO] [RANK 0]  iteration      215/   30000 | elapsed time per iteration (ms): 62707.7 | learning rate 7.200E-06 | total loss 7.274742E-02 | loss 7.274742E-02 |speed 0.96 samples/(min*GPU)
[2025-03-17 06:29:48,917] [INFO] [RANK 0] time (ms) | forward: 35627.13 | backward: 16534.04 | allreduce: 0.00 | optimizer: 141.17 | data loader: 1.44
[2025-03-17 06:30:51,602] [INFO] [RANK 0]  iteration      216/   30000 | elapsed time per iteration (ms): 62691.8 | learning rate 7.233E-06 | total loss 7.394554E-02 | loss 7.394554E-02 |speed 0.96 samples/(min*GPU)
[2025-03-17 06:30:51,610] [INFO] [RANK 0] time (ms) | forward: 39912.55 | backward: 16569.56 | allreduce: 0.00 | optimizer: 101.74 | data loader: 1.71
[2025-03-17 06:32:01,289] [INFO] [RANK 0]  iteration      217/   30000 | elapsed time per iteration (ms): 69687.8 | learning rate 7.267E-06 | total loss 9.351967E-02 | loss 9.351967E-02 |speed 0.86 samples/(min*GPU)
[2025-03-17 06:32:01,293] [INFO] [RANK 0] time (ms) | forward: 44127.45 | backward: 20794.27 | allreduce: 0.00 | optimizer: 60.99 | data loader: 1.01
[2025-03-17 06:33:05,931] [INFO] [RANK 0]  iteration      218/   30000 | elapsed time per iteration (ms): 64641.3 | learning rate 7.300E-06 | total loss 6.978083E-02 | loss 6.978083E-02 |speed 0.93 samples/(min*GPU)
[2025-03-17 06:33:05,934] [INFO] [RANK 0] time (ms) | forward: 36050.13 | backward: 18798.91 | allreduce: 0.00 | optimizer: 52.13 | data loader: 0.91
[2025-03-17 06:34:15,202] [INFO] [RANK 0]  iteration      219/   30000 | elapsed time per iteration (ms): 69271.5 | learning rate 7.333E-06 | total loss 7.770772E-02 | loss 7.770772E-02 |speed 0.87 samples/(min*GPU)
[2025-03-17 06:34:15,214] [INFO] [RANK 0] time (ms) | forward: 50785.27 | backward: 18132.83 | allreduce: 0.00 | optimizer: 341.27 | data loader: 0.43
[2025-03-17 06:35:22,952] [INFO] [RANK 0]  iteration      220/   30000 | elapsed time per iteration (ms): 67749.9 | learning rate 7.367E-06 | total loss 1.280238E-01 | loss 1.280238E-01 |speed 0.89 samples/(min*GPU)
[2025-03-17 06:35:23,002] [INFO] [RANK 0] time (ms) | forward: 46199.92 | backward: 19188.63 | allreduce: 0.00 | optimizer: 121.83 | data loader: 0.79
[2025-03-17 06:36:25,082] [INFO] [RANK 0]  iteration      221/   30000 | elapsed time per iteration (ms): 62129.6 | learning rate 7.400E-06 | total loss 6.777629E-02 | loss 6.777629E-02 |speed 0.97 samples/(min*GPU)
[2025-03-17 06:36:25,087] [INFO] [RANK 0] time (ms) | forward: 36725.07 | backward: 17980.13 | allreduce: 0.00 | optimizer: 173.03 | data loader: 7.52
[2025-03-17 06:37:31,822] [INFO] [RANK 0]  iteration      222/   30000 | elapsed time per iteration (ms): 66739.5 | learning rate 7.433E-06 | total loss 9.300923E-02 | loss 9.300923E-02 |speed 0.90 samples/(min*GPU)
[2025-03-17 06:37:31,832] [INFO] [RANK 0] time (ms) | forward: 37242.53 | backward: 18900.08 | allreduce: 0.00 | optimizer: 158.51 | data loader: 3.50
[2025-03-17 06:38:41,895] [INFO] [RANK 0]  iteration      223/   30000 | elapsed time per iteration (ms): 70059.6 | learning rate 7.467E-06 | total loss 8.975758E-02 | loss 8.975758E-02 |speed 0.86 samples/(min*GPU)
[2025-03-17 06:38:41,902] [INFO] [RANK 0] time (ms) | forward: 49069.41 | backward: 20186.77 | allreduce: 0.00 | optimizer: 108.20 | data loader: 3.25
[2025-03-17 06:39:48,007] [INFO] [RANK 0]  iteration      224/   30000 | elapsed time per iteration (ms): 66126.2 | learning rate 7.500E-06 | total loss 8.795051E-02 | loss 8.795051E-02 |speed 0.91 samples/(min*GPU)
[2025-03-17 06:39:48,017] [INFO] [RANK 0] time (ms) | forward: 37996.78 | backward: 19229.85 | allreduce: 0.00 | optimizer: 336.97 | data loader: 1.07
[2025-03-17 06:40:56,017] [INFO] [RANK 0]  iteration      225/   30000 | elapsed time per iteration (ms): 68009.4 | learning rate 7.533E-06 | total loss 7.304692E-02 | loss 7.304692E-02 |speed 0.88 samples/(min*GPU)
[2025-03-17 06:40:56,021] [INFO] [RANK 0] time (ms) | forward: 41802.46 | backward: 17128.20 | allreduce: 0.00 | optimizer: 125.07 | data loader: 1.23
[2025-03-17 06:42:06,310] [INFO] [RANK 0]  iteration      226/   30000 | elapsed time per iteration (ms): 70284.2 | learning rate 7.567E-06 | total loss 6.815895E-02 | loss 6.815895E-02 |speed 0.85 samples/(min*GPU)
[2025-03-17 06:42:06,321] [INFO] [RANK 0] time (ms) | forward: 47299.19 | backward: 19779.27 | allreduce: 0.00 | optimizer: 54.47 | data loader: 2.38
[2025-03-17 06:43:14,072] [INFO] [RANK 0]  iteration      227/   30000 | elapsed time per iteration (ms): 67770.7 | learning rate 7.600E-06 | total loss 7.258119E-02 | loss 7.258119E-02 |speed 0.89 samples/(min*GPU)
[2025-03-17 06:43:14,101] [INFO] [RANK 0] time (ms) | forward: 44581.57 | backward: 20068.49 | allreduce: 0.00 | optimizer: 72.05 | data loader: 1.30
[2025-03-17 06:44:15,124] [INFO] [RANK 0]  iteration      228/   30000 | elapsed time per iteration (ms): 61052.6 | learning rate 7.633E-06 | total loss 1.039799E-01 | loss 1.039799E-01 |speed 0.98 samples/(min*GPU)
[2025-03-17 06:44:15,134] [INFO] [RANK 0] time (ms) | forward: 37942.98 | backward: 17439.74 | allreduce: 0.00 | optimizer: 174.73 | data loader: 0.97
[2025-03-17 06:45:20,992] [INFO] [RANK 0]  iteration      229/   30000 | elapsed time per iteration (ms): 65867.2 | learning rate 7.667E-06 | total loss 8.348192E-02 | loss 8.348192E-02 |speed 0.91 samples/(min*GPU)
[2025-03-17 06:45:21,009] [INFO] [RANK 0] time (ms) | forward: 42696.13 | backward: 16602.19 | allreduce: 0.00 | optimizer: 96.22 | data loader: 9.04
[2025-03-17 06:46:31,297] [INFO] [RANK 0]  iteration      230/   30000 | elapsed time per iteration (ms): 70305.3 | learning rate 7.700E-06 | total loss 9.372893E-02 | loss 9.372893E-02 |speed 0.85 samples/(min*GPU)
[2025-03-17 06:46:31,300] [INFO] [RANK 0] time (ms) | forward: 44488.44 | backward: 21671.07 | allreduce: 0.00 | optimizer: 112.99 | data loader: 6.37
[2025-03-17 06:47:31,496] [INFO] [RANK 0]  iteration      231/   30000 | elapsed time per iteration (ms): 60199.2 | learning rate 7.733E-06 | total loss 7.483774E-02 | loss 7.483774E-02 |speed 1.00 samples/(min*GPU)
[2025-03-17 06:47:31,500] [INFO] [RANK 0] time (ms) | forward: 37039.84 | backward: 17865.72 | allreduce: 0.00 | optimizer: 139.62 | data loader: 2.07
[2025-03-17 06:48:36,528] [INFO] [RANK 0]  iteration      232/   30000 | elapsed time per iteration (ms): 65031.8 | learning rate 7.767E-06 | total loss 1.075004E-01 | loss 1.075004E-01 |speed 0.92 samples/(min*GPU)
[2025-03-17 06:48:36,545] [INFO] [RANK 0] time (ms) | forward: 47938.11 | backward: 16805.07 | allreduce: 0.00 | optimizer: 207.52 | data loader: 0.95
[2025-03-17 06:49:43,720] [INFO] [RANK 0]  iteration      233/   30000 | elapsed time per iteration (ms): 67192.3 | learning rate 7.800E-06 | total loss 9.019035E-02 | loss 9.019035E-02 |speed 0.89 samples/(min*GPU)
[2025-03-17 06:49:43,738] [INFO] [RANK 0] time (ms) | forward: 45856.08 | backward: 17685.12 | allreduce: 0.00 | optimizer: 382.92 | data loader: 1.28
[2025-03-17 06:50:52,940] [INFO] [RANK 0]  iteration      234/   30000 | elapsed time per iteration (ms): 69219.7 | learning rate 7.833E-06 | total loss 7.907957E-02 | loss 7.907957E-02 |speed 0.87 samples/(min*GPU)
[2025-03-17 06:50:52,999] [INFO] [RANK 0] time (ms) | forward: 42143.21 | backward: 19963.41 | allreduce: 0.00 | optimizer: 80.33 | data loader: 4.08
[2025-03-17 06:51:58,133] [INFO] [RANK 0]  iteration      235/   30000 | elapsed time per iteration (ms): 65193.5 | learning rate 7.867E-06 | total loss 8.542462E-02 | loss 8.542462E-02 |speed 0.92 samples/(min*GPU)
[2025-03-17 06:51:58,143] [INFO] [RANK 0] time (ms) | forward: 36886.38 | backward: 19653.01 | allreduce: 0.00 | optimizer: 163.56 | data loader: 0.78
[2025-03-17 06:53:05,126] [INFO] [RANK 0]  iteration      236/   30000 | elapsed time per iteration (ms): 66992.5 | learning rate 7.900E-06 | total loss 8.135708E-02 | loss 8.135708E-02 |speed 0.90 samples/(min*GPU)
[2025-03-17 06:53:05,137] [INFO] [RANK 0] time (ms) | forward: 41713.31 | backward: 17976.68 | allreduce: 0.00 | optimizer: 134.94 | data loader: 7.59
[2025-03-17 06:54:13,961] [INFO] [RANK 0]  iteration      237/   30000 | elapsed time per iteration (ms): 68835.4 | learning rate 7.933E-06 | total loss 7.483384E-02 | loss 7.483384E-02 |speed 0.87 samples/(min*GPU)
[2025-03-17 06:54:14,110] [INFO] [RANK 0] time (ms) | forward: 42419.99 | backward: 19007.07 | allreduce: 0.00 | optimizer: 93.72 | data loader: 3.52
[2025-03-17 06:55:17,919] [INFO] [RANK 0]  iteration      238/   30000 | elapsed time per iteration (ms): 63958.1 | learning rate 7.967E-06 | total loss 7.223272E-02 | loss 7.223272E-02 |speed 0.94 samples/(min*GPU)
[2025-03-17 06:55:17,932] [INFO] [RANK 0] time (ms) | forward: 41981.58 | backward: 19731.28 | allreduce: 0.00 | optimizer: 51.67 | data loader: 0.66
[2025-03-17 06:56:24,309] [INFO] [RANK 0]  iteration      239/   30000 | elapsed time per iteration (ms): 66388.4 | learning rate 8.000E-06 | total loss 8.634244E-02 | loss 8.634244E-02 |speed 0.90 samples/(min*GPU)
[2025-03-17 06:56:24,314] [INFO] [RANK 0] time (ms) | forward: 42373.58 | backward: 15294.31 | allreduce: 0.00 | optimizer: 172.85 | data loader: 0.55
[2025-03-17 06:57:31,004] [INFO] [RANK 0]  iteration      240/   30000 | elapsed time per iteration (ms): 66693.1 | learning rate 8.033E-06 | total loss 6.509108E-02 | loss 6.509108E-02 |speed 0.90 samples/(min*GPU)
[2025-03-17 06:57:31,018] [INFO] [RANK 0] time (ms) | forward: 41590.65 | backward: 18271.11 | allreduce: 0.00 | optimizer: 49.94 | data loader: 1.29
[2025-03-17 06:58:36,082] [INFO] [RANK 0]  iteration      241/   30000 | elapsed time per iteration (ms): 65080.9 | learning rate 8.067E-06 | total loss 8.021290E-02 | loss 8.021290E-02 |speed 0.92 samples/(min*GPU)
[2025-03-17 06:58:36,104] [INFO] [RANK 0] time (ms) | forward: 42769.54 | backward: 17740.98 | allreduce: 0.00 | optimizer: 239.14 | data loader: 3.35
[2025-03-17 06:59:42,535] [INFO] [RANK 0]  iteration      242/   30000 | elapsed time per iteration (ms): 66452.9 | learning rate 8.100E-06 | total loss 8.816442E-02 | loss 8.816442E-02 |speed 0.90 samples/(min*GPU)
[2025-03-17 06:59:42,540] [INFO] [RANK 0] time (ms) | forward: 41949.95 | backward: 16131.95 | allreduce: 0.00 | optimizer: 102.66 | data loader: 0.89
[2025-03-17 07:00:46,381] [INFO] [RANK 0]  iteration      243/   30000 | elapsed time per iteration (ms): 63846.4 | learning rate 8.133E-06 | total loss 8.570842E-02 | loss 8.570842E-02 |speed 0.94 samples/(min*GPU)
[2025-03-17 07:00:46,382] [INFO] [RANK 0] time (ms) | forward: 39801.78 | backward: 15599.25 | allreduce: 0.00 | optimizer: 68.76 | data loader: 3.05
[2025-03-17 07:01:55,895] [INFO] [RANK 0]  iteration      244/   30000 | elapsed time per iteration (ms): 69514.2 | learning rate 8.167E-06 | total loss 6.715225E-02 | loss 6.715225E-02 |speed 0.86 samples/(min*GPU)
[2025-03-17 07:01:55,917] [INFO] [RANK 0] time (ms) | forward: 47187.01 | backward: 21067.18 | allreduce: 0.00 | optimizer: 72.57 | data loader: 0.33
[2025-03-17 07:02:58,316] [INFO] [RANK 0]  iteration      245/   30000 | elapsed time per iteration (ms): 62420.6 | learning rate 8.200E-06 | total loss 7.183392E-02 | loss 7.183392E-02 |speed 0.96 samples/(min*GPU)
[2025-03-17 07:02:58,325] [INFO] [RANK 0] time (ms) | forward: 38894.67 | backward: 19282.10 | allreduce: 0.00 | optimizer: 144.77 | data loader: 2.27
[2025-03-17 07:04:05,984] [INFO] [RANK 0]  iteration      246/   30000 | elapsed time per iteration (ms): 67668.0 | learning rate 8.233E-06 | total loss 8.953354E-02 | loss 8.953354E-02 |speed 0.89 samples/(min*GPU)
[2025-03-17 07:04:05,996] [INFO] [RANK 0] time (ms) | forward: 46026.90 | backward: 17800.08 | allreduce: 0.00 | optimizer: 229.23 | data loader: 0.79
[2025-03-17 07:05:17,789] [INFO] [RANK 0]  iteration      247/   30000 | elapsed time per iteration (ms): 71805.2 | learning rate 8.267E-06 | total loss 8.621602E-02 | loss 8.621602E-02 |speed 0.84 samples/(min*GPU)
[2025-03-17 07:05:17,818] [INFO] [RANK 0] time (ms) | forward: 40231.86 | backward: 20959.81 | allreduce: 0.00 | optimizer: 197.49 | data loader: 0.80
[2025-03-17 07:06:21,748] [INFO] [RANK 0]  iteration      248/   30000 | elapsed time per iteration (ms): 63959.3 | learning rate 8.300E-06 | total loss 6.497955E-02 | loss 6.497955E-02 |speed 0.94 samples/(min*GPU)
[2025-03-17 07:06:21,810] [INFO] [RANK 0] time (ms) | forward: 40949.94 | backward: 19218.86 | allreduce: 0.00 | optimizer: 112.97 | data loader: 2.38
[2025-03-17 07:07:24,914] [INFO] [RANK 0]  iteration      249/   30000 | elapsed time per iteration (ms): 63165.3 | learning rate 8.333E-06 | total loss 7.569068E-02 | loss 7.569068E-02 |speed 0.95 samples/(min*GPU)
[2025-03-17 07:07:24,928] [INFO] [RANK 0] time (ms) | forward: 41408.43 | backward: 18375.87 | allreduce: 0.00 | optimizer: 112.41 | data loader: 1.49
[2025-03-17 07:08:30,412] [INFO] [logging.py:128:log_dist] [Rank 0] step=250, skipped=0, lr=[8.333333333333334e-06, 8.333333333333334e-06], mom=[[0.9, 0.95], [0.9, 0.95]]
[2025-03-17 07:08:30,451] [INFO] [RANK 0]  iteration      250/   30000 | elapsed time per iteration (ms): 65537.0 | learning rate 8.367E-06 | total loss 6.928904E-02 | loss 6.928904E-02 |speed 0.92 samples/(min*GPU)
[2025-03-17 07:08:30,452] [INFO] [RANK 0] time (ms) | forward: 45764.56 | backward: 16590.22 | allreduce: 0.00 | optimizer: 61.31 | data loader: 2.22
[2025-03-17 07:08:30,452] [INFO] [RANK 0] Saving Model...
[2025-03-17 07:09:04,815] [INFO] [logging.py:128:log_dist] [Rank 0] Saving model checkpoint: stage-2/train-stage-2-03-17-02-27/250/mp_rank_00_model_states.pt
[2025-03-17 07:09:04,816] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving stage-2/train-stage-2-03-17-02-27/250/mp_rank_00_model_states.pt...
[2025-03-17 07:13:43,929] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved stage-2/train-stage-2-03-17-02-27/250/mp_rank_00_model_states.pt.
[2025-03-17 07:13:44,861] [INFO] [RANK 0] Saving Ema Model...
[2025-03-17 07:14:21,494] [INFO] [logging.py:128:log_dist] [Rank 0] Saving model checkpoint: stage-2/train-stage-2-03-17-02-27/250-ema/mp_rank_00_model_states.pt
[2025-03-17 07:14:21,496] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving stage-2/train-stage-2-03-17-02-27/250-ema/mp_rank_00_model_states.pt...
[rank1]:[E317 07:18:30.480148803 ProcessGroupNCCL.cpp:607] [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=4852, OpType=_ALLGATHER_BASE, NumelIn=279412736, NumelOut=2235301888, Timeout(ms)=600000) ran for 600162 milliseconds before timing out.
[rank1]:[E317 07:18:30.480187296 ProcessGroupNCCL.cpp:607] [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=888, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600162 milliseconds before timing out.
[rank5]:[E317 07:18:30.480182076 ProcessGroupNCCL.cpp:607] [Rank 5] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=888, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600160 milliseconds before timing out.
[rank2]:[E317 07:18:30.480231790 ProcessGroupNCCL.cpp:607] [Rank 2] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=888, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600155 milliseconds before timing out.
[rank2]:[E317 07:18:30.480453244 ProcessGroupNCCL.cpp:607] [Rank 2] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=4852, OpType=_ALLGATHER_BASE, NumelIn=279412736, NumelOut=2235301888, Timeout(ms)=600000) ran for 600155 milliseconds before timing out.
[rank7]:[E317 07:18:30.480387903 ProcessGroupNCCL.cpp:607] [Rank 7] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=4852, OpType=_ALLGATHER_BASE, NumelIn=279412736, NumelOut=2235301888, Timeout(ms)=600000) ran for 600159 milliseconds before timing out.
[rank3]:[E317 07:18:30.480401894 ProcessGroupNCCL.cpp:607] [Rank 3] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=888, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600160 milliseconds before timing out.
[rank7]:[E317 07:18:30.480446550 ProcessGroupNCCL.cpp:607] [Rank 7] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=888, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600159 milliseconds before timing out.
[rank3]:[E317 07:18:30.480585898 ProcessGroupNCCL.cpp:607] [Rank 3] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=4852, OpType=_ALLGATHER_BASE, NumelIn=279412736, NumelOut=2235301888, Timeout(ms)=600000) ran for 600160 milliseconds before timing out.
[rank6]:[E317 07:18:30.480505171 ProcessGroupNCCL.cpp:607] [Rank 6] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=4852, OpType=_ALLGATHER_BASE, NumelIn=279412736, NumelOut=2235301888, Timeout(ms)=600000) ran for 600160 milliseconds before timing out.
[rank2]:[E317 07:18:30.499225350 ProcessGroupNCCL.cpp:1664] [PG 0 (default_pg) Rank 2] Exception (either an error or timeout) detected by watchdog at work: 888, last enqueued NCCL work: 888, last completed NCCL work: 887.
[rank6]:[E317 07:18:30.480562392 ProcessGroupNCCL.cpp:607] [Rank 6] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=888, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600158 milliseconds before timing out.
[rank7]:[E317 07:18:30.499304358 ProcessGroupNCCL.cpp:1664] [PG 0 (default_pg) Rank 7] Exception (either an error or timeout) detected by watchdog at work: 888, last enqueued NCCL work: 888, last completed NCCL work: 887.
[rank4]:[E317 07:18:30.480970336 ProcessGroupNCCL.cpp:607] [Rank 4] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=888, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600162 milliseconds before timing out.
[rank3]:[E317 07:18:30.499384987 ProcessGroupNCCL.cpp:1664] [PG 1 Rank 3] Exception (either an error or timeout) detected by watchdog at work: 4852, last enqueued NCCL work: 4853, last completed NCCL work: 4851.
[rank1]:[E317 07:18:30.498619525 ProcessGroupNCCL.cpp:1664] [PG 1 Rank 1] Exception (either an error or timeout) detected by watchdog at work: 4852, last enqueued NCCL work: 4853, last completed NCCL work: 4851.
[rank4]:[E317 07:18:30.481097198 ProcessGroupNCCL.cpp:607] [Rank 4] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=4852, OpType=_ALLGATHER_BASE, NumelIn=279412736, NumelOut=2235301888, Timeout(ms)=600000) ran for 600162 milliseconds before timing out.
[rank5]:[E317 07:18:30.498641917 ProcessGroupNCCL.cpp:1664] [PG 0 (default_pg) Rank 5] Exception (either an error or timeout) detected by watchdog at work: 888, last enqueued NCCL work: 888, last completed NCCL work: 887.
[rank6]:[E317 07:18:30.499479820 ProcessGroupNCCL.cpp:1664] [PG 0 (default_pg) Rank 6] Exception (either an error or timeout) detected by watchdog at work: 888, last enqueued NCCL work: 888, last completed NCCL work: 887.
[rank4]:[E317 07:18:30.499669992 ProcessGroupNCCL.cpp:1664] [PG 1 Rank 4] Exception (either an error or timeout) detected by watchdog at work: 4852, last enqueued NCCL work: 4853, last completed NCCL work: 4851.
[rank3]:[E317 07:18:30.499687484 ProcessGroupNCCL.cpp:1664] [PG 0 (default_pg) Rank 3] Exception (either an error or timeout) detected by watchdog at work: 888, last enqueued NCCL work: 888, last completed NCCL work: 887.
[rank4]:[E317 07:18:30.499674825 ProcessGroupNCCL.cpp:1664] [PG 0 (default_pg) Rank 4] Exception (either an error or timeout) detected by watchdog at work: 888, last enqueued NCCL work: 888, last completed NCCL work: 887.
[rank2]:[E317 07:18:30.499205962 ProcessGroupNCCL.cpp:1664] [PG 1 Rank 2] Exception (either an error or timeout) detected by watchdog at work: 4852, last enqueued NCCL work: 4853, last completed NCCL work: 4851.
[rank5]:[E317 07:18:30.480260933 ProcessGroupNCCL.cpp:607] [Rank 5] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=4852, OpType=_ALLGATHER_BASE, NumelIn=279412736, NumelOut=2235301888, Timeout(ms)=600000) ran for 600160 milliseconds before timing out.
[rank5]:[E317 07:18:30.500603017 ProcessGroupNCCL.cpp:1664] [PG 1 Rank 5] Exception (either an error or timeout) detected by watchdog at work: 4852, last enqueued NCCL work: 4853, last completed NCCL work: 4851.
[rank1]:[E317 07:18:30.498626466 ProcessGroupNCCL.cpp:1664] [PG 0 (default_pg) Rank 1] Exception (either an error or timeout) detected by watchdog at work: 888, last enqueued NCCL work: 888, last completed NCCL work: 887.
[rank6]:[E317 07:18:30.504113036 ProcessGroupNCCL.cpp:1664] [PG 1 Rank 6] Exception (either an error or timeout) detected by watchdog at work: 4852, last enqueued NCCL work: 4853, last completed NCCL work: 4851.
[rank7]:[E317 07:18:30.504205167 ProcessGroupNCCL.cpp:1664] [PG 1 Rank 7] Exception (either an error or timeout) detected by watchdog at work: 4852, last enqueued NCCL work: 4853, last completed NCCL work: 4851.
[rank7]:[E317 07:18:32.970501636 ProcessGroupNCCL.cpp:1709] [PG 1 Rank 7] Timeout at NCCL work: 4852, last enqueued NCCL work: 4853, last completed NCCL work: 4851.
[rank7]:[E317 07:18:32.970577412 ProcessGroupNCCL.cpp:621] [Rank 7] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank7]:[E317 07:18:32.970589584 ProcessGroupNCCL.cpp:627] [Rank 7] To avoid data inconsistency, we are taking the entire process down.
[rank7]:[E317 07:18:32.972395161 ProcessGroupNCCL.cpp:1515] [PG 1 Rank 7] Process group watchdog thread terminated with exception: [Rank 7] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=4852, OpType=_ALLGATHER_BASE, NumelIn=279412736, NumelOut=2235301888, Timeout(ms)=600000) ran for 600159 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:609 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f1fbdeadf86 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7f1fbf1aa8d2 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x233 (0x7f1fbf1b1313 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x10c (0x7f1fbf1b36fc in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xd3b65 (0x7f200c936b65 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/bin/../lib/libstdc++.so.6)
frame #5: <unknown function> + 0x8609 (0x7f2011dab609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #6: clone + 0x43 (0x7f2011b76133 in /lib/x86_64-linux-gnu/libc.so.6)

terminate called after throwing an instance of 'c10::DistBackendError'
  what():  [PG 1 Rank 7] Process group watchdog thread terminated with exception: [Rank 7] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=4852, OpType=_ALLGATHER_BASE, NumelIn=279412736, NumelOut=2235301888, Timeout(ms)=600000) ran for 600159 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:609 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f1fbdeadf86 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7f1fbf1aa8d2 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x233 (0x7f1fbf1b1313 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x10c (0x7f1fbf1b36fc in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xd3b65 (0x7f200c936b65 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/bin/../lib/libstdc++.so.6)
frame #5: <unknown function> + 0x8609 (0x7f2011dab609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #6: clone + 0x43 (0x7f2011b76133 in /lib/x86_64-linux-gnu/libc.so.6)

Exception raised from ncclCommWatchdog at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1521 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f1fbdeadf86 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0xe5aa84 (0x7f1fbee3ca84 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #2: <unknown function> + 0xd3b65 (0x7f200c936b65 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/bin/../lib/libstdc++.so.6)
frame #3: <unknown function> + 0x8609 (0x7f2011dab609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #4: clone + 0x43 (0x7f2011b76133 in /lib/x86_64-linux-gnu/libc.so.6)

[rank4]:[E317 07:18:32.019243752 ProcessGroupNCCL.cpp:1709] [PG 1 Rank 4] Timeout at NCCL work: 4852, last enqueued NCCL work: 4853, last completed NCCL work: 4851.
[rank4]:[E317 07:18:32.019316370 ProcessGroupNCCL.cpp:621] [Rank 4] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank4]:[E317 07:18:32.019328173 ProcessGroupNCCL.cpp:627] [Rank 4] To avoid data inconsistency, we are taking the entire process down.
[rank4]:[E317 07:18:32.020941946 ProcessGroupNCCL.cpp:1515] [PG 1 Rank 4] Process group watchdog thread terminated with exception: [Rank 4] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=4852, OpType=_ALLGATHER_BASE, NumelIn=279412736, NumelOut=2235301888, Timeout(ms)=600000) ran for 600162 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:609 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f6f2fb9ff86 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7f6f30e9c8d2 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x233 (0x7f6f30ea3313 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x10c (0x7f6f30ea56fc in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xd3b65 (0x7f6f7e628b65 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/bin/../lib/libstdc++.so.6)
frame #5: <unknown function> + 0x8609 (0x7f6f83a9d609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #6: clone + 0x43 (0x7f6f83868133 in /lib/x86_64-linux-gnu/libc.so.6)

terminate called after throwing an instance of 'c10::DistBackendError'
  what():  [PG 1 Rank 4] Process group watchdog thread terminated with exception: [Rank 4] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=4852, OpType=_ALLGATHER_BASE, NumelIn=279412736, NumelOut=2235301888, Timeout(ms)=600000) ran for 600162 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:609 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f6f2fb9ff86 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7f6f30e9c8d2 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x233 (0x7f6f30ea3313 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x10c (0x7f6f30ea56fc in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xd3b65 (0x7f6f7e628b65 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/bin/../lib/libstdc++.so.6)
frame #5: <unknown function> + 0x8609 (0x7f6f83a9d609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #6: clone + 0x43 (0x7f6f83868133 in /lib/x86_64-linux-gnu/libc.so.6)

Exception raised from ncclCommWatchdog at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1521 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f6f2fb9ff86 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0xe5aa84 (0x7f6f30b2ea84 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #2: <unknown function> + 0xd3b65 (0x7f6f7e628b65 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/bin/../lib/libstdc++.so.6)
frame #3: <unknown function> + 0x8609 (0x7f6f83a9d609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #4: clone + 0x43 (0x7f6f83868133 in /lib/x86_64-linux-gnu/libc.so.6)

[rank3]:[E317 07:18:32.050358972 ProcessGroupNCCL.cpp:1709] [PG 1 Rank 3] Timeout at NCCL work: 4852, last enqueued NCCL work: 4853, last completed NCCL work: 4851.
[rank3]:[E317 07:18:32.050446965 ProcessGroupNCCL.cpp:621] [Rank 3] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank3]:[E317 07:18:32.050460423 ProcessGroupNCCL.cpp:627] [Rank 3] To avoid data inconsistency, we are taking the entire process down.
[rank3]:[E317 07:18:32.052383424 ProcessGroupNCCL.cpp:1515] [PG 1 Rank 3] Process group watchdog thread terminated with exception: [Rank 3] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=4852, OpType=_ALLGATHER_BASE, NumelIn=279412736, NumelOut=2235301888, Timeout(ms)=600000) ran for 600160 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:609 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7fe8cd261f86 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7fe8ce55e8d2 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x233 (0x7fe8ce565313 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x10c (0x7fe8ce5676fc in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xd3b65 (0x7fe91bceab65 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/bin/../lib/libstdc++.so.6)
frame #5: <unknown function> + 0x8609 (0x7fe92115f609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #6: clone + 0x43 (0x7fe920f2a133 in /lib/x86_64-linux-gnu/libc.so.6)

terminate called after throwing an instance of 'c10::DistBackendError'
  what():  [PG 1 Rank 3] Process group watchdog thread terminated with exception: [Rank 3] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=4852, OpType=_ALLGATHER_BASE, NumelIn=279412736, NumelOut=2235301888, Timeout(ms)=600000) ran for 600160 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:609 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7fe8cd261f86 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7fe8ce55e8d2 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x233 (0x7fe8ce565313 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x10c (0x7fe8ce5676fc in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xd3b65 (0x7fe91bceab65 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/bin/../lib/libstdc++.so.6)
frame #5: <unknown function> + 0x8609 (0x7fe92115f609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #6: clone + 0x43 (0x7fe920f2a133 in /lib/x86_64-linux-gnu/libc.so.6)

Exception raised from ncclCommWatchdog at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1521 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7fe8cd261f86 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0xe5aa84 (0x7fe8ce1f0a84 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #2: <unknown function> + 0xd3b65 (0x7fe91bceab65 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/bin/../lib/libstdc++.so.6)
frame #3: <unknown function> + 0x8609 (0x7fe92115f609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #4: clone + 0x43 (0x7fe920f2a133 in /lib/x86_64-linux-gnu/libc.so.6)

[rank6]:[E317 07:18:32.111096918 ProcessGroupNCCL.cpp:1709] [PG 1 Rank 6] Timeout at NCCL work: 4852, last enqueued NCCL work: 4853, last completed NCCL work: 4851.
[rank6]:[E317 07:18:32.111148667 ProcessGroupNCCL.cpp:621] [Rank 6] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank6]:[E317 07:18:32.111158677 ProcessGroupNCCL.cpp:627] [Rank 6] To avoid data inconsistency, we are taking the entire process down.
[rank6]:[E317 07:18:32.112452646 ProcessGroupNCCL.cpp:1515] [PG 1 Rank 6] Process group watchdog thread terminated with exception: [Rank 6] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=4852, OpType=_ALLGATHER_BASE, NumelIn=279412736, NumelOut=2235301888, Timeout(ms)=600000) ran for 600160 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:609 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f9b625f4f86 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7f9b638f18d2 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x233 (0x7f9b638f8313 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x10c (0x7f9b638fa6fc in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xd3b65 (0x7f9bb107db65 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/bin/../lib/libstdc++.so.6)
frame #5: <unknown function> + 0x8609 (0x7f9bb64f2609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #6: clone + 0x43 (0x7f9bb62bd133 in /lib/x86_64-linux-gnu/libc.so.6)

terminate called after throwing an instance of 'c10::DistBackendError'
  what():  [PG 1 Rank 6] Process group watchdog thread terminated with exception: [Rank 6] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=4852, OpType=_ALLGATHER_BASE, NumelIn=279412736, NumelOut=2235301888, Timeout(ms)=600000) ran for 600160 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:609 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f9b625f4f86 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7f9b638f18d2 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x233 (0x7f9b638f8313 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x10c (0x7f9b638fa6fc in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xd3b65 (0x7f9bb107db65 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/bin/../lib/libstdc++.so.6)
frame #5: <unknown function> + 0x8609 (0x7f9bb64f2609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #6: clone + 0x43 (0x7f9bb62bd133 in /lib/x86_64-linux-gnu/libc.so.6)

Exception raised from ncclCommWatchdog at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1521 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f9b625f4f86 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0xe5aa84 (0x7f9b63583a84 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #2: <unknown function> + 0xd3b65 (0x7f9bb107db65 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/bin/../lib/libstdc++.so.6)
frame #3: <unknown function> + 0x8609 (0x7f9bb64f2609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #4: clone + 0x43 (0x7f9bb62bd133 in /lib/x86_64-linux-gnu/libc.so.6)

[rank2]:[E317 07:18:32.197522856 ProcessGroupNCCL.cpp:1709] [PG 1 Rank 2] Timeout at NCCL work: 4852, last enqueued NCCL work: 4853, last completed NCCL work: 4851.
[rank2]:[E317 07:18:32.197659217 ProcessGroupNCCL.cpp:621] [Rank 2] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank2]:[E317 07:18:32.197673747 ProcessGroupNCCL.cpp:627] [Rank 2] To avoid data inconsistency, we are taking the entire process down.
[rank2]:[E317 07:18:32.199458521 ProcessGroupNCCL.cpp:1515] [PG 1 Rank 2] Process group watchdog thread terminated with exception: [Rank 2] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=4852, OpType=_ALLGATHER_BASE, NumelIn=279412736, NumelOut=2235301888, Timeout(ms)=600000) ran for 600155 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:609 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f27c9d50f86 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7f27cb04d8d2 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x233 (0x7f27cb054313 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x10c (0x7f27cb0566fc in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xd3b65 (0x7f28187d9b65 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/bin/../lib/libstdc++.so.6)
frame #5: <unknown function> + 0x8609 (0x7f281dc4e609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #6: clone + 0x43 (0x7f281da19133 in /lib/x86_64-linux-gnu/libc.so.6)

terminate called after throwing an instance of 'c10::DistBackendError'
  what():  [PG 1 Rank 2] Process group watchdog thread terminated with exception: [Rank 2] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=4852, OpType=_ALLGATHER_BASE, NumelIn=279412736, NumelOut=2235301888, Timeout(ms)=600000) ran for 600155 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:609 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f27c9d50f86 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7f27cb04d8d2 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x233 (0x7f27cb054313 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x10c (0x7f27cb0566fc in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xd3b65 (0x7f28187d9b65 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/bin/../lib/libstdc++.so.6)
frame #5: <unknown function> + 0x8609 (0x7f281dc4e609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #6: clone + 0x43 (0x7f281da19133 in /lib/x86_64-linux-gnu/libc.so.6)

Exception raised from ncclCommWatchdog at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1521 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f27c9d50f86 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0xe5aa84 (0x7f27cacdfa84 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #2: <unknown function> + 0xd3b65 (0x7f28187d9b65 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/bin/../lib/libstdc++.so.6)
frame #3: <unknown function> + 0x8609 (0x7f281dc4e609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #4: clone + 0x43 (0x7f281da19133 in /lib/x86_64-linux-gnu/libc.so.6)

[rank1]:[E317 07:18:32.326913036 ProcessGroupNCCL.cpp:1709] [PG 0 (default_pg) Rank 1] Timeout at NCCL work: 888, last enqueued NCCL work: 888, last completed NCCL work: 887.
[rank1]:[E317 07:18:32.326964179 ProcessGroupNCCL.cpp:621] [Rank 1] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank1]:[E317 07:18:32.326972017 ProcessGroupNCCL.cpp:627] [Rank 1] To avoid data inconsistency, we are taking the entire process down.
[rank1]:[E317 07:18:32.328929840 ProcessGroupNCCL.cpp:1515] [PG 0 (default_pg) Rank 1] Process group watchdog thread terminated with exception: [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=888, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600162 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:609 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f08aa7c7f86 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7f08abac48d2 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x233 (0x7f08abacb313 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x10c (0x7f08abacd6fc in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xd3b65 (0x7f08f9250b65 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/bin/../lib/libstdc++.so.6)
frame #5: <unknown function> + 0x8609 (0x7f08fe6c5609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #6: clone + 0x43 (0x7f08fe490133 in /lib/x86_64-linux-gnu/libc.so.6)

terminate called after throwing an instance of 'c10::DistBackendError'
  what():  [PG 0 (default_pg) Rank 1] Process group watchdog thread terminated with exception: [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=888, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600162 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:609 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f08aa7c7f86 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7f08abac48d2 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x233 (0x7f08abacb313 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x10c (0x7f08abacd6fc in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xd3b65 (0x7f08f9250b65 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/bin/../lib/libstdc++.so.6)
frame #5: <unknown function> + 0x8609 (0x7f08fe6c5609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #6: clone + 0x43 (0x7f08fe490133 in /lib/x86_64-linux-gnu/libc.so.6)

Exception raised from ncclCommWatchdog at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1521 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f08aa7c7f86 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0xe5aa84 (0x7f08ab756a84 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #2: <unknown function> + 0xd3b65 (0x7f08f9250b65 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/bin/../lib/libstdc++.so.6)
frame #3: <unknown function> + 0x8609 (0x7f08fe6c5609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #4: clone + 0x43 (0x7f08fe490133 in /lib/x86_64-linux-gnu/libc.so.6)

[rank5]:[E317 07:18:32.365993101 ProcessGroupNCCL.cpp:1709] [PG 1 Rank 5] Timeout at NCCL work: 4852, last enqueued NCCL work: 4853, last completed NCCL work: 4851.
[rank5]:[E317 07:18:32.371444326 ProcessGroupNCCL.cpp:621] [Rank 5] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank5]:[E317 07:18:32.371484460 ProcessGroupNCCL.cpp:627] [Rank 5] To avoid data inconsistency, we are taking the entire process down.
[rank5]:[E317 07:18:32.373285594 ProcessGroupNCCL.cpp:1515] [PG 1 Rank 5] Process group watchdog thread terminated with exception: [Rank 5] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=4852, OpType=_ALLGATHER_BASE, NumelIn=279412736, NumelOut=2235301888, Timeout(ms)=600000) ran for 600160 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:609 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7fe99543ef86 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7fe99673b8d2 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x233 (0x7fe996742313 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x10c (0x7fe9967446fc in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xd3b65 (0x7fe9e3ec7b65 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/bin/../lib/libstdc++.so.6)
frame #5: <unknown function> + 0x8609 (0x7fe9e933c609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #6: clone + 0x43 (0x7fe9e9107133 in /lib/x86_64-linux-gnu/libc.so.6)

terminate called after throwing an instance of 'c10::DistBackendError'
  what():  [PG 1 Rank 5] Process group watchdog thread terminated with exception: [Rank 5] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=4852, OpType=_ALLGATHER_BASE, NumelIn=279412736, NumelOut=2235301888, Timeout(ms)=600000) ran for 600160 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:609 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7fe99543ef86 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7fe99673b8d2 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x233 (0x7fe996742313 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x10c (0x7fe9967446fc in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xd3b65 (0x7fe9e3ec7b65 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/bin/../lib/libstdc++.so.6)
frame #5: <unknown function> + 0x8609 (0x7fe9e933c609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #6: clone + 0x43 (0x7fe9e9107133 in /lib/x86_64-linux-gnu/libc.so.6)

Exception raised from ncclCommWatchdog at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1521 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7fe99543ef86 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0xe5aa84 (0x7fe9963cda84 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #2: <unknown function> + 0xd3b65 (0x7fe9e3ec7b65 in /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/bin/../lib/libstdc++.so.6)
frame #3: <unknown function> + 0x8609 (0x7fe9e933c609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #4: clone + 0x43 (0x7fe9e9107133 in /lib/x86_64-linux-gnu/libc.so.6)

[2025-03-17 07:18:56,113] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved stage-2/train-stage-2-03-17-02-27/250-ema/mp_rank_00_model_states.pt.
W0317 07:19:44.297000 140520969041088 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 96371 closing signal SIGTERM
W0317 07:19:44.307000 140520969041088 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 96372 closing signal SIGTERM
W0317 07:19:44.308000 140520969041088 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 96373 closing signal SIGTERM
W0317 07:19:44.312000 140520969041088 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 96375 closing signal SIGTERM
W0317 07:19:44.332000 140520969041088 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 96376 closing signal SIGTERM
W0317 07:19:44.332000 140520969041088 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 96377 closing signal SIGTERM
W0317 07:19:44.332000 140520969041088 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 96378 closing signal SIGTERM
E0317 07:20:08.512000 140520969041088 torch/distributed/elastic/multiprocessing/api.py:833] failed (exitcode: -6) local_rank: 3 (pid: 96374) of binary: /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/bin/python
Traceback (most recent call last):
  File "/sds_wangby/group_conda_envs/anaconda3/envs/hallo3/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 348, in wrapper
    return f(*args, **kwargs)
  File "/sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/distributed/run.py", line 901, in main
    run(args)
  File "/sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 133, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
======================================================
hallo3/train_video.py FAILED
------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-03-17_07:19:44
  host      : 3vvvmc4cgetnp-0
  rank      : 3 (local_rank: 3)
  exitcode  : -6 (pid: 96374)
  error_file: <N/A>
  traceback : Signal 6 (SIGABRT) received by PID 96374
======================================================
