W0207 09:40:42.152000 140587200083776 torch/distributed/run.py:779] 
W0207 09:40:42.152000 140587200083776 torch/distributed/run.py:779] *****************************************
W0207 09:40:42.152000 140587200083776 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0207 09:40:42.152000 140587200083776 torch/distributed/run.py:779] *****************************************
[2025-02-07 09:40:52,998] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-07 09:40:54,248] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-07 09:40:54,575] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-07 09:40:55,208] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-07 09:40:55,436] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-07 09:40:55,683] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-07 09:40:55,783] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-07 09:40:55,847] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
2025-02-07 09:41:26.641273: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-02-07 09:41:26.745762: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-02-07 09:41:26.746925: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-02-07 09:41:26.810339: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1738921286.858820  129429 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-02-07 09:41:26.870132: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
E0000 00:00:1738921286.875086  129429 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-02-07 09:41:26.877686: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-02-07 09:41:26.880444: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1738921286.934565  129435 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-02-07 09:41:26.939066: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
E0000 00:00:1738921286.967210  129435 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-02-07 09:41:26.982714: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-02-07 09:41:27.078589: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-02-07 09:41:27.118932: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1738921287.124774  129433 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1738921287.135718  129433 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-02-07 09:41:27.173147: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1738921287.185043  129430 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1738921287.201691  129430 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1738921287.212587  129431 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-02-07 09:41:27.217110: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-02-07 09:41:27.229058: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-02-07 09:41:27.232030: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-02-07 09:41:27.239360: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
E0000 00:00:1738921287.258035  129431 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-02-07 09:41:27.280662: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1738921287.412835  129428 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1738921287.430296  129428 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-02-07 09:41:27.483443: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-02-07 09:41:27.489536: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1738921287.522092  129427 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1738921287.533195  129427 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-02-07 09:41:27.557035: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-02-07 09:41:27.582443: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-02-07 09:41:27.683559: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-02-07 09:41:27.701371: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1738921287.745737  129434 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1738921287.822120  129434 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-02-07 09:41:27.864980: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2025-02-07 09:41:59,540] [INFO] using world size: 8
[2025-02-07 09:41:59,541] [INFO] Will override arguments with manually specified deepspeed_config!
[W207 09:42:00.856380941 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[2025-02-07 09:42:00,057] [INFO] [comm.py:652:init_distributed] cdb=None
[W207 09:42:00.961099163 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[2025-02-07 09:42:00,149] [INFO] [comm.py:652:init_distributed] cdb=None
[W207 09:42:00.986716023 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[2025-02-07 09:42:00,170] [INFO] [comm.py:652:init_distributed] cdb=None
[W207 09:42:00.217860044 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[2025-02-07 09:42:00,401] [INFO] [comm.py:652:init_distributed] cdb=None
[W207 09:42:00.785043415 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[2025-02-07 09:42:00,995] [INFO] [comm.py:652:init_distributed] cdb=None
[W207 09:42:01.942621556 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W207 09:42:01.943197721 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[2025-02-07 09:42:01,127] [INFO] [comm.py:652:init_distributed] cdb=None
[2025-02-07 09:42:01,129] [INFO] [comm.py:652:init_distributed] cdb=None
[W207 09:42:01.952874201 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[2025-02-07 09:42:01,135] [INFO] [RANK 0] > initializing model parallel with size 1
[2025-02-07 09:42:01,137] [INFO] [comm.py:652:init_distributed] cdb=None
[2025-02-07 09:42:01,642] [INFO] [RANK 0] building SATVideoDiffusionEngine model ...
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:37<00:37, 37.24s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:36<00:36, 36.59s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:39<00:39, 39.96s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:39<00:39, 39.83s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:33<00:33, 33.29s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:35<00:35, 35.89s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:32<00:32, 33.00s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:26<00:26, 26.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:05<00:00, 32.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:05<00:00, 32.86s/it]
Initialized embedder #0: FrozenT5Embedder with 4762310656 params. Trainable: False
Loading checkpoint shards: 100%|██████████| 2/2 [01:07<00:00, 33.03s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:07<00:00, 33.66s/it]
Initialized embedder #0: FrozenT5Embedder with 4762310656 params. Trainable: False
Loading checkpoint shards: 100%|██████████| 2/2 [01:10<00:00, 34.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:10<00:00, 35.29s/it]
Initialized embedder #0: FrozenT5Embedder with 4762310656 params. Trainable: False
Working with z of shape (1, 16, 32, 32) = 16384 dimensions.
Working with z of shape (1, 16, 32, 32) = 16384 dimensions.
Working with z of shape (1, 16, 32, 32) = 16384 dimensions.
Loading checkpoint shards: 100%|██████████| 2/2 [01:10<00:00, 34.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:10<00:00, 35.46s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:04<00:00, 31.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:04<00:00, 32.32s/it]
Initialized embedder #0: FrozenT5Embedder with 4762310656 params. Trainable: False
Initialized embedder #0: FrozenT5Embedder with 4762310656 params. Trainable: False
Loading checkpoint shards: 100%|██████████| 2/2 [01:04<00:00, 32.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:04<00:00, 32.29s/it]
Initialized embedder #0: FrozenT5Embedder with 4762310656 params. Trainable: False
Working with z of shape (1, 16, 32, 32) = 16384 dimensions.
Working with z of shape (1, 16, 32, 32) = 16384 dimensions.
Working with z of shape (1, 16, 32, 32) = 16384 dimensions.
Loading checkpoint shards: 100%|██████████| 2/2 [01:03<00:00, 31.64s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:03<00:00, 31.84s/it]
Initialized embedder #0: FrozenT5Embedder with 4762310656 params. Trainable: False
Deleting key loss.logvar from state_dict.
Deleting key loss.perceptual_loss.scaling_layer.shift from state_dict.
Deleting key loss.perceptual_loss.scaling_layer.scale from state_dict.
Deleting key loss.perceptual_loss.net.slice1.0.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice1.0.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice1.2.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice1.2.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice2.5.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice2.5.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice2.7.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice2.7.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice3.10.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice3.10.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice3.12.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice3.12.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice3.14.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice3.14.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice4.17.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice4.17.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice4.19.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice4.19.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice4.21.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice4.21.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice5.24.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice5.24.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice5.26.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice5.26.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice5.28.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice5.28.bias from state_dict.
Deleting key loss.perceptual_loss.lin0.model.1.weight from state_dict.
Deleting key loss.perceptual_loss.lin1.model.1.weight from state_dict.
Deleting key loss.perceptual_loss.lin2.model.1.weight from state_dict.
Deleting key loss.perceptual_loss.lin3.model.1.weight from state_dict.
Deleting key loss.perceptual_loss.lin4.model.1.weight from state_dict.
Deleting key loss.discriminator.blocks.0.downsample_res.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.0.downsample_res.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.0.net.0.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.0.net.0.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.0.net.2.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.0.net.2.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.0.downsample.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.0.downsample.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.1.downsample_res.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.1.downsample_res.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.1.net.0.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.1.net.0.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.1.net.2.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.1.net.2.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.1.downsample.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.1.downsample.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.2.downsample_res.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.2.downsample_res.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.2.net.0.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.2.net.0.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.2.net.2.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.2.net.2.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.2.downsample.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.2.downsample.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.3.downsample_res.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.3.downsample_res.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.3.net.0.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.3.net.0.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.3.net.2.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.3.net.2.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.3.downsample.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.3.downsample.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.4.0.conv_res.weight from state_dict.
Deleting key loss.discriminator.blocks.4.0.conv_res.bias from state_dict.
Deleting key loss.discriminator.blocks.4.0.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.0.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.4.0.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.4.0.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.4.0.downsample.1.weight from state_dict.
Deleting key loss.discriminator.blocks.4.0.downsample.1.bias from state_dict.
Deleting key loss.discriminator.blocks.4.1.0.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.4.1.0.fn.attn.to_q.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.0.fn.attn.to_kv.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.0.fn.attn.to_out.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.5.0.conv_res.weight from state_dict.
Deleting key loss.discriminator.blocks.5.0.conv_res.bias from state_dict.
Deleting key loss.discriminator.blocks.5.0.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.0.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.5.0.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.5.0.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.5.0.downsample.1.weight from state_dict.
Deleting key loss.discriminator.blocks.5.0.downsample.1.bias from state_dict.
Deleting key loss.discriminator.blocks.5.1.0.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.5.1.0.fn.attn.to_q.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.0.fn.attn.to_kv.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.0.fn.attn.to_out.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.6.0.conv_res.weight from state_dict.
Deleting key loss.discriminator.blocks.6.0.conv_res.bias from state_dict.
Deleting key loss.discriminator.blocks.6.0.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.0.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.6.0.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.6.0.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.6.1.0.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.6.1.0.fn.attn.to_q.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.0.fn.attn.to_kv.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.0.fn.attn.to_out.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.net.2.bias from state_dict.
Deleting key loss.discriminator.to_logits.0.weight from state_dict.
Deleting key loss.discriminator.to_logits.0.bias from state_dict.
Deleting key loss.discriminator.to_logits.3.weight from state_dict.
Deleting key loss.discriminator.to_logits.3.bias from state_dict.
Working with z of shape (1, 16, 32, 32) = 16384 dimensions.
Deleting key loss.logvar from state_dict.
Deleting key loss.perceptual_loss.scaling_layer.shift from state_dict.
Deleting key loss.perceptual_loss.scaling_layer.scale from state_dict.
Deleting key loss.perceptual_loss.net.slice1.0.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice1.0.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice1.2.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice1.2.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice2.5.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice2.5.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice2.7.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice2.7.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice3.10.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice3.10.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice3.12.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice3.12.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice3.14.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice3.14.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice4.17.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice4.17.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice4.19.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice4.19.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice4.21.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice4.21.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice5.24.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice5.24.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice5.26.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice5.26.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice5.28.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice5.28.bias from state_dict.
Deleting key loss.perceptual_loss.lin0.model.1.weight from state_dict.
Deleting key loss.perceptual_loss.lin1.model.1.weight from state_dict.
Deleting key loss.perceptual_loss.lin2.model.1.weight from state_dict.
Deleting key loss.perceptual_loss.lin3.model.1.weight from state_dict.
Deleting key loss.perceptual_loss.lin4.model.1.weight from state_dict.
Deleting key loss.discriminator.blocks.0.downsample_res.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.0.downsample_res.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.0.net.0.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.0.net.0.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.0.net.2.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.0.net.2.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.0.downsample.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.0.downsample.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.1.downsample_res.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.1.downsample_res.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.1.net.0.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.1.net.0.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.1.net.2.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.1.net.2.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.1.downsample.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.1.downsample.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.2.downsample_res.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.2.downsample_res.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.2.net.0.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.2.net.0.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.2.net.2.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.2.net.2.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.2.downsample.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.2.downsample.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.3.downsample_res.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.3.downsample_res.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.3.net.0.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.3.net.0.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.3.net.2.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.3.net.2.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.3.downsample.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.3.downsample.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.4.0.conv_res.weight from state_dict.
Deleting key loss.discriminator.blocks.4.0.conv_res.bias from state_dict.
Deleting key loss.discriminator.blocks.4.0.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.0.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.4.0.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.4.0.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.4.0.downsample.1.weight from state_dict.
Deleting key loss.discriminator.blocks.4.0.downsample.1.bias from state_dict.
Deleting key loss.discriminator.blocks.4.1.0.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.4.1.0.fn.attn.to_q.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.0.fn.attn.to_kv.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.0.fn.attn.to_out.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.5.0.conv_res.weight from state_dict.
Deleting key loss.discriminator.blocks.5.0.conv_res.bias from state_dict.
Deleting key loss.discriminator.blocks.5.0.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.0.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.5.0.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.5.0.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.5.0.downsample.1.weight from state_dict.
Deleting key loss.discriminator.blocks.5.0.downsample.1.bias from state_dict.
Deleting key loss.discriminator.blocks.5.1.0.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.5.1.0.fn.attn.to_q.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.0.fn.attn.to_kv.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.0.fn.attn.to_out.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.6.0.conv_res.weight from state_dict.
Deleting key loss.discriminator.blocks.6.0.conv_res.bias from state_dict.
Deleting key loss.discriminator.blocks.6.0.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.0.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.6.0.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.6.0.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.6.1.0.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.6.1.0.fn.attn.to_q.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.0.fn.attn.to_kv.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.0.fn.attn.to_out.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.net.2.bias from state_dict.
Deleting key loss.discriminator.to_logits.0.weight from state_dict.
Deleting key loss.discriminator.to_logits.0.bias from state_dict.
Deleting key loss.discriminator.to_logits.3.weight from state_dict.
Deleting key loss.discriminator.to_logits.3.bias from state_dict.
Deleting key loss.logvar from state_dict.
Deleting key loss.perceptual_loss.scaling_layer.shift from state_dict.
Deleting key loss.perceptual_loss.scaling_layer.scale from state_dict.
Deleting key loss.perceptual_loss.net.slice1.0.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice1.0.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice1.2.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice1.2.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice2.5.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice2.5.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice2.7.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice2.7.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice3.10.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice3.10.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice3.12.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice3.12.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice3.14.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice3.14.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice4.17.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice4.17.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice4.19.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice4.19.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice4.21.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice4.21.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice5.24.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice5.24.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice5.26.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice5.26.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice5.28.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice5.28.bias from state_dict.
Deleting key loss.perceptual_loss.lin0.model.1.weight from state_dict.
Deleting key loss.perceptual_loss.lin1.model.1.weight from state_dict.
Deleting key loss.perceptual_loss.lin2.model.1.weight from state_dict.
Deleting key loss.perceptual_loss.lin3.model.1.weight from state_dict.
Deleting key loss.perceptual_loss.lin4.model.1.weight from state_dict.
Deleting key loss.discriminator.blocks.0.downsample_res.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.0.downsample_res.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.0.net.0.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.0.net.0.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.0.net.2.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.0.net.2.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.0.downsample.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.0.downsample.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.1.downsample_res.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.1.downsample_res.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.1.net.0.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.1.net.0.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.1.net.2.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.1.net.2.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.1.downsample.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.1.downsample.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.2.downsample_res.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.2.downsample_res.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.2.net.0.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.2.net.0.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.2.net.2.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.2.net.2.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.2.downsample.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.2.downsample.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.3.downsample_res.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.3.downsample_res.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.3.net.0.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.3.net.0.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.3.net.2.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.3.net.2.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.3.downsample.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.3.downsample.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.4.0.conv_res.weight from state_dict.
Deleting key loss.discriminator.blocks.4.0.conv_res.bias from state_dict.
Deleting key loss.discriminator.blocks.4.0.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.0.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.4.0.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.4.0.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.4.0.downsample.1.weight from state_dict.
Deleting key loss.discriminator.blocks.4.0.downsample.1.bias from state_dict.
Deleting key loss.discriminator.blocks.4.1.0.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.4.1.0.fn.attn.to_q.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.0.fn.attn.to_kv.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.0.fn.attn.to_out.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.5.0.conv_res.weight from state_dict.
Deleting key loss.discriminator.blocks.5.0.conv_res.bias from state_dict.
Deleting key loss.discriminator.blocks.5.0.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.0.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.5.0.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.5.0.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.5.0.downsample.1.weight from state_dict.
Deleting key loss.discriminator.blocks.5.0.downsample.1.bias from state_dict.
Deleting key loss.discriminator.blocks.5.1.0.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.5.1.0.fn.attn.to_q.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.0.fn.attn.to_kv.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.0.fn.attn.to_out.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.6.0.conv_res.weight from state_dict.
Deleting key loss.discriminator.blocks.6.0.conv_res.bias from state_dict.
Deleting key loss.discriminator.blocks.6.0.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.0.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.6.0.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.6.0.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.6.1.0.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.6.1.0.fn.attn.to_q.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.0.fn.attn.to_kv.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.0.fn.attn.to_out.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.net.2.bias from state_dict.
Deleting key loss.discriminator.to_logits.0.weight from state_dict.
Deleting key loss.discriminator.to_logits.0.bias from state_dict.
Deleting key loss.discriminator.to_logits.3.weight from state_dict.
Deleting key loss.discriminator.to_logits.3.bias from state_dict.
Missing keys:  []
Unexpected keys:  []
Restored from ./pretrained_models/cogvideox-5b-i2v-sat/vae/3d-vae.pt
Missing keys:  []
Unexpected keys:  []
Restored from ./pretrained_models/cogvideox-5b-i2v-sat/vae/3d-vae.pt
Missing keys:  []
Unexpected keys:  []
Restored from ./pretrained_models/cogvideox-5b-i2v-sat/vae/3d-vae.pt
Deleting key loss.logvar from state_dict.
Deleting key loss.perceptual_loss.scaling_layer.shift from state_dict.
Deleting key loss.perceptual_loss.scaling_layer.scale from state_dict.
Deleting key loss.perceptual_loss.net.slice1.0.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice1.0.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice1.2.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice1.2.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice2.5.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice2.5.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice2.7.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice2.7.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice3.10.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice3.10.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice3.12.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice3.12.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice3.14.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice3.14.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice4.17.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice4.17.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice4.19.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice4.19.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice4.21.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice4.21.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice5.24.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice5.24.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice5.26.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice5.26.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice5.28.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice5.28.bias from state_dict.
Deleting key loss.perceptual_loss.lin0.model.1.weight from state_dict.
Deleting key loss.perceptual_loss.lin1.model.1.weight from state_dict.
Deleting key loss.perceptual_loss.lin2.model.1.weight from state_dict.
Deleting key loss.perceptual_loss.lin3.model.1.weight from state_dict.
Deleting key loss.perceptual_loss.lin4.model.1.weight from state_dict.
Deleting key loss.discriminator.blocks.0.downsample_res.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.0.downsample_res.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.0.net.0.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.0.net.0.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.0.net.2.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.0.net.2.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.0.downsample.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.0.downsample.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.1.downsample_res.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.1.downsample_res.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.1.net.0.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.1.net.0.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.1.net.2.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.1.net.2.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.1.downsample.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.1.downsample.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.2.downsample_res.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.2.downsample_res.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.2.net.0.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.2.net.0.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.2.net.2.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.2.net.2.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.2.downsample.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.2.downsample.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.3.downsample_res.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.3.downsample_res.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.3.net.0.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.3.net.0.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.3.net.2.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.3.net.2.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.3.downsample.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.3.downsample.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.4.0.conv_res.weight from state_dict.
Deleting key loss.discriminator.blocks.4.0.conv_res.bias from state_dict.
Deleting key loss.discriminator.blocks.4.0.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.0.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.4.0.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.4.0.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.4.0.downsample.1.weight from state_dict.
Deleting key loss.discriminator.blocks.4.0.downsample.1.bias from state_dict.
Deleting key loss.discriminator.blocks.4.1.0.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.4.1.0.fn.attn.to_q.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.0.fn.attn.to_kv.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.0.fn.attn.to_out.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.5.0.conv_res.weight from state_dict.
Deleting key loss.discriminator.blocks.5.0.conv_res.bias from state_dict.
Deleting key loss.discriminator.blocks.5.0.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.0.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.5.0.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.5.0.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.5.0.downsample.1.weight from state_dict.
Deleting key loss.discriminator.blocks.5.0.downsample.1.bias from state_dict.
Deleting key loss.discriminator.blocks.5.1.0.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.5.1.0.fn.attn.to_q.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.0.fn.attn.to_kv.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.0.fn.attn.to_out.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.6.0.conv_res.weight from state_dict.
Deleting key loss.discriminator.blocks.6.0.conv_res.bias from state_dict.
Deleting key loss.discriminator.blocks.6.0.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.0.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.6.0.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.6.0.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.6.1.0.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.6.1.0.fn.attn.to_q.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.0.fn.attn.to_kv.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.0.fn.attn.to_out.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.net.2.bias from state_dict.
Deleting key loss.discriminator.to_logits.0.weight from state_dict.
Deleting key loss.discriminator.to_logits.0.bias from state_dict.
Deleting key loss.discriminator.to_logits.3.weight from state_dict.
Deleting key loss.discriminator.to_logits.3.bias from state_dict.
Missing keys:  []
Unexpected keys:  []
Restored from ./pretrained_models/cogvideox-5b-i2v-sat/vae/3d-vae.pt
Deleting key loss.logvar from state_dict.
Deleting key loss.perceptual_loss.scaling_layer.shift from state_dict.
Deleting key loss.perceptual_loss.scaling_layer.scale from state_dict.
Deleting key loss.perceptual_loss.net.slice1.0.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice1.0.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice1.2.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice1.2.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice2.5.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice2.5.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice2.7.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice2.7.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice3.10.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice3.10.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice3.12.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice3.12.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice3.14.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice3.14.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice4.17.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice4.17.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice4.19.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice4.19.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice4.21.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice4.21.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice5.24.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice5.24.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice5.26.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice5.26.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice5.28.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice5.28.bias from state_dict.
Deleting key loss.perceptual_loss.lin0.model.1.weight from state_dict.
Deleting key loss.perceptual_loss.lin1.model.1.weight from state_dict.
Deleting key loss.perceptual_loss.lin2.model.1.weight from state_dict.
Deleting key loss.perceptual_loss.lin3.model.1.weight from state_dict.
Deleting key loss.perceptual_loss.lin4.model.1.weight from state_dict.
Deleting key loss.discriminator.blocks.0.downsample_res.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.0.downsample_res.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.0.net.0.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.0.net.0.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.0.net.2.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.0.net.2.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.0.downsample.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.0.downsample.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.1.downsample_res.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.1.downsample_res.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.1.net.0.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.1.net.0.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.1.net.2.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.1.net.2.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.1.downsample.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.1.downsample.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.2.downsample_res.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.2.downsample_res.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.2.net.0.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.2.net.0.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.2.net.2.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.2.net.2.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.2.downsample.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.2.downsample.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.3.downsample_res.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.3.downsample_res.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.3.net.0.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.3.net.0.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.3.net.2.conv.weight from state_dict.
Loading checkpoint shards: 100%|██████████| 2/2 [00:56<00:00, 28.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:56<00:00, 28.28s/it]
Deleting key loss.discriminator.blocks.3.net.2.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.3.downsample.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.3.downsample.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.4.0.conv_res.weight from state_dict.
Deleting key loss.discriminator.blocks.4.0.conv_res.bias from state_dict.
Deleting key loss.discriminator.blocks.4.0.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.0.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.4.0.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.4.0.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.4.0.downsample.1.weight from state_dict.
Deleting key loss.discriminator.blocks.4.0.downsample.1.bias from state_dict.
Deleting key loss.discriminator.blocks.4.1.0.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.4.1.0.fn.attn.to_q.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.0.fn.attn.to_kv.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.0.fn.attn.to_out.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.5.0.conv_res.weight from state_dict.
Deleting key loss.discriminator.blocks.5.0.conv_res.bias from state_dict.
Deleting key loss.discriminator.blocks.5.0.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.0.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.5.0.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.5.0.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.5.0.downsample.1.weight from state_dict.
Deleting key loss.discriminator.blocks.5.0.downsample.1.bias from state_dict.
Deleting key loss.discriminator.blocks.5.1.0.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.5.1.0.fn.attn.to_q.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.0.fn.attn.to_kv.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.0.fn.attn.to_out.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.6.0.conv_res.weight from state_dict.
Deleting key loss.discriminator.blocks.6.0.conv_res.bias from state_dict.
Deleting key loss.discriminator.blocks.6.0.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.0.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.6.0.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.6.0.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.6.1.0.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.6.1.0.fn.attn.to_q.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.0.fn.attn.to_kv.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.0.fn.attn.to_out.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.net.2.bias from state_dict.
Deleting key loss.discriminator.to_logits.0.weight from state_dict.
Deleting key loss.discriminator.to_logits.0.bias from state_dict.
Deleting key loss.discriminator.to_logits.3.weight from state_dict.
Deleting key loss.discriminator.to_logits.3.bias from state_dict.
Deleting key loss.logvar from state_dict.
Deleting key loss.perceptual_loss.scaling_layer.shift from state_dict.
Deleting key loss.perceptual_loss.scaling_layer.scale from state_dict.
Deleting key loss.perceptual_loss.net.slice1.0.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice1.0.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice1.2.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice1.2.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice2.5.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice2.5.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice2.7.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice2.7.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice3.10.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice3.10.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice3.12.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice3.12.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice3.14.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice3.14.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice4.17.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice4.17.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice4.19.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice4.19.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice4.21.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice4.21.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice5.24.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice5.24.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice5.26.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice5.26.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice5.28.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice5.28.bias from state_dict.
Deleting key loss.perceptual_loss.lin0.model.1.weight from state_dict.
Deleting key loss.perceptual_loss.lin1.model.1.weight from state_dict.
Deleting key loss.perceptual_loss.lin2.model.1.weight from state_dict.
Deleting key loss.perceptual_loss.lin3.model.1.weight from state_dict.
Deleting key loss.perceptual_loss.lin4.model.1.weight from state_dict.
Deleting key loss.discriminator.blocks.0.downsample_res.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.0.downsample_res.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.0.net.0.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.0.net.0.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.0.net.2.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.0.net.2.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.0.downsample.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.0.downsample.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.1.downsample_res.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.1.downsample_res.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.1.net.0.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.1.net.0.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.1.net.2.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.1.net.2.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.1.downsample.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.1.downsample.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.2.downsample_res.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.2.downsample_res.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.2.net.0.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.2.net.0.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.2.net.2.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.2.net.2.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.2.downsample.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.2.downsample.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.3.downsample_res.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.3.downsample_res.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.3.net.0.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.3.net.0.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.3.net.2.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.3.net.2.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.3.downsample.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.3.downsample.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.4.0.conv_res.weight from state_dict.
Deleting key loss.discriminator.blocks.4.0.conv_res.bias from state_dict.
Deleting key loss.discriminator.blocks.4.0.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.0.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.4.0.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.4.0.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.4.0.downsample.1.weight from state_dict.
Deleting key loss.discriminator.blocks.4.0.downsample.1.bias from state_dict.
Deleting key loss.discriminator.blocks.4.1.0.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.4.1.0.fn.attn.to_q.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.0.fn.attn.to_kv.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.0.fn.attn.to_out.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.5.0.conv_res.weight from state_dict.
Deleting key loss.discriminator.blocks.5.0.conv_res.bias from state_dict.
Deleting key loss.discriminator.blocks.5.0.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.0.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.5.0.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.5.0.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.5.0.downsample.1.weight from state_dict.
Deleting key loss.discriminator.blocks.5.0.downsample.1.bias from state_dict.
Deleting key loss.discriminator.blocks.5.1.0.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.5.1.0.fn.attn.to_q.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.0.fn.attn.to_kv.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.0.fn.attn.to_out.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.6.0.conv_res.weight from state_dict.
Deleting key loss.discriminator.blocks.6.0.conv_res.bias from state_dict.
Deleting key loss.discriminator.blocks.6.0.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.0.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.6.0.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.6.0.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.6.1.0.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.6.1.0.fn.attn.to_q.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.0.fn.attn.to_kv.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.0.fn.attn.to_out.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.net.2.bias from state_dict.
Deleting key loss.discriminator.to_logits.0.weight from state_dict.
Deleting key loss.discriminator.to_logits.0.bias from state_dict.
Deleting key loss.discriminator.to_logits.3.weight from state_dict.
Deleting key loss.discriminator.to_logits.3.bias from state_dict.
Initialized embedder #0: FrozenT5Embedder with 4762310656 params. Trainable: False
Missing keys:  []
Unexpected keys:  []
Restored from ./pretrained_models/cogvideox-5b-i2v-sat/vae/3d-vae.pt
Missing keys:  []
Unexpected keys:  []
Restored from ./pretrained_models/cogvideox-5b-i2v-sat/vae/3d-vae.pt
Working with z of shape (1, 16, 32, 32) = 16384 dimensions.
Deleting key loss.logvar from state_dict.
Deleting key loss.perceptual_loss.scaling_layer.shift from state_dict.
Deleting key loss.perceptual_loss.scaling_layer.scale from state_dict.
Deleting key loss.perceptual_loss.net.slice1.0.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice1.0.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice1.2.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice1.2.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice2.5.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice2.5.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice2.7.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice2.7.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice3.10.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice3.10.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice3.12.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice3.12.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice3.14.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice3.14.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice4.17.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice4.17.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice4.19.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice4.19.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice4.21.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice4.21.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice5.24.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice5.24.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice5.26.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice5.26.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice5.28.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice5.28.bias from state_dict.
Deleting key loss.perceptual_loss.lin0.model.1.weight from state_dict.
Deleting key loss.perceptual_loss.lin1.model.1.weight from state_dict.
Deleting key loss.perceptual_loss.lin2.model.1.weight from state_dict.
Deleting key loss.perceptual_loss.lin3.model.1.weight from state_dict.
Deleting key loss.perceptual_loss.lin4.model.1.weight from state_dict.
Deleting key loss.discriminator.blocks.0.downsample_res.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.0.downsample_res.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.0.net.0.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.0.net.0.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.0.net.2.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.0.net.2.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.0.downsample.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.0.downsample.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.1.downsample_res.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.1.downsample_res.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.1.net.0.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.1.net.0.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.1.net.2.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.1.net.2.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.1.downsample.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.1.downsample.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.2.downsample_res.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.2.downsample_res.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.2.net.0.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.2.net.0.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.2.net.2.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.2.net.2.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.2.downsample.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.2.downsample.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.3.downsample_res.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.3.downsample_res.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.3.net.0.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.3.net.0.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.3.net.2.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.3.net.2.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.3.downsample.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.3.downsample.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.4.0.conv_res.weight from state_dict.
Deleting key loss.discriminator.blocks.4.0.conv_res.bias from state_dict.
Deleting key loss.discriminator.blocks.4.0.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.0.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.4.0.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.4.0.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.4.0.downsample.1.weight from state_dict.
Deleting key loss.discriminator.blocks.4.0.downsample.1.bias from state_dict.
Deleting key loss.discriminator.blocks.4.1.0.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.4.1.0.fn.attn.to_q.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.0.fn.attn.to_kv.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.0.fn.attn.to_out.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.5.0.conv_res.weight from state_dict.
Deleting key loss.discriminator.blocks.5.0.conv_res.bias from state_dict.
Deleting key loss.discriminator.blocks.5.0.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.0.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.5.0.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.5.0.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.5.0.downsample.1.weight from state_dict.
Deleting key loss.discriminator.blocks.5.0.downsample.1.bias from state_dict.
Deleting key loss.discriminator.blocks.5.1.0.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.5.1.0.fn.attn.to_q.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.0.fn.attn.to_kv.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.0.fn.attn.to_out.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.6.0.conv_res.weight from state_dict.
Deleting key loss.discriminator.blocks.6.0.conv_res.bias from state_dict.
Deleting key loss.discriminator.blocks.6.0.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.0.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.6.0.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.6.0.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.6.1.0.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.6.1.0.fn.attn.to_q.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.0.fn.attn.to_kv.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.0.fn.attn.to_out.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.net.2.bias from state_dict.
Deleting key loss.discriminator.to_logits.0.weight from state_dict.
Deleting key loss.discriminator.to_logits.0.bias from state_dict.
Deleting key loss.discriminator.to_logits.3.weight from state_dict.
Deleting key loss.discriminator.to_logits.3.bias from state_dict.
Missing keys:  []
Unexpected keys:  []
Restored from ./pretrained_models/cogvideox-5b-i2v-sat/vae/3d-vae.pt
Deleting key loss.logvar from state_dict.
Deleting key loss.perceptual_loss.scaling_layer.shift from state_dict.
Deleting key loss.perceptual_loss.scaling_layer.scale from state_dict.
Deleting key loss.perceptual_loss.net.slice1.0.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice1.0.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice1.2.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice1.2.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice2.5.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice2.5.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice2.7.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice2.7.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice3.10.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice3.10.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice3.12.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice3.12.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice3.14.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice3.14.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice4.17.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice4.17.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice4.19.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice4.19.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice4.21.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice4.21.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice5.24.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice5.24.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice5.26.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice5.26.bias from state_dict.
Deleting key loss.perceptual_loss.net.slice5.28.weight from state_dict.
Deleting key loss.perceptual_loss.net.slice5.28.bias from state_dict.
Deleting key loss.perceptual_loss.lin0.model.1.weight from state_dict.
Deleting key loss.perceptual_loss.lin1.model.1.weight from state_dict.
Deleting key loss.perceptual_loss.lin2.model.1.weight from state_dict.
Deleting key loss.perceptual_loss.lin3.model.1.weight from state_dict.
Deleting key loss.perceptual_loss.lin4.model.1.weight from state_dict.
Deleting key loss.discriminator.blocks.0.downsample_res.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.0.downsample_res.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.0.net.0.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.0.net.0.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.0.net.2.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.0.net.2.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.0.downsample.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.0.downsample.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.1.downsample_res.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.1.downsample_res.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.1.net.0.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.1.net.0.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.1.net.2.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.1.net.2.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.1.downsample.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.1.downsample.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.2.downsample_res.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.2.downsample_res.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.2.net.0.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.2.net.0.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.2.net.2.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.2.net.2.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.2.downsample.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.2.downsample.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.3.downsample_res.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.3.downsample_res.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.3.net.0.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.3.net.0.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.3.net.2.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.3.net.2.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.3.downsample.conv.weight from state_dict.
Deleting key loss.discriminator.blocks.3.downsample.conv.bias from state_dict.
Deleting key loss.discriminator.blocks.4.0.conv_res.weight from state_dict.
Deleting key loss.discriminator.blocks.4.0.conv_res.bias from state_dict.
Deleting key loss.discriminator.blocks.4.0.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.0.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.4.0.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.4.0.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.4.0.downsample.1.weight from state_dict.
Deleting key loss.discriminator.blocks.4.0.downsample.1.bias from state_dict.
Deleting key loss.discriminator.blocks.4.1.0.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.4.1.0.fn.attn.to_q.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.0.fn.attn.to_kv.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.0.fn.attn.to_out.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.4.1.1.fn.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.5.0.conv_res.weight from state_dict.
Deleting key loss.discriminator.blocks.5.0.conv_res.bias from state_dict.
Deleting key loss.discriminator.blocks.5.0.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.0.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.5.0.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.5.0.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.5.0.downsample.1.weight from state_dict.
Deleting key loss.discriminator.blocks.5.0.downsample.1.bias from state_dict.
Deleting key loss.discriminator.blocks.5.1.0.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.5.1.0.fn.attn.to_q.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.0.fn.attn.to_kv.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.0.fn.attn.to_out.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.5.1.1.fn.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.6.0.conv_res.weight from state_dict.
Deleting key loss.discriminator.blocks.6.0.conv_res.bias from state_dict.
Deleting key loss.discriminator.blocks.6.0.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.0.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.6.0.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.6.0.net.2.bias from state_dict.
Deleting key loss.discriminator.blocks.6.1.0.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.6.1.0.fn.attn.to_q.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.0.fn.attn.to_kv.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.0.fn.attn.to_out.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.norm.gamma from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.net.0.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.net.0.bias from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.net.2.weight from state_dict.
Deleting key loss.discriminator.blocks.6.1.1.fn.net.2.bias from state_dict.
Deleting key loss.discriminator.to_logits.0.weight from state_dict.
Deleting key loss.discriminator.to_logits.0.bias from state_dict.
Deleting key loss.discriminator.to_logits.3.weight from state_dict.
Deleting key loss.discriminator.to_logits.3.bias from state_dict.
Missing keys:  []
Unexpected keys:  []
Restored from ./pretrained_models/cogvideox-5b-i2v-sat/vae/3d-vae.pt
[2025-02-07 09:49:04,984] [INFO] [RANK 0]  > number of parameters on model parallel rank 0: 17288304931
[2025-02-07 09:51:45,628] [INFO] [RANK 0] global rank 0 is loading checkpoint ./pretrained_models/cogvideox-5b-i2v-sat/transformer/1/mp_rank_00_model_states.pt
[2025-02-07 09:52:11,169] [INFO] [RANK 0] > successfully loaded ./pretrained_models/cogvideox-5b-i2v-sat/transformer/1/mp_rank_00_model_states.pt
[1738921931.809986] [297hi17a9s0l1-0:129427:f]        vfs_fuse.c:281  UCX  ERROR inotify_add_watch(/tmp) failed: No space left on device
[1738921931.883920] [297hi17a9s0l1-0:129430:f]        vfs_fuse.c:281  UCX  ERROR inotify_add_watch(/tmp) failed: No space left on device
[1738921931.884823] [297hi17a9s0l1-0:129434:f]        vfs_fuse.c:281  UCX  ERROR inotify_add_watch(/tmp) failed: No space left on device
[1738921931.891329] [297hi17a9s0l1-0:129431:f]        vfs_fuse.c:281  UCX  ERROR inotify_add_watch(/tmp) failed: No space left on device
[1738921931.899763] [297hi17a9s0l1-0:129433:f]        vfs_fuse.c:281  UCX  ERROR inotify_add_watch(/tmp) failed: No space left on device
[1738921931.905655] [297hi17a9s0l1-0:129429:f]        vfs_fuse.c:281  UCX  ERROR inotify_add_watch(/tmp) failed: No space left on device
[1738921931.913869] [297hi17a9s0l1-0:129428:f]        vfs_fuse.c:281  UCX  ERROR inotify_add_watch(/tmp) failed: No space left on device
[1738921932.411234] [297hi17a9s0l1-0:129435:f]        vfs_fuse.c:281  UCX  ERROR inotify_add_watch(/tmp) failed: No space left on device
[2025-02-07 09:52:19,607] [INFO] [RANK 0] global rank 0 is loading checkpoint ./pretrained_models/cogvideox-5b-i2v-sat/transformer/1/mp_rank_00_model_states.pt
[2025-02-07 09:52:49,075] [INFO] [RANK 0] > successfully loaded ./pretrained_models/cogvideox-5b-i2v-sat/transformer/1/mp_rank_00_model_states.pt
[2025-02-07 09:52:50,665] [INFO] [RANK 0] model.diffusion_model.transformer.layers.0.attention.query_key_value.weight
[2025-02-07 09:52:50,665] [INFO] [RANK 0] model.diffusion_model.transformer.layers.0.attention.query_key_value.bias
[2025-02-07 09:52:50,666] [INFO] [RANK 0] model.diffusion_model.transformer.layers.0.attention.dense.weight
[2025-02-07 09:52:50,666] [INFO] [RANK 0] model.diffusion_model.transformer.layers.0.attention.dense.bias
[2025-02-07 09:52:50,666] [INFO] [RANK 0] model.diffusion_model.transformer.layers.0.post_attention_layernorm.weight
[2025-02-07 09:52:50,666] [INFO] [RANK 0] model.diffusion_model.transformer.layers.0.post_attention_layernorm.bias
[2025-02-07 09:52:50,666] [INFO] [RANK 0] model.diffusion_model.transformer.layers.0.face_input_layernorm.weight
[2025-02-07 09:52:50,666] [INFO] [RANK 0] model.diffusion_model.transformer.layers.0.face_input_layernorm.bias
[2025-02-07 09:52:50,666] [INFO] [RANK 0] model.diffusion_model.transformer.layers.0.face_attn.query.weight
[2025-02-07 09:52:50,667] [INFO] [RANK 0] model.diffusion_model.transformer.layers.0.face_attn.query.bias
[2025-02-07 09:52:50,667] [INFO] [RANK 0] model.diffusion_model.transformer.layers.0.face_attn.key_value.weight
[2025-02-07 09:52:50,667] [INFO] [RANK 0] model.diffusion_model.transformer.layers.0.face_attn.key_value.bias
[2025-02-07 09:52:50,667] [INFO] [RANK 0] model.diffusion_model.transformer.layers.0.face_attn.dense.weight
[2025-02-07 09:52:50,667] [INFO] [RANK 0] model.diffusion_model.transformer.layers.0.face_attn.dense.bias
[2025-02-07 09:52:50,668] [INFO] [RANK 0] model.diffusion_model.transformer.layers.1.attention.query_key_value.weight
[2025-02-07 09:52:50,668] [INFO] [RANK 0] model.diffusion_model.transformer.layers.1.attention.query_key_value.bias
[2025-02-07 09:52:50,668] [INFO] [RANK 0] model.diffusion_model.transformer.layers.1.attention.dense.weight
[2025-02-07 09:52:50,668] [INFO] [RANK 0] model.diffusion_model.transformer.layers.1.attention.dense.bias
[2025-02-07 09:52:50,668] [INFO] [RANK 0] model.diffusion_model.transformer.layers.1.post_attention_layernorm.weight
[2025-02-07 09:52:50,669] [INFO] [RANK 0] model.diffusion_model.transformer.layers.1.post_attention_layernorm.bias
[2025-02-07 09:52:50,669] [INFO] [RANK 0] model.diffusion_model.transformer.layers.1.face_input_layernorm.weight
[2025-02-07 09:52:50,669] [INFO] [RANK 0] model.diffusion_model.transformer.layers.1.face_input_layernorm.bias
[2025-02-07 09:52:50,669] [INFO] [RANK 0] model.diffusion_model.transformer.layers.1.face_attn.query.weight
[2025-02-07 09:52:50,682] [INFO] [RANK 0] model.diffusion_model.transformer.layers.1.face_attn.query.bias
[2025-02-07 09:52:50,687] [INFO] [RANK 0] model.diffusion_model.transformer.layers.1.face_attn.key_value.weight
[2025-02-07 09:52:50,687] [INFO] [RANK 0] model.diffusion_model.transformer.layers.1.face_attn.key_value.bias
[2025-02-07 09:52:50,687] [INFO] [RANK 0] model.diffusion_model.transformer.layers.1.face_attn.dense.weight
[2025-02-07 09:52:50,688] [INFO] [RANK 0] model.diffusion_model.transformer.layers.1.face_attn.dense.bias
[2025-02-07 09:52:50,707] [INFO] [RANK 0] model.diffusion_model.transformer.layers.2.attention.query_key_value.weight
[2025-02-07 09:52:50,707] [INFO] [RANK 0] model.diffusion_model.transformer.layers.2.attention.query_key_value.bias
[2025-02-07 09:52:50,715] [INFO] [RANK 0] model.diffusion_model.transformer.layers.2.attention.dense.weight
[2025-02-07 09:52:50,716] [INFO] [RANK 0] model.diffusion_model.transformer.layers.2.attention.dense.bias
[2025-02-07 09:52:50,716] [INFO] [RANK 0] model.diffusion_model.transformer.layers.2.post_attention_layernorm.weight
[2025-02-07 09:52:50,716] [INFO] [RANK 0] model.diffusion_model.transformer.layers.2.post_attention_layernorm.bias
[2025-02-07 09:52:50,717] [INFO] [RANK 0] model.diffusion_model.transformer.layers.2.face_input_layernorm.weight
[2025-02-07 09:52:50,717] [INFO] [RANK 0] model.diffusion_model.transformer.layers.2.face_input_layernorm.bias
[2025-02-07 09:52:50,717] [INFO] [RANK 0] model.diffusion_model.transformer.layers.2.face_attn.query.weight
[2025-02-07 09:52:50,717] [INFO] [RANK 0] model.diffusion_model.transformer.layers.2.face_attn.query.bias
[2025-02-07 09:52:50,717] [INFO] [RANK 0] model.diffusion_model.transformer.layers.2.face_attn.key_value.weight
[2025-02-07 09:52:50,718] [INFO] [RANK 0] model.diffusion_model.transformer.layers.2.face_attn.key_value.bias
[2025-02-07 09:52:50,718] [INFO] [RANK 0] model.diffusion_model.transformer.layers.2.face_attn.dense.weight
[2025-02-07 09:52:50,718] [INFO] [RANK 0] model.diffusion_model.transformer.layers.2.face_attn.dense.bias
[2025-02-07 09:52:50,737] [INFO] [RANK 0] model.diffusion_model.transformer.layers.3.attention.query_key_value.weight
[2025-02-07 09:52:50,737] [INFO] [RANK 0] model.diffusion_model.transformer.layers.3.attention.query_key_value.bias
[2025-02-07 09:52:50,738] [INFO] [RANK 0] model.diffusion_model.transformer.layers.3.attention.dense.weight
[2025-02-07 09:52:50,738] [INFO] [RANK 0] model.diffusion_model.transformer.layers.3.attention.dense.bias
[2025-02-07 09:52:50,742] [INFO] [RANK 0] model.diffusion_model.transformer.layers.3.post_attention_layernorm.weight
[2025-02-07 09:52:50,743] [INFO] [RANK 0] model.diffusion_model.transformer.layers.3.post_attention_layernorm.bias
[2025-02-07 09:52:50,743] [INFO] [RANK 0] model.diffusion_model.transformer.layers.3.face_input_layernorm.weight
[2025-02-07 09:52:50,744] [INFO] [RANK 0] model.diffusion_model.transformer.layers.3.face_input_layernorm.bias
[2025-02-07 09:52:50,744] [INFO] [RANK 0] model.diffusion_model.transformer.layers.3.face_attn.query.weight
[2025-02-07 09:52:50,745] [INFO] [RANK 0] model.diffusion_model.transformer.layers.3.face_attn.query.bias
[2025-02-07 09:52:50,745] [INFO] [RANK 0] model.diffusion_model.transformer.layers.3.face_attn.key_value.weight
[2025-02-07 09:52:50,745] [INFO] [RANK 0] model.diffusion_model.transformer.layers.3.face_attn.key_value.bias
[2025-02-07 09:52:50,745] [INFO] [RANK 0] model.diffusion_model.transformer.layers.3.face_attn.dense.weight
[2025-02-07 09:52:50,745] [INFO] [RANK 0] model.diffusion_model.transformer.layers.3.face_attn.dense.bias
[2025-02-07 09:52:50,746] [INFO] [RANK 0] model.diffusion_model.transformer.layers.4.attention.query_key_value.weight
[2025-02-07 09:52:50,746] [INFO] [RANK 0] model.diffusion_model.transformer.layers.4.attention.query_key_value.bias
[2025-02-07 09:52:50,746] [INFO] [RANK 0] model.diffusion_model.transformer.layers.4.attention.dense.weight
[2025-02-07 09:52:50,747] [INFO] [RANK 0] model.diffusion_model.transformer.layers.4.attention.dense.bias
[2025-02-07 09:52:50,763] [INFO] [RANK 0] model.diffusion_model.transformer.layers.4.post_attention_layernorm.weight
[2025-02-07 09:52:50,764] [INFO] [RANK 0] model.diffusion_model.transformer.layers.4.post_attention_layernorm.bias
[2025-02-07 09:52:50,764] [INFO] [RANK 0] model.diffusion_model.transformer.layers.4.face_input_layernorm.weight
[2025-02-07 09:52:50,764] [INFO] [RANK 0] model.diffusion_model.transformer.layers.4.face_input_layernorm.bias
[2025-02-07 09:52:50,765] [INFO] [RANK 0] model.diffusion_model.transformer.layers.4.face_attn.query.weight
[2025-02-07 09:52:50,765] [INFO] [RANK 0] model.diffusion_model.transformer.layers.4.face_attn.query.bias
[2025-02-07 09:52:50,765] [INFO] [RANK 0] model.diffusion_model.transformer.layers.4.face_attn.key_value.weight
[2025-02-07 09:52:50,765] [INFO] [RANK 0] model.diffusion_model.transformer.layers.4.face_attn.key_value.bias
[2025-02-07 09:52:50,766] [INFO] [RANK 0] model.diffusion_model.transformer.layers.4.face_attn.dense.weight
[2025-02-07 09:52:50,766] [INFO] [RANK 0] model.diffusion_model.transformer.layers.4.face_attn.dense.bias
[2025-02-07 09:52:50,767] [INFO] [RANK 0] model.diffusion_model.transformer.layers.5.attention.query_key_value.weight
[2025-02-07 09:52:50,767] [INFO] [RANK 0] model.diffusion_model.transformer.layers.5.attention.query_key_value.bias
[2025-02-07 09:52:50,767] [INFO] [RANK 0] model.diffusion_model.transformer.layers.5.attention.dense.weight
[2025-02-07 09:52:50,768] [INFO] [RANK 0] model.diffusion_model.transformer.layers.5.attention.dense.bias
[2025-02-07 09:52:50,768] [INFO] [RANK 0] model.diffusion_model.transformer.layers.5.post_attention_layernorm.weight
[2025-02-07 09:52:50,768] [INFO] [RANK 0] model.diffusion_model.transformer.layers.5.post_attention_layernorm.bias
[2025-02-07 09:52:50,768] [INFO] [RANK 0] model.diffusion_model.transformer.layers.5.face_input_layernorm.weight
[2025-02-07 09:52:50,775] [INFO] [RANK 0] model.diffusion_model.transformer.layers.5.face_input_layernorm.bias
[2025-02-07 09:52:50,775] [INFO] [RANK 0] model.diffusion_model.transformer.layers.5.face_attn.query.weight
[2025-02-07 09:52:50,775] [INFO] [RANK 0] model.diffusion_model.transformer.layers.5.face_attn.query.bias
[2025-02-07 09:52:50,775] [INFO] [RANK 0] model.diffusion_model.transformer.layers.5.face_attn.key_value.weight
[2025-02-07 09:52:50,776] [INFO] [RANK 0] model.diffusion_model.transformer.layers.5.face_attn.key_value.bias
[2025-02-07 09:52:50,776] [INFO] [RANK 0] model.diffusion_model.transformer.layers.5.face_attn.dense.weight
[2025-02-07 09:52:50,776] [INFO] [RANK 0] model.diffusion_model.transformer.layers.5.face_attn.dense.bias
[2025-02-07 09:52:50,784] [INFO] [RANK 0] model.diffusion_model.transformer.layers.6.attention.query_key_value.weight
[2025-02-07 09:52:50,785] [INFO] [RANK 0] model.diffusion_model.transformer.layers.6.attention.query_key_value.bias
[2025-02-07 09:52:50,785] [INFO] [RANK 0] model.diffusion_model.transformer.layers.6.attention.dense.weight
[2025-02-07 09:52:50,785] [INFO] [RANK 0] model.diffusion_model.transformer.layers.6.attention.dense.bias
[2025-02-07 09:52:50,785] [INFO] [RANK 0] model.diffusion_model.transformer.layers.6.post_attention_layernorm.weight
[2025-02-07 09:52:50,786] [INFO] [RANK 0] model.diffusion_model.transformer.layers.6.post_attention_layernorm.bias
[2025-02-07 09:52:50,786] [INFO] [RANK 0] model.diffusion_model.transformer.layers.6.face_input_layernorm.weight
[2025-02-07 09:52:50,786] [INFO] [RANK 0] model.diffusion_model.transformer.layers.6.face_input_layernorm.bias
[2025-02-07 09:52:50,786] [INFO] [RANK 0] model.diffusion_model.transformer.layers.6.face_attn.query.weight
[2025-02-07 09:52:50,786] [INFO] [RANK 0] model.diffusion_model.transformer.layers.6.face_attn.query.bias
[2025-02-07 09:52:50,786] [INFO] [RANK 0] model.diffusion_model.transformer.layers.6.face_attn.key_value.weight
[2025-02-07 09:52:50,787] [INFO] [RANK 0] model.diffusion_model.transformer.layers.6.face_attn.key_value.bias
[2025-02-07 09:52:50,787] [INFO] [RANK 0] model.diffusion_model.transformer.layers.6.face_attn.dense.weight
[2025-02-07 09:52:50,801] [INFO] [RANK 0] model.diffusion_model.transformer.layers.6.face_attn.dense.bias
[2025-02-07 09:52:50,810] [INFO] [RANK 0] model.diffusion_model.transformer.layers.7.attention.query_key_value.weight
[2025-02-07 09:52:50,811] [INFO] [RANK 0] model.diffusion_model.transformer.layers.7.attention.query_key_value.bias
[2025-02-07 09:52:50,812] [INFO] [RANK 0] model.diffusion_model.transformer.layers.7.attention.dense.weight
[2025-02-07 09:52:50,812] [INFO] [RANK 0] model.diffusion_model.transformer.layers.7.attention.dense.bias
[2025-02-07 09:52:50,812] [INFO] [RANK 0] model.diffusion_model.transformer.layers.7.post_attention_layernorm.weight
[2025-02-07 09:52:50,812] [INFO] [RANK 0] model.diffusion_model.transformer.layers.7.post_attention_layernorm.bias
[2025-02-07 09:52:50,812] [INFO] [RANK 0] model.diffusion_model.transformer.layers.7.face_input_layernorm.weight
[2025-02-07 09:52:50,813] [INFO] [RANK 0] model.diffusion_model.transformer.layers.7.face_input_layernorm.bias
[2025-02-07 09:52:50,813] [INFO] [RANK 0] model.diffusion_model.transformer.layers.7.face_attn.query.weight
[2025-02-07 09:52:50,813] [INFO] [RANK 0] model.diffusion_model.transformer.layers.7.face_attn.query.bias
[2025-02-07 09:52:50,813] [INFO] [RANK 0] model.diffusion_model.transformer.layers.7.face_attn.key_value.weight
[2025-02-07 09:52:50,813] [INFO] [RANK 0] model.diffusion_model.transformer.layers.7.face_attn.key_value.bias
[2025-02-07 09:52:50,814] [INFO] [RANK 0] model.diffusion_model.transformer.layers.7.face_attn.dense.weight
[2025-02-07 09:52:50,814] [INFO] [RANK 0] model.diffusion_model.transformer.layers.7.face_attn.dense.bias
[2025-02-07 09:52:50,815] [INFO] [RANK 0] model.diffusion_model.transformer.layers.8.attention.query_key_value.weight
[2025-02-07 09:52:50,815] [INFO] [RANK 0] model.diffusion_model.transformer.layers.8.attention.query_key_value.bias
[2025-02-07 09:52:50,815] [INFO] [RANK 0] model.diffusion_model.transformer.layers.8.attention.dense.weight
[2025-02-07 09:52:50,815] [INFO] [RANK 0] model.diffusion_model.transformer.layers.8.attention.dense.bias
[2025-02-07 09:52:50,815] [INFO] [RANK 0] model.diffusion_model.transformer.layers.8.post_attention_layernorm.weight
[2025-02-07 09:52:50,815] [INFO] [RANK 0] model.diffusion_model.transformer.layers.8.post_attention_layernorm.bias
[2025-02-07 09:52:50,816] [INFO] [RANK 0] model.diffusion_model.transformer.layers.8.face_input_layernorm.weight
[2025-02-07 09:52:50,816] [INFO] [RANK 0] model.diffusion_model.transformer.layers.8.face_input_layernorm.bias
[2025-02-07 09:52:50,816] [INFO] [RANK 0] model.diffusion_model.transformer.layers.8.face_attn.query.weight
[2025-02-07 09:52:50,816] [INFO] [RANK 0] model.diffusion_model.transformer.layers.8.face_attn.query.bias
[2025-02-07 09:52:50,816] [INFO] [RANK 0] model.diffusion_model.transformer.layers.8.face_attn.key_value.weight
[2025-02-07 09:52:50,817] [INFO] [RANK 0] model.diffusion_model.transformer.layers.8.face_attn.key_value.bias
[2025-02-07 09:52:50,817] [INFO] [RANK 0] model.diffusion_model.transformer.layers.8.face_attn.dense.weight
[2025-02-07 09:52:50,817] [INFO] [RANK 0] model.diffusion_model.transformer.layers.8.face_attn.dense.bias
[2025-02-07 09:52:50,818] [INFO] [RANK 0] model.diffusion_model.transformer.layers.9.attention.query_key_value.weight
[2025-02-07 09:52:50,818] [INFO] [RANK 0] model.diffusion_model.transformer.layers.9.attention.query_key_value.bias
[2025-02-07 09:52:50,818] [INFO] [RANK 0] model.diffusion_model.transformer.layers.9.attention.dense.weight
[2025-02-07 09:52:50,818] [INFO] [RANK 0] model.diffusion_model.transformer.layers.9.attention.dense.bias
[2025-02-07 09:52:50,819] [INFO] [RANK 0] model.diffusion_model.transformer.layers.9.post_attention_layernorm.weight
[2025-02-07 09:52:50,819] [INFO] [RANK 0] model.diffusion_model.transformer.layers.9.post_attention_layernorm.bias
[2025-02-07 09:52:50,819] [INFO] [RANK 0] model.diffusion_model.transformer.layers.9.face_input_layernorm.weight
[2025-02-07 09:52:50,819] [INFO] [RANK 0] model.diffusion_model.transformer.layers.9.face_input_layernorm.bias
[2025-02-07 09:52:50,829] [INFO] [RANK 0] model.diffusion_model.transformer.layers.9.face_attn.query.weight
[2025-02-07 09:52:50,829] [INFO] [RANK 0] model.diffusion_model.transformer.layers.9.face_attn.query.bias
[2025-02-07 09:52:50,829] [INFO] [RANK 0] model.diffusion_model.transformer.layers.9.face_attn.key_value.weight
[2025-02-07 09:52:50,830] [INFO] [RANK 0] model.diffusion_model.transformer.layers.9.face_attn.key_value.bias
[2025-02-07 09:52:50,830] [INFO] [RANK 0] model.diffusion_model.transformer.layers.9.face_attn.dense.weight
[2025-02-07 09:52:50,830] [INFO] [RANK 0] model.diffusion_model.transformer.layers.9.face_attn.dense.bias
[2025-02-07 09:52:50,831] [INFO] [RANK 0] model.diffusion_model.transformer.layers.10.attention.query_key_value.weight
[2025-02-07 09:52:50,832] [INFO] [RANK 0] model.diffusion_model.transformer.layers.10.attention.query_key_value.bias
[2025-02-07 09:52:50,833] [INFO] [RANK 0] model.diffusion_model.transformer.layers.10.attention.dense.weight
[2025-02-07 09:52:50,835] [INFO] [RANK 0] model.diffusion_model.transformer.layers.10.attention.dense.bias
[2025-02-07 09:52:50,836] [INFO] [RANK 0] model.diffusion_model.transformer.layers.10.post_attention_layernorm.weight
[2025-02-07 09:52:50,836] [INFO] [RANK 0] model.diffusion_model.transformer.layers.10.post_attention_layernorm.bias
[2025-02-07 09:52:50,836] [INFO] [RANK 0] model.diffusion_model.transformer.layers.10.face_input_layernorm.weight
[2025-02-07 09:52:50,836] [INFO] [RANK 0] model.diffusion_model.transformer.layers.10.face_input_layernorm.bias
[2025-02-07 09:52:50,836] [INFO] [RANK 0] model.diffusion_model.transformer.layers.10.face_attn.query.weight
[2025-02-07 09:52:50,836] [INFO] [RANK 0] model.diffusion_model.transformer.layers.10.face_attn.query.bias
[2025-02-07 09:52:50,837] [INFO] [RANK 0] model.diffusion_model.transformer.layers.10.face_attn.key_value.weight
[2025-02-07 09:52:50,837] [INFO] [RANK 0] model.diffusion_model.transformer.layers.10.face_attn.key_value.bias
[2025-02-07 09:52:50,837] [INFO] [RANK 0] model.diffusion_model.transformer.layers.10.face_attn.dense.weight
[2025-02-07 09:52:50,837] [INFO] [RANK 0] model.diffusion_model.transformer.layers.10.face_attn.dense.bias
[2025-02-07 09:52:50,838] [INFO] [RANK 0] model.diffusion_model.transformer.layers.11.attention.query_key_value.weight
[2025-02-07 09:52:50,852] [INFO] [RANK 0] model.diffusion_model.transformer.layers.11.attention.query_key_value.bias
[2025-02-07 09:52:50,853] [INFO] [RANK 0] model.diffusion_model.transformer.layers.11.attention.dense.weight
[2025-02-07 09:52:50,854] [INFO] [RANK 0] model.diffusion_model.transformer.layers.11.attention.dense.bias
[2025-02-07 09:52:50,854] [INFO] [RANK 0] model.diffusion_model.transformer.layers.11.post_attention_layernorm.weight
[2025-02-07 09:52:50,854] [INFO] [RANK 0] model.diffusion_model.transformer.layers.11.post_attention_layernorm.bias
[2025-02-07 09:52:50,854] [INFO] [RANK 0] model.diffusion_model.transformer.layers.11.face_input_layernorm.weight
[2025-02-07 09:52:50,854] [INFO] [RANK 0] model.diffusion_model.transformer.layers.11.face_input_layernorm.bias
[2025-02-07 09:52:50,855] [INFO] [RANK 0] model.diffusion_model.transformer.layers.11.face_attn.query.weight
[2025-02-07 09:52:50,855] [INFO] [RANK 0] model.diffusion_model.transformer.layers.11.face_attn.query.bias
[2025-02-07 09:52:50,855] [INFO] [RANK 0] model.diffusion_model.transformer.layers.11.face_attn.key_value.weight
[2025-02-07 09:52:50,855] [INFO] [RANK 0] model.diffusion_model.transformer.layers.11.face_attn.key_value.bias
[2025-02-07 09:52:50,855] [INFO] [RANK 0] model.diffusion_model.transformer.layers.11.face_attn.dense.weight
[2025-02-07 09:52:50,856] [INFO] [RANK 0] model.diffusion_model.transformer.layers.11.face_attn.dense.bias
[2025-02-07 09:52:50,858] [INFO] [RANK 0] model.diffusion_model.transformer.layers.12.attention.query_key_value.weight
[2025-02-07 09:52:50,858] [INFO] [RANK 0] model.diffusion_model.transformer.layers.12.attention.query_key_value.bias
[2025-02-07 09:52:50,858] [INFO] [RANK 0] model.diffusion_model.transformer.layers.12.attention.dense.weight
[2025-02-07 09:52:50,865] [INFO] [RANK 0] model.diffusion_model.transformer.layers.12.attention.dense.bias
[2025-02-07 09:52:50,865] [INFO] [RANK 0] model.diffusion_model.transformer.layers.12.post_attention_layernorm.weight
[2025-02-07 09:52:50,865] [INFO] [RANK 0] model.diffusion_model.transformer.layers.12.post_attention_layernorm.bias
[2025-02-07 09:52:50,866] [INFO] [RANK 0] model.diffusion_model.transformer.layers.12.face_input_layernorm.weight
[2025-02-07 09:52:50,866] [INFO] [RANK 0] model.diffusion_model.transformer.layers.12.face_input_layernorm.bias
[2025-02-07 09:52:50,892] [INFO] [RANK 0] model.diffusion_model.transformer.layers.12.face_attn.query.weight
[2025-02-07 09:52:50,896] [INFO] [RANK 0] model.diffusion_model.transformer.layers.12.face_attn.query.bias
[2025-02-07 09:52:50,898] [INFO] [RANK 0] model.diffusion_model.transformer.layers.12.face_attn.key_value.weight
[2025-02-07 09:52:50,898] [INFO] [RANK 0] model.diffusion_model.transformer.layers.12.face_attn.key_value.bias
[2025-02-07 09:52:50,898] [INFO] [RANK 0] model.diffusion_model.transformer.layers.12.face_attn.dense.weight
[2025-02-07 09:52:50,899] [INFO] [RANK 0] model.diffusion_model.transformer.layers.12.face_attn.dense.bias
[2025-02-07 09:52:50,900] [INFO] [RANK 0] model.diffusion_model.transformer.layers.13.attention.query_key_value.weight
[2025-02-07 09:52:50,900] [INFO] [RANK 0] model.diffusion_model.transformer.layers.13.attention.query_key_value.bias
[2025-02-07 09:52:50,900] [INFO] [RANK 0] model.diffusion_model.transformer.layers.13.attention.dense.weight
[2025-02-07 09:52:50,900] [INFO] [RANK 0] model.diffusion_model.transformer.layers.13.attention.dense.bias
[2025-02-07 09:52:50,900] [INFO] [RANK 0] model.diffusion_model.transformer.layers.13.post_attention_layernorm.weight
[2025-02-07 09:52:50,901] [INFO] [RANK 0] model.diffusion_model.transformer.layers.13.post_attention_layernorm.bias
[2025-02-07 09:52:50,901] [INFO] [RANK 0] model.diffusion_model.transformer.layers.13.face_input_layernorm.weight
[2025-02-07 09:52:50,901] [INFO] [RANK 0] model.diffusion_model.transformer.layers.13.face_input_layernorm.bias
[2025-02-07 09:52:50,901] [INFO] [RANK 0] model.diffusion_model.transformer.layers.13.face_attn.query.weight
[2025-02-07 09:52:50,901] [INFO] [RANK 0] model.diffusion_model.transformer.layers.13.face_attn.query.bias
[2025-02-07 09:52:50,902] [INFO] [RANK 0] model.diffusion_model.transformer.layers.13.face_attn.key_value.weight
[2025-02-07 09:52:50,903] [INFO] [RANK 0] model.diffusion_model.transformer.layers.13.face_attn.key_value.bias
[2025-02-07 09:52:50,903] [INFO] [RANK 0] model.diffusion_model.transformer.layers.13.face_attn.dense.weight
[2025-02-07 09:52:50,903] [INFO] [RANK 0] model.diffusion_model.transformer.layers.13.face_attn.dense.bias
[2025-02-07 09:52:50,904] [INFO] [RANK 0] model.diffusion_model.transformer.layers.14.attention.query_key_value.weight
[2025-02-07 09:52:50,904] [INFO] [RANK 0] model.diffusion_model.transformer.layers.14.attention.query_key_value.bias
[2025-02-07 09:52:50,916] [INFO] [RANK 0] model.diffusion_model.transformer.layers.14.attention.dense.weight
[2025-02-07 09:52:50,916] [INFO] [RANK 0] model.diffusion_model.transformer.layers.14.attention.dense.bias
[2025-02-07 09:52:50,919] [INFO] [RANK 0] model.diffusion_model.transformer.layers.14.post_attention_layernorm.weight
[2025-02-07 09:52:50,920] [INFO] [RANK 0] model.diffusion_model.transformer.layers.14.post_attention_layernorm.bias
[2025-02-07 09:52:50,920] [INFO] [RANK 0] model.diffusion_model.transformer.layers.14.face_input_layernorm.weight
[2025-02-07 09:52:50,920] [INFO] [RANK 0] model.diffusion_model.transformer.layers.14.face_input_layernorm.bias
[2025-02-07 09:52:50,921] [INFO] [RANK 0] model.diffusion_model.transformer.layers.14.face_attn.query.weight
[2025-02-07 09:52:50,921] [INFO] [RANK 0] model.diffusion_model.transformer.layers.14.face_attn.query.bias
[2025-02-07 09:52:50,921] [INFO] [RANK 0] model.diffusion_model.transformer.layers.14.face_attn.key_value.weight
[2025-02-07 09:52:50,927] [INFO] [RANK 0] model.diffusion_model.transformer.layers.14.face_attn.key_value.bias
[2025-02-07 09:52:50,927] [INFO] [RANK 0] model.diffusion_model.transformer.layers.14.face_attn.dense.weight
[2025-02-07 09:52:50,928] [INFO] [RANK 0] model.diffusion_model.transformer.layers.14.face_attn.dense.bias
[2025-02-07 09:52:50,929] [INFO] [RANK 0] model.diffusion_model.transformer.layers.15.attention.query_key_value.weight
[2025-02-07 09:52:50,929] [INFO] [RANK 0] model.diffusion_model.transformer.layers.15.attention.query_key_value.bias
[2025-02-07 09:52:50,929] [INFO] [RANK 0] model.diffusion_model.transformer.layers.15.attention.dense.weight
[2025-02-07 09:52:50,929] [INFO] [RANK 0] model.diffusion_model.transformer.layers.15.attention.dense.bias
[2025-02-07 09:52:50,929] [INFO] [RANK 0] model.diffusion_model.transformer.layers.15.post_attention_layernorm.weight
[2025-02-07 09:52:50,930] [INFO] [RANK 0] model.diffusion_model.transformer.layers.15.post_attention_layernorm.bias
[2025-02-07 09:52:50,930] [INFO] [RANK 0] model.diffusion_model.transformer.layers.15.face_input_layernorm.weight
[2025-02-07 09:52:50,930] [INFO] [RANK 0] model.diffusion_model.transformer.layers.15.face_input_layernorm.bias
[2025-02-07 09:52:50,930] [INFO] [RANK 0] model.diffusion_model.transformer.layers.15.face_attn.query.weight
[2025-02-07 09:52:50,931] [INFO] [RANK 0] model.diffusion_model.transformer.layers.15.face_attn.query.bias
[2025-02-07 09:52:50,931] [INFO] [RANK 0] model.diffusion_model.transformer.layers.15.face_attn.key_value.weight
[2025-02-07 09:52:50,931] [INFO] [RANK 0] model.diffusion_model.transformer.layers.15.face_attn.key_value.bias
[2025-02-07 09:52:50,931] [INFO] [RANK 0] model.diffusion_model.transformer.layers.15.face_attn.dense.weight
[2025-02-07 09:52:50,931] [INFO] [RANK 0] model.diffusion_model.transformer.layers.15.face_attn.dense.bias
[2025-02-07 09:52:50,932] [INFO] [RANK 0] model.diffusion_model.transformer.layers.16.attention.query_key_value.weight
[2025-02-07 09:52:50,933] [INFO] [RANK 0] model.diffusion_model.transformer.layers.16.attention.query_key_value.bias
[2025-02-07 09:52:50,933] [INFO] [RANK 0] model.diffusion_model.transformer.layers.16.attention.dense.weight
[2025-02-07 09:52:50,933] [INFO] [RANK 0] model.diffusion_model.transformer.layers.16.attention.dense.bias
[2025-02-07 09:52:50,933] [INFO] [RANK 0] model.diffusion_model.transformer.layers.16.post_attention_layernorm.weight
[2025-02-07 09:52:50,933] [INFO] [RANK 0] model.diffusion_model.transformer.layers.16.post_attention_layernorm.bias
[2025-02-07 09:52:50,933] [INFO] [RANK 0] model.diffusion_model.transformer.layers.16.face_input_layernorm.weight
[2025-02-07 09:52:50,934] [INFO] [RANK 0] model.diffusion_model.transformer.layers.16.face_input_layernorm.bias
[2025-02-07 09:52:50,934] [INFO] [RANK 0] model.diffusion_model.transformer.layers.16.face_attn.query.weight
[2025-02-07 09:52:50,934] [INFO] [RANK 0] model.diffusion_model.transformer.layers.16.face_attn.query.bias
[2025-02-07 09:52:50,934] [INFO] [RANK 0] model.diffusion_model.transformer.layers.16.face_attn.key_value.weight
[2025-02-07 09:52:50,934] [INFO] [RANK 0] model.diffusion_model.transformer.layers.16.face_attn.key_value.bias
[2025-02-07 09:52:50,935] [INFO] [RANK 0] model.diffusion_model.transformer.layers.16.face_attn.dense.weight
[2025-02-07 09:52:50,935] [INFO] [RANK 0] model.diffusion_model.transformer.layers.16.face_attn.dense.bias
[2025-02-07 09:52:50,936] [INFO] [RANK 0] model.diffusion_model.transformer.layers.17.attention.query_key_value.weight
[2025-02-07 09:52:50,936] [INFO] [RANK 0] model.diffusion_model.transformer.layers.17.attention.query_key_value.bias
[2025-02-07 09:52:50,936] [INFO] [RANK 0] model.diffusion_model.transformer.layers.17.attention.dense.weight
[2025-02-07 09:52:50,936] [INFO] [RANK 0] model.diffusion_model.transformer.layers.17.attention.dense.bias
[2025-02-07 09:52:50,937] [INFO] [RANK 0] model.diffusion_model.transformer.layers.17.post_attention_layernorm.weight
[2025-02-07 09:52:50,937] [INFO] [RANK 0] model.diffusion_model.transformer.layers.17.post_attention_layernorm.bias
[2025-02-07 09:52:50,950] [INFO] [RANK 0] model.diffusion_model.transformer.layers.17.face_input_layernorm.weight
[2025-02-07 09:52:50,951] [INFO] [RANK 0] model.diffusion_model.transformer.layers.17.face_input_layernorm.bias
[2025-02-07 09:52:50,951] [INFO] [RANK 0] model.diffusion_model.transformer.layers.17.face_attn.query.weight
[2025-02-07 09:52:50,951] [INFO] [RANK 0] model.diffusion_model.transformer.layers.17.face_attn.query.bias
[2025-02-07 09:52:50,952] [INFO] [RANK 0] model.diffusion_model.transformer.layers.17.face_attn.key_value.weight
[2025-02-07 09:52:50,952] [INFO] [RANK 0] model.diffusion_model.transformer.layers.17.face_attn.key_value.bias
[2025-02-07 09:52:50,952] [INFO] [RANK 0] model.diffusion_model.transformer.layers.17.face_attn.dense.weight
[2025-02-07 09:52:50,952] [INFO] [RANK 0] model.diffusion_model.transformer.layers.17.face_attn.dense.bias
[2025-02-07 09:52:50,953] [INFO] [RANK 0] model.diffusion_model.transformer.layers.18.attention.query_key_value.weight
[2025-02-07 09:52:50,953] [INFO] [RANK 0] model.diffusion_model.transformer.layers.18.attention.query_key_value.bias
[2025-02-07 09:52:50,954] [INFO] [RANK 0] model.diffusion_model.transformer.layers.18.attention.dense.weight
[2025-02-07 09:52:50,954] [INFO] [RANK 0] model.diffusion_model.transformer.layers.18.attention.dense.bias
[2025-02-07 09:52:50,954] [INFO] [RANK 0] model.diffusion_model.transformer.layers.18.post_attention_layernorm.weight
[2025-02-07 09:52:50,954] [INFO] [RANK 0] model.diffusion_model.transformer.layers.18.post_attention_layernorm.bias
[2025-02-07 09:52:50,954] [INFO] [RANK 0] model.diffusion_model.transformer.layers.18.face_input_layernorm.weight
[2025-02-07 09:52:50,954] [INFO] [RANK 0] model.diffusion_model.transformer.layers.18.face_input_layernorm.bias
[2025-02-07 09:52:50,955] [INFO] [RANK 0] model.diffusion_model.transformer.layers.18.face_attn.query.weight
[2025-02-07 09:52:50,955] [INFO] [RANK 0] model.diffusion_model.transformer.layers.18.face_attn.query.bias
[2025-02-07 09:52:50,955] [INFO] [RANK 0] model.diffusion_model.transformer.layers.18.face_attn.key_value.weight
[2025-02-07 09:52:50,955] [INFO] [RANK 0] model.diffusion_model.transformer.layers.18.face_attn.key_value.bias
[2025-02-07 09:52:50,955] [INFO] [RANK 0] model.diffusion_model.transformer.layers.18.face_attn.dense.weight
[2025-02-07 09:52:50,956] [INFO] [RANK 0] model.diffusion_model.transformer.layers.18.face_attn.dense.bias
[2025-02-07 09:52:50,956] [INFO] [RANK 0] model.diffusion_model.transformer.layers.19.attention.query_key_value.weight
[2025-02-07 09:52:50,957] [INFO] [RANK 0] model.diffusion_model.transformer.layers.19.attention.query_key_value.bias
[2025-02-07 09:52:50,957] [INFO] [RANK 0] model.diffusion_model.transformer.layers.19.attention.dense.weight
[2025-02-07 09:52:50,957] [INFO] [RANK 0] model.diffusion_model.transformer.layers.19.attention.dense.bias
[2025-02-07 09:52:50,957] [INFO] [RANK 0] model.diffusion_model.transformer.layers.19.post_attention_layernorm.weight
[2025-02-07 09:52:50,957] [INFO] [RANK 0] model.diffusion_model.transformer.layers.19.post_attention_layernorm.bias
[2025-02-07 09:52:50,958] [INFO] [RANK 0] model.diffusion_model.transformer.layers.19.face_input_layernorm.weight
[2025-02-07 09:52:50,958] [INFO] [RANK 0] model.diffusion_model.transformer.layers.19.face_input_layernorm.bias
[2025-02-07 09:52:50,958] [INFO] [RANK 0] model.diffusion_model.transformer.layers.19.face_attn.query.weight
[2025-02-07 09:52:50,958] [INFO] [RANK 0] model.diffusion_model.transformer.layers.19.face_attn.query.bias
[2025-02-07 09:52:50,958] [INFO] [RANK 0] model.diffusion_model.transformer.layers.19.face_attn.key_value.weight
[2025-02-07 09:52:50,959] [INFO] [RANK 0] model.diffusion_model.transformer.layers.19.face_attn.key_value.bias
[2025-02-07 09:52:50,959] [INFO] [RANK 0] model.diffusion_model.transformer.layers.19.face_attn.dense.weight
[2025-02-07 09:52:50,964] [INFO] [RANK 0] model.diffusion_model.transformer.layers.19.face_attn.dense.bias
[2025-02-07 09:52:50,966] [INFO] [RANK 0] model.diffusion_model.transformer.layers.20.attention.query_key_value.weight
[2025-02-07 09:52:50,980] [INFO] [RANK 0] model.diffusion_model.transformer.layers.20.attention.query_key_value.bias
[2025-02-07 09:52:50,985] [INFO] [RANK 0] model.diffusion_model.transformer.layers.20.attention.dense.weight
[2025-02-07 09:52:50,985] [INFO] [RANK 0] model.diffusion_model.transformer.layers.20.attention.dense.bias
[2025-02-07 09:52:50,988] [INFO] [RANK 0] model.diffusion_model.transformer.layers.20.post_attention_layernorm.weight
[2025-02-07 09:52:51,003] [INFO] [RANK 0] model.diffusion_model.transformer.layers.20.post_attention_layernorm.bias
[2025-02-07 09:52:51,003] [INFO] [RANK 0] model.diffusion_model.transformer.layers.20.face_input_layernorm.weight
[2025-02-07 09:52:51,004] [INFO] [RANK 0] model.diffusion_model.transformer.layers.20.face_input_layernorm.bias
[2025-02-07 09:52:51,031] [INFO] [RANK 0] model.diffusion_model.transformer.layers.20.face_attn.query.weight
[2025-02-07 09:52:51,031] [INFO] [RANK 0] model.diffusion_model.transformer.layers.20.face_attn.query.bias
[2025-02-07 09:52:51,031] [INFO] [RANK 0] model.diffusion_model.transformer.layers.20.face_attn.key_value.weight
[2025-02-07 09:52:51,031] [INFO] [RANK 0] model.diffusion_model.transformer.layers.20.face_attn.key_value.bias
[2025-02-07 09:52:51,032] [INFO] [RANK 0] model.diffusion_model.transformer.layers.20.face_attn.dense.weight
[2025-02-07 09:52:51,032] [INFO] [RANK 0] model.diffusion_model.transformer.layers.20.face_attn.dense.bias
[2025-02-07 09:52:51,033] [INFO] [RANK 0] model.diffusion_model.transformer.layers.21.attention.query_key_value.weight
[2025-02-07 09:52:51,033] [INFO] [RANK 0] model.diffusion_model.transformer.layers.21.attention.query_key_value.bias
[2025-02-07 09:52:51,033] [INFO] [RANK 0] model.diffusion_model.transformer.layers.21.attention.dense.weight
[2025-02-07 09:52:51,033] [INFO] [RANK 0] model.diffusion_model.transformer.layers.21.attention.dense.bias
[2025-02-07 09:52:51,033] [INFO] [RANK 0] model.diffusion_model.transformer.layers.21.post_attention_layernorm.weight
[2025-02-07 09:52:51,034] [INFO] [RANK 0] model.diffusion_model.transformer.layers.21.post_attention_layernorm.bias
[2025-02-07 09:52:51,034] [INFO] [RANK 0] model.diffusion_model.transformer.layers.21.face_input_layernorm.weight
[2025-02-07 09:52:51,034] [INFO] [RANK 0] model.diffusion_model.transformer.layers.21.face_input_layernorm.bias
[2025-02-07 09:52:51,034] [INFO] [RANK 0] model.diffusion_model.transformer.layers.21.face_attn.query.weight
[2025-02-07 09:52:51,034] [INFO] [RANK 0] model.diffusion_model.transformer.layers.21.face_attn.query.bias
[2025-02-07 09:52:51,034] [INFO] [RANK 0] model.diffusion_model.transformer.layers.21.face_attn.key_value.weight
[2025-02-07 09:52:51,034] [INFO] [RANK 0] model.diffusion_model.transformer.layers.21.face_attn.key_value.bias
[2025-02-07 09:52:51,035] [INFO] [RANK 0] model.diffusion_model.transformer.layers.21.face_attn.dense.weight
[2025-02-07 09:52:51,035] [INFO] [RANK 0] model.diffusion_model.transformer.layers.21.face_attn.dense.bias
[2025-02-07 09:52:51,035] [INFO] [RANK 0] model.diffusion_model.transformer.layers.22.attention.query_key_value.weight
[2025-02-07 09:52:51,036] [INFO] [RANK 0] model.diffusion_model.transformer.layers.22.attention.query_key_value.bias
[2025-02-07 09:52:51,036] [INFO] [RANK 0] model.diffusion_model.transformer.layers.22.attention.dense.weight
[2025-02-07 09:52:51,036] [INFO] [RANK 0] model.diffusion_model.transformer.layers.22.attention.dense.bias
[2025-02-07 09:52:51,036] [INFO] [RANK 0] model.diffusion_model.transformer.layers.22.post_attention_layernorm.weight
[2025-02-07 09:52:51,036] [INFO] [RANK 0] model.diffusion_model.transformer.layers.22.post_attention_layernorm.bias
[2025-02-07 09:52:51,036] [INFO] [RANK 0] model.diffusion_model.transformer.layers.22.face_input_layernorm.weight
[2025-02-07 09:52:51,037] [INFO] [RANK 0] model.diffusion_model.transformer.layers.22.face_input_layernorm.bias
[2025-02-07 09:52:51,037] [INFO] [RANK 0] model.diffusion_model.transformer.layers.22.face_attn.query.weight
[2025-02-07 09:52:51,040] [INFO] [RANK 0] model.diffusion_model.transformer.layers.22.face_attn.query.bias
[2025-02-07 09:52:51,040] [INFO] [RANK 0] model.diffusion_model.transformer.layers.22.face_attn.key_value.weight
[2025-02-07 09:52:51,040] [INFO] [RANK 0] model.diffusion_model.transformer.layers.22.face_attn.key_value.bias
[2025-02-07 09:52:51,040] [INFO] [RANK 0] model.diffusion_model.transformer.layers.22.face_attn.dense.weight
[2025-02-07 09:52:51,041] [INFO] [RANK 0] model.diffusion_model.transformer.layers.22.face_attn.dense.bias
[2025-02-07 09:52:51,041] [INFO] [RANK 0] model.diffusion_model.transformer.layers.23.attention.query_key_value.weight
[2025-02-07 09:52:51,042] [INFO] [RANK 0] model.diffusion_model.transformer.layers.23.attention.query_key_value.bias
[2025-02-07 09:52:51,042] [INFO] [RANK 0] model.diffusion_model.transformer.layers.23.attention.dense.weight
[2025-02-07 09:52:51,042] [INFO] [RANK 0] model.diffusion_model.transformer.layers.23.attention.dense.bias
[2025-02-07 09:52:51,042] [INFO] [RANK 0] model.diffusion_model.transformer.layers.23.post_attention_layernorm.weight
[2025-02-07 09:52:51,042] [INFO] [RANK 0] model.diffusion_model.transformer.layers.23.post_attention_layernorm.bias
[2025-02-07 09:52:51,043] [INFO] [RANK 0] model.diffusion_model.transformer.layers.23.face_input_layernorm.weight
[2025-02-07 09:52:51,043] [INFO] [RANK 0] model.diffusion_model.transformer.layers.23.face_input_layernorm.bias
[2025-02-07 09:52:51,043] [INFO] [RANK 0] model.diffusion_model.transformer.layers.23.face_attn.query.weight
[2025-02-07 09:52:51,043] [INFO] [RANK 0] model.diffusion_model.transformer.layers.23.face_attn.query.bias
[2025-02-07 09:52:51,043] [INFO] [RANK 0] model.diffusion_model.transformer.layers.23.face_attn.key_value.weight
[2025-02-07 09:52:51,043] [INFO] [RANK 0] model.diffusion_model.transformer.layers.23.face_attn.key_value.bias
[2025-02-07 09:52:51,043] [INFO] [RANK 0] model.diffusion_model.transformer.layers.23.face_attn.dense.weight
[2025-02-07 09:52:51,044] [INFO] [RANK 0] model.diffusion_model.transformer.layers.23.face_attn.dense.bias
[2025-02-07 09:52:51,044] [INFO] [RANK 0] model.diffusion_model.transformer.layers.24.attention.query_key_value.weight
[2025-02-07 09:52:51,044] [INFO] [RANK 0] model.diffusion_model.transformer.layers.24.attention.query_key_value.bias
[2025-02-07 09:52:51,045] [INFO] [RANK 0] model.diffusion_model.transformer.layers.24.attention.dense.weight
[2025-02-07 09:52:51,045] [INFO] [RANK 0] model.diffusion_model.transformer.layers.24.attention.dense.bias
[2025-02-07 09:52:51,045] [INFO] [RANK 0] model.diffusion_model.transformer.layers.24.post_attention_layernorm.weight
[2025-02-07 09:52:51,045] [INFO] [RANK 0] model.diffusion_model.transformer.layers.24.post_attention_layernorm.bias
[2025-02-07 09:52:51,045] [INFO] [RANK 0] model.diffusion_model.transformer.layers.24.face_input_layernorm.weight
[2025-02-07 09:52:51,046] [INFO] [RANK 0] model.diffusion_model.transformer.layers.24.face_input_layernorm.bias
[2025-02-07 09:52:51,046] [INFO] [RANK 0] model.diffusion_model.transformer.layers.24.face_attn.query.weight
[2025-02-07 09:52:51,046] [INFO] [RANK 0] model.diffusion_model.transformer.layers.24.face_attn.query.bias
[2025-02-07 09:52:51,046] [INFO] [RANK 0] model.diffusion_model.transformer.layers.24.face_attn.key_value.weight
[2025-02-07 09:52:51,046] [INFO] [RANK 0] model.diffusion_model.transformer.layers.24.face_attn.key_value.bias
[2025-02-07 09:52:51,047] [INFO] [RANK 0] model.diffusion_model.transformer.layers.24.face_attn.dense.weight
[2025-02-07 09:52:51,047] [INFO] [RANK 0] model.diffusion_model.transformer.layers.24.face_attn.dense.bias
[2025-02-07 09:52:51,047] [INFO] [RANK 0] model.diffusion_model.transformer.layers.25.attention.query_key_value.weight
[2025-02-07 09:52:51,048] [INFO] [RANK 0] model.diffusion_model.transformer.layers.25.attention.query_key_value.bias
[2025-02-07 09:52:51,048] [INFO] [RANK 0] model.diffusion_model.transformer.layers.25.attention.dense.weight
[2025-02-07 09:52:51,048] [INFO] [RANK 0] model.diffusion_model.transformer.layers.25.attention.dense.bias
[2025-02-07 09:52:51,072] [INFO] [RANK 0] model.diffusion_model.transformer.layers.25.post_attention_layernorm.weight
[2025-02-07 09:52:51,073] [INFO] [RANK 0] model.diffusion_model.transformer.layers.25.post_attention_layernorm.bias
[2025-02-07 09:52:51,073] [INFO] [RANK 0] model.diffusion_model.transformer.layers.25.face_input_layernorm.weight
[2025-02-07 09:52:51,073] [INFO] [RANK 0] model.diffusion_model.transformer.layers.25.face_input_layernorm.bias
[2025-02-07 09:52:51,073] [INFO] [RANK 0] model.diffusion_model.transformer.layers.25.face_attn.query.weight
[2025-02-07 09:52:51,074] [INFO] [RANK 0] model.diffusion_model.transformer.layers.25.face_attn.query.bias
[2025-02-07 09:52:51,074] [INFO] [RANK 0] model.diffusion_model.transformer.layers.25.face_attn.key_value.weight
[2025-02-07 09:52:51,074] [INFO] [RANK 0] model.diffusion_model.transformer.layers.25.face_attn.key_value.bias
[2025-02-07 09:52:51,074] [INFO] [RANK 0] model.diffusion_model.transformer.layers.25.face_attn.dense.weight
[2025-02-07 09:52:51,074] [INFO] [RANK 0] model.diffusion_model.transformer.layers.25.face_attn.dense.bias
[2025-02-07 09:52:51,075] [INFO] [RANK 0] model.diffusion_model.transformer.layers.26.attention.query_key_value.weight
[2025-02-07 09:52:51,075] [INFO] [RANK 0] model.diffusion_model.transformer.layers.26.attention.query_key_value.bias
[2025-02-07 09:52:51,075] [INFO] [RANK 0] model.diffusion_model.transformer.layers.26.attention.dense.weight
[2025-02-07 09:52:51,076] [INFO] [RANK 0] model.diffusion_model.transformer.layers.26.attention.dense.bias
[2025-02-07 09:52:51,076] [INFO] [RANK 0] model.diffusion_model.transformer.layers.26.post_attention_layernorm.weight
[2025-02-07 09:52:51,076] [INFO] [RANK 0] model.diffusion_model.transformer.layers.26.post_attention_layernorm.bias
[2025-02-07 09:52:51,076] [INFO] [RANK 0] model.diffusion_model.transformer.layers.26.face_input_layernorm.weight
[2025-02-07 09:52:51,076] [INFO] [RANK 0] model.diffusion_model.transformer.layers.26.face_input_layernorm.bias
[2025-02-07 09:52:51,076] [INFO] [RANK 0] model.diffusion_model.transformer.layers.26.face_attn.query.weight
[2025-02-07 09:52:51,076] [INFO] [RANK 0] model.diffusion_model.transformer.layers.26.face_attn.query.bias
[2025-02-07 09:52:51,076] [INFO] [RANK 0] model.diffusion_model.transformer.layers.26.face_attn.key_value.weight
[2025-02-07 09:52:51,077] [INFO] [RANK 0] model.diffusion_model.transformer.layers.26.face_attn.key_value.bias
[2025-02-07 09:52:51,077] [INFO] [RANK 0] model.diffusion_model.transformer.layers.26.face_attn.dense.weight
[2025-02-07 09:52:51,077] [INFO] [RANK 0] model.diffusion_model.transformer.layers.26.face_attn.dense.bias
[2025-02-07 09:52:51,077] [INFO] [RANK 0] model.diffusion_model.transformer.layers.27.attention.query_key_value.weight
[2025-02-07 09:52:51,077] [INFO] [RANK 0] model.diffusion_model.transformer.layers.27.attention.query_key_value.bias
[2025-02-07 09:52:51,078] [INFO] [RANK 0] model.diffusion_model.transformer.layers.27.attention.dense.weight
[2025-02-07 09:52:51,078] [INFO] [RANK 0] model.diffusion_model.transformer.layers.27.attention.dense.bias
[2025-02-07 09:52:51,078] [INFO] [RANK 0] model.diffusion_model.transformer.layers.27.post_attention_layernorm.weight
[2025-02-07 09:52:51,078] [INFO] [RANK 0] model.diffusion_model.transformer.layers.27.post_attention_layernorm.bias
[2025-02-07 09:52:51,078] [INFO] [RANK 0] model.diffusion_model.transformer.layers.27.face_input_layernorm.weight
[2025-02-07 09:52:51,078] [INFO] [RANK 0] model.diffusion_model.transformer.layers.27.face_input_layernorm.bias
[2025-02-07 09:52:51,078] [INFO] [RANK 0] model.diffusion_model.transformer.layers.27.face_attn.query.weight
[2025-02-07 09:52:51,078] [INFO] [RANK 0] model.diffusion_model.transformer.layers.27.face_attn.query.bias
[2025-02-07 09:52:51,079] [INFO] [RANK 0] model.diffusion_model.transformer.layers.27.face_attn.key_value.weight
[2025-02-07 09:52:51,079] [INFO] [RANK 0] model.diffusion_model.transformer.layers.27.face_attn.key_value.bias
[2025-02-07 09:52:51,083] [INFO] [RANK 0] model.diffusion_model.transformer.layers.27.face_attn.dense.weight
[2025-02-07 09:52:51,100] [INFO] [RANK 0] model.diffusion_model.transformer.layers.27.face_attn.dense.bias
[2025-02-07 09:52:51,103] [INFO] [RANK 0] model.diffusion_model.transformer.layers.28.attention.query_key_value.weight
[2025-02-07 09:52:51,104] [INFO] [RANK 0] model.diffusion_model.transformer.layers.28.attention.query_key_value.bias
[2025-02-07 09:52:51,104] [INFO] [RANK 0] model.diffusion_model.transformer.layers.28.attention.dense.weight
[2025-02-07 09:52:51,104] [INFO] [RANK 0] model.diffusion_model.transformer.layers.28.attention.dense.bias
[2025-02-07 09:52:51,105] [INFO] [RANK 0] model.diffusion_model.transformer.layers.28.post_attention_layernorm.weight
[2025-02-07 09:52:51,105] [INFO] [RANK 0] model.diffusion_model.transformer.layers.28.post_attention_layernorm.bias
[2025-02-07 09:52:51,105] [INFO] [RANK 0] model.diffusion_model.transformer.layers.28.face_input_layernorm.weight
[2025-02-07 09:52:51,105] [INFO] [RANK 0] model.diffusion_model.transformer.layers.28.face_input_layernorm.bias
[2025-02-07 09:52:51,105] [INFO] [RANK 0] model.diffusion_model.transformer.layers.28.face_attn.query.weight
[2025-02-07 09:52:51,105] [INFO] [RANK 0] model.diffusion_model.transformer.layers.28.face_attn.query.bias
[2025-02-07 09:52:51,106] [INFO] [RANK 0] model.diffusion_model.transformer.layers.28.face_attn.key_value.weight
[2025-02-07 09:52:51,106] [INFO] [RANK 0] model.diffusion_model.transformer.layers.28.face_attn.key_value.bias
[2025-02-07 09:52:51,106] [INFO] [RANK 0] model.diffusion_model.transformer.layers.28.face_attn.dense.weight
[2025-02-07 09:52:51,106] [INFO] [RANK 0] model.diffusion_model.transformer.layers.28.face_attn.dense.bias
[2025-02-07 09:52:51,107] [INFO] [RANK 0] model.diffusion_model.transformer.layers.29.attention.query_key_value.weight
[2025-02-07 09:52:51,107] [INFO] [RANK 0] model.diffusion_model.transformer.layers.29.attention.query_key_value.bias
[2025-02-07 09:52:51,124] [INFO] [RANK 0] model.diffusion_model.transformer.layers.29.attention.dense.weight
[2025-02-07 09:52:51,138] [INFO] [RANK 0] model.diffusion_model.transformer.layers.29.attention.dense.bias
[2025-02-07 09:52:51,138] [INFO] [RANK 0] model.diffusion_model.transformer.layers.29.post_attention_layernorm.weight
[2025-02-07 09:52:51,139] [INFO] [RANK 0] model.diffusion_model.transformer.layers.29.post_attention_layernorm.bias
[2025-02-07 09:52:51,139] [INFO] [RANK 0] model.diffusion_model.transformer.layers.29.face_input_layernorm.weight
[2025-02-07 09:52:51,139] [INFO] [RANK 0] model.diffusion_model.transformer.layers.29.face_input_layernorm.bias
[2025-02-07 09:52:51,139] [INFO] [RANK 0] model.diffusion_model.transformer.layers.29.face_attn.query.weight
[2025-02-07 09:52:51,139] [INFO] [RANK 0] model.diffusion_model.transformer.layers.29.face_attn.query.bias
[2025-02-07 09:52:51,140] [INFO] [RANK 0] model.diffusion_model.transformer.layers.29.face_attn.key_value.weight
[2025-02-07 09:52:51,140] [INFO] [RANK 0] model.diffusion_model.transformer.layers.29.face_attn.key_value.bias
[2025-02-07 09:52:51,140] [INFO] [RANK 0] model.diffusion_model.transformer.layers.29.face_attn.dense.weight
[2025-02-07 09:52:51,140] [INFO] [RANK 0] model.diffusion_model.transformer.layers.29.face_attn.dense.bias
[2025-02-07 09:52:51,141] [INFO] [RANK 0] model.diffusion_model.transformer.layers.30.attention.query_key_value.weight
[2025-02-07 09:52:51,141] [INFO] [RANK 0] model.diffusion_model.transformer.layers.30.attention.query_key_value.bias
[2025-02-07 09:52:51,141] [INFO] [RANK 0] model.diffusion_model.transformer.layers.30.attention.dense.weight
[2025-02-07 09:52:51,141] [INFO] [RANK 0] model.diffusion_model.transformer.layers.30.attention.dense.bias
[2025-02-07 09:52:51,142] [INFO] [RANK 0] model.diffusion_model.transformer.layers.30.post_attention_layernorm.weight
[2025-02-07 09:52:51,142] [INFO] [RANK 0] model.diffusion_model.transformer.layers.30.post_attention_layernorm.bias
[2025-02-07 09:52:51,142] [INFO] [RANK 0] model.diffusion_model.transformer.layers.30.face_input_layernorm.weight
[2025-02-07 09:52:51,176] [INFO] [RANK 0] model.diffusion_model.transformer.layers.30.face_input_layernorm.bias
[2025-02-07 09:52:51,177] [INFO] [RANK 0] model.diffusion_model.transformer.layers.30.face_attn.query.weight
[2025-02-07 09:52:51,177] [INFO] [RANK 0] model.diffusion_model.transformer.layers.30.face_attn.query.bias
[2025-02-07 09:52:51,177] [INFO] [RANK 0] model.diffusion_model.transformer.layers.30.face_attn.key_value.weight
[2025-02-07 09:52:51,178] [INFO] [RANK 0] model.diffusion_model.transformer.layers.30.face_attn.key_value.bias
[2025-02-07 09:52:51,178] [INFO] [RANK 0] model.diffusion_model.transformer.layers.30.face_attn.dense.weight
[2025-02-07 09:52:51,178] [INFO] [RANK 0] model.diffusion_model.transformer.layers.30.face_attn.dense.bias
[2025-02-07 09:52:51,179] [INFO] [RANK 0] model.diffusion_model.transformer.layers.31.attention.query_key_value.weight
[2025-02-07 09:52:51,192] [INFO] [RANK 0] model.diffusion_model.transformer.layers.31.attention.query_key_value.bias
[2025-02-07 09:52:51,192] [INFO] [RANK 0] model.diffusion_model.transformer.layers.31.attention.dense.weight
[2025-02-07 09:52:51,193] [INFO] [RANK 0] model.diffusion_model.transformer.layers.31.attention.dense.bias
[2025-02-07 09:52:51,193] [INFO] [RANK 0] model.diffusion_model.transformer.layers.31.post_attention_layernorm.weight
[2025-02-07 09:52:51,193] [INFO] [RANK 0] model.diffusion_model.transformer.layers.31.post_attention_layernorm.bias
[2025-02-07 09:52:51,193] [INFO] [RANK 0] model.diffusion_model.transformer.layers.31.face_input_layernorm.weight
[2025-02-07 09:52:51,193] [INFO] [RANK 0] model.diffusion_model.transformer.layers.31.face_input_layernorm.bias
[2025-02-07 09:52:51,193] [INFO] [RANK 0] model.diffusion_model.transformer.layers.31.face_attn.query.weight
[2025-02-07 09:52:51,194] [INFO] [RANK 0] model.diffusion_model.transformer.layers.31.face_attn.query.bias
[2025-02-07 09:52:51,194] [INFO] [RANK 0] model.diffusion_model.transformer.layers.31.face_attn.key_value.weight
[2025-02-07 09:52:51,194] [INFO] [RANK 0] model.diffusion_model.transformer.layers.31.face_attn.key_value.bias
[2025-02-07 09:52:51,206] [INFO] [RANK 0] model.diffusion_model.transformer.layers.31.face_attn.dense.weight
[2025-02-07 09:52:51,206] [INFO] [RANK 0] model.diffusion_model.transformer.layers.31.face_attn.dense.bias
[2025-02-07 09:52:51,234] [INFO] [RANK 0] model.diffusion_model.transformer.layers.32.attention.query_key_value.weight
[2025-02-07 09:52:51,234] [INFO] [RANK 0] model.diffusion_model.transformer.layers.32.attention.query_key_value.bias
[2025-02-07 09:52:51,235] [INFO] [RANK 0] model.diffusion_model.transformer.layers.32.attention.dense.weight
[2025-02-07 09:52:51,235] [INFO] [RANK 0] model.diffusion_model.transformer.layers.32.attention.dense.bias
[2025-02-07 09:52:51,235] [INFO] [RANK 0] model.diffusion_model.transformer.layers.32.post_attention_layernorm.weight
[2025-02-07 09:52:51,235] [INFO] [RANK 0] model.diffusion_model.transformer.layers.32.post_attention_layernorm.bias
[2025-02-07 09:52:51,235] [INFO] [RANK 0] model.diffusion_model.transformer.layers.32.face_input_layernorm.weight
[2025-02-07 09:52:51,236] [INFO] [RANK 0] model.diffusion_model.transformer.layers.32.face_input_layernorm.bias
[2025-02-07 09:52:51,236] [INFO] [RANK 0] model.diffusion_model.transformer.layers.32.face_attn.query.weight
[2025-02-07 09:52:51,236] [INFO] [RANK 0] model.diffusion_model.transformer.layers.32.face_attn.query.bias
[2025-02-07 09:52:51,236] [INFO] [RANK 0] model.diffusion_model.transformer.layers.32.face_attn.key_value.weight
[2025-02-07 09:52:51,236] [INFO] [RANK 0] model.diffusion_model.transformer.layers.32.face_attn.key_value.bias
[2025-02-07 09:52:51,236] [INFO] [RANK 0] model.diffusion_model.transformer.layers.32.face_attn.dense.weight
[2025-02-07 09:52:51,237] [INFO] [RANK 0] model.diffusion_model.transformer.layers.32.face_attn.dense.bias
[2025-02-07 09:52:51,237] [INFO] [RANK 0] model.diffusion_model.transformer.layers.33.attention.query_key_value.weight
[2025-02-07 09:52:51,255] [INFO] [RANK 0] model.diffusion_model.transformer.layers.33.attention.query_key_value.bias
[2025-02-07 09:52:51,255] [INFO] [RANK 0] model.diffusion_model.transformer.layers.33.attention.dense.weight
[2025-02-07 09:52:51,255] [INFO] [RANK 0] model.diffusion_model.transformer.layers.33.attention.dense.bias
[2025-02-07 09:52:51,256] [INFO] [RANK 0] model.diffusion_model.transformer.layers.33.post_attention_layernorm.weight
[2025-02-07 09:52:51,256] [INFO] [RANK 0] model.diffusion_model.transformer.layers.33.post_attention_layernorm.bias
[2025-02-07 09:52:51,256] [INFO] [RANK 0] model.diffusion_model.transformer.layers.33.face_input_layernorm.weight
[2025-02-07 09:52:51,264] [INFO] [RANK 0] model.diffusion_model.transformer.layers.33.face_input_layernorm.bias
[2025-02-07 09:52:51,265] [INFO] [RANK 0] model.diffusion_model.transformer.layers.33.face_attn.query.weight
[2025-02-07 09:52:51,265] [INFO] [RANK 0] model.diffusion_model.transformer.layers.33.face_attn.query.bias
[2025-02-07 09:52:51,265] [INFO] [RANK 0] model.diffusion_model.transformer.layers.33.face_attn.key_value.weight
[2025-02-07 09:52:51,265] [INFO] [RANK 0] model.diffusion_model.transformer.layers.33.face_attn.key_value.bias
[2025-02-07 09:52:51,266] [INFO] [RANK 0] model.diffusion_model.transformer.layers.33.face_attn.dense.weight
[2025-02-07 09:52:51,266] [INFO] [RANK 0] model.diffusion_model.transformer.layers.33.face_attn.dense.bias
[2025-02-07 09:52:51,267] [INFO] [RANK 0] model.diffusion_model.transformer.layers.34.attention.query_key_value.weight
[2025-02-07 09:52:51,278] [INFO] [RANK 0] model.diffusion_model.transformer.layers.34.attention.query_key_value.bias
[2025-02-07 09:52:51,278] [INFO] [RANK 0] model.diffusion_model.transformer.layers.34.attention.dense.weight
[2025-02-07 09:52:51,278] [INFO] [RANK 0] model.diffusion_model.transformer.layers.34.attention.dense.bias
[2025-02-07 09:52:51,279] [INFO] [RANK 0] model.diffusion_model.transformer.layers.34.post_attention_layernorm.weight
[2025-02-07 09:52:51,279] [INFO] [RANK 0] model.diffusion_model.transformer.layers.34.post_attention_layernorm.bias
[2025-02-07 09:52:51,279] [INFO] [RANK 0] model.diffusion_model.transformer.layers.34.face_input_layernorm.weight
[2025-02-07 09:52:51,279] [INFO] [RANK 0] model.diffusion_model.transformer.layers.34.face_input_layernorm.bias
[2025-02-07 09:52:51,279] [INFO] [RANK 0] model.diffusion_model.transformer.layers.34.face_attn.query.weight
[2025-02-07 09:52:51,279] [INFO] [RANK 0] model.diffusion_model.transformer.layers.34.face_attn.query.bias
[2025-02-07 09:52:51,280] [INFO] [RANK 0] model.diffusion_model.transformer.layers.34.face_attn.key_value.weight
[2025-02-07 09:52:51,280] [INFO] [RANK 0] model.diffusion_model.transformer.layers.34.face_attn.key_value.bias
[2025-02-07 09:52:51,280] [INFO] [RANK 0] model.diffusion_model.transformer.layers.34.face_attn.dense.weight
[2025-02-07 09:52:51,280] [INFO] [RANK 0] model.diffusion_model.transformer.layers.34.face_attn.dense.bias
[2025-02-07 09:52:51,281] [INFO] [RANK 0] model.diffusion_model.transformer.layers.35.attention.query_key_value.weight
[2025-02-07 09:52:51,281] [INFO] [RANK 0] model.diffusion_model.transformer.layers.35.attention.query_key_value.bias
[2025-02-07 09:52:51,282] [INFO] [RANK 0] model.diffusion_model.transformer.layers.35.attention.dense.weight
[2025-02-07 09:52:51,282] [INFO] [RANK 0] model.diffusion_model.transformer.layers.35.attention.dense.bias
[2025-02-07 09:52:51,282] [INFO] [RANK 0] model.diffusion_model.transformer.layers.35.post_attention_layernorm.weight
[2025-02-07 09:52:51,282] [INFO] [RANK 0] model.diffusion_model.transformer.layers.35.post_attention_layernorm.bias
[2025-02-07 09:52:51,282] [INFO] [RANK 0] model.diffusion_model.transformer.layers.35.face_input_layernorm.weight
[2025-02-07 09:52:51,282] [INFO] [RANK 0] model.diffusion_model.transformer.layers.35.face_input_layernorm.bias
[2025-02-07 09:52:51,283] [INFO] [RANK 0] model.diffusion_model.transformer.layers.35.face_attn.query.weight
[2025-02-07 09:52:51,283] [INFO] [RANK 0] model.diffusion_model.transformer.layers.35.face_attn.query.bias
[2025-02-07 09:52:51,310] [INFO] [RANK 0] model.diffusion_model.transformer.layers.35.face_attn.key_value.weight
[2025-02-07 09:52:51,310] [INFO] [RANK 0] model.diffusion_model.transformer.layers.35.face_attn.key_value.bias
[2025-02-07 09:52:51,310] [INFO] [RANK 0] model.diffusion_model.transformer.layers.35.face_attn.dense.weight
[2025-02-07 09:52:51,311] [INFO] [RANK 0] model.diffusion_model.transformer.layers.35.face_attn.dense.bias
[2025-02-07 09:52:51,312] [INFO] [RANK 0] model.diffusion_model.transformer.layers.36.attention.query_key_value.weight
[2025-02-07 09:52:51,312] [INFO] [RANK 0] model.diffusion_model.transformer.layers.36.attention.query_key_value.bias
[2025-02-07 09:52:51,312] [INFO] [RANK 0] model.diffusion_model.transformer.layers.36.attention.dense.weight
[2025-02-07 09:52:51,312] [INFO] [RANK 0] model.diffusion_model.transformer.layers.36.attention.dense.bias
[2025-02-07 09:52:51,312] [INFO] [RANK 0] model.diffusion_model.transformer.layers.36.post_attention_layernorm.weight
[2025-02-07 09:52:51,313] [INFO] [RANK 0] model.diffusion_model.transformer.layers.36.post_attention_layernorm.bias
[2025-02-07 09:52:51,313] [INFO] [RANK 0] model.diffusion_model.transformer.layers.36.face_input_layernorm.weight
[2025-02-07 09:52:51,313] [INFO] [RANK 0] model.diffusion_model.transformer.layers.36.face_input_layernorm.bias
[2025-02-07 09:52:51,324] [INFO] [RANK 0] model.diffusion_model.transformer.layers.36.face_attn.query.weight
[2025-02-07 09:52:51,325] [INFO] [RANK 0] model.diffusion_model.transformer.layers.36.face_attn.query.bias
[2025-02-07 09:52:51,325] [INFO] [RANK 0] model.diffusion_model.transformer.layers.36.face_attn.key_value.weight
[2025-02-07 09:52:51,325] [INFO] [RANK 0] model.diffusion_model.transformer.layers.36.face_attn.key_value.bias
[2025-02-07 09:52:51,325] [INFO] [RANK 0] model.diffusion_model.transformer.layers.36.face_attn.dense.weight
[2025-02-07 09:52:51,326] [INFO] [RANK 0] model.diffusion_model.transformer.layers.36.face_attn.dense.bias
[2025-02-07 09:52:51,327] [INFO] [RANK 0] model.diffusion_model.transformer.layers.37.attention.query_key_value.weight
[2025-02-07 09:52:51,327] [INFO] [RANK 0] model.diffusion_model.transformer.layers.37.attention.query_key_value.bias
[2025-02-07 09:52:51,327] [INFO] [RANK 0] model.diffusion_model.transformer.layers.37.attention.dense.weight
[2025-02-07 09:52:51,327] [INFO] [RANK 0] model.diffusion_model.transformer.layers.37.attention.dense.bias
[2025-02-07 09:52:51,327] [INFO] [RANK 0] model.diffusion_model.transformer.layers.37.post_attention_layernorm.weight
[2025-02-07 09:52:51,327] [INFO] [RANK 0] model.diffusion_model.transformer.layers.37.post_attention_layernorm.bias
[2025-02-07 09:52:51,328] [INFO] [RANK 0] model.diffusion_model.transformer.layers.37.face_input_layernorm.weight
[2025-02-07 09:52:51,328] [INFO] [RANK 0] model.diffusion_model.transformer.layers.37.face_input_layernorm.bias
[2025-02-07 09:52:51,328] [INFO] [RANK 0] model.diffusion_model.transformer.layers.37.face_attn.query.weight
[2025-02-07 09:52:51,328] [INFO] [RANK 0] model.diffusion_model.transformer.layers.37.face_attn.query.bias
[2025-02-07 09:52:51,328] [INFO] [RANK 0] model.diffusion_model.transformer.layers.37.face_attn.key_value.weight
[2025-02-07 09:52:51,328] [INFO] [RANK 0] model.diffusion_model.transformer.layers.37.face_attn.key_value.bias
[2025-02-07 09:52:51,329] [INFO] [RANK 0] model.diffusion_model.transformer.layers.37.face_attn.dense.weight
[2025-02-07 09:52:51,329] [INFO] [RANK 0] model.diffusion_model.transformer.layers.37.face_attn.dense.bias
[2025-02-07 09:52:51,330] [INFO] [RANK 0] model.diffusion_model.transformer.layers.38.attention.query_key_value.weight
[2025-02-07 09:52:51,330] [INFO] [RANK 0] model.diffusion_model.transformer.layers.38.attention.query_key_value.bias
[2025-02-07 09:52:51,330] [INFO] [RANK 0] model.diffusion_model.transformer.layers.38.attention.dense.weight
[2025-02-07 09:52:51,330] [INFO] [RANK 0] model.diffusion_model.transformer.layers.38.attention.dense.bias
[2025-02-07 09:52:51,374] [INFO] [RANK 0] model.diffusion_model.transformer.layers.38.post_attention_layernorm.weight
[2025-02-07 09:52:51,374] [INFO] [RANK 0] model.diffusion_model.transformer.layers.38.post_attention_layernorm.bias
[2025-02-07 09:52:51,374] [INFO] [RANK 0] model.diffusion_model.transformer.layers.38.face_input_layernorm.weight
[2025-02-07 09:52:51,374] [INFO] [RANK 0] model.diffusion_model.transformer.layers.38.face_input_layernorm.bias
[2025-02-07 09:52:51,374] [INFO] [RANK 0] model.diffusion_model.transformer.layers.38.face_attn.query.weight
[2025-02-07 09:52:51,375] [INFO] [RANK 0] model.diffusion_model.transformer.layers.38.face_attn.query.bias
[2025-02-07 09:52:51,375] [INFO] [RANK 0] model.diffusion_model.transformer.layers.38.face_attn.key_value.weight
[2025-02-07 09:52:51,375] [INFO] [RANK 0] model.diffusion_model.transformer.layers.38.face_attn.key_value.bias
[2025-02-07 09:52:51,375] [INFO] [RANK 0] model.diffusion_model.transformer.layers.38.face_attn.dense.weight
[2025-02-07 09:52:51,375] [INFO] [RANK 0] model.diffusion_model.transformer.layers.38.face_attn.dense.bias
[2025-02-07 09:52:51,376] [INFO] [RANK 0] model.diffusion_model.transformer.layers.39.attention.query_key_value.weight
[2025-02-07 09:52:51,376] [INFO] [RANK 0] model.diffusion_model.transformer.layers.39.attention.query_key_value.bias
[2025-02-07 09:52:51,376] [INFO] [RANK 0] model.diffusion_model.transformer.layers.39.attention.dense.weight
[2025-02-07 09:52:51,377] [INFO] [RANK 0] model.diffusion_model.transformer.layers.39.attention.dense.bias
[2025-02-07 09:52:51,377] [INFO] [RANK 0] model.diffusion_model.transformer.layers.39.post_attention_layernorm.weight
[2025-02-07 09:52:51,377] [INFO] [RANK 0] model.diffusion_model.transformer.layers.39.post_attention_layernorm.bias
[2025-02-07 09:52:51,377] [INFO] [RANK 0] model.diffusion_model.transformer.layers.39.face_input_layernorm.weight
[2025-02-07 09:52:51,377] [INFO] [RANK 0] model.diffusion_model.transformer.layers.39.face_input_layernorm.bias
[2025-02-07 09:52:51,378] [INFO] [RANK 0] model.diffusion_model.transformer.layers.39.face_attn.query.weight
[2025-02-07 09:52:51,378] [INFO] [RANK 0] model.diffusion_model.transformer.layers.39.face_attn.query.bias
[2025-02-07 09:52:51,378] [INFO] [RANK 0] model.diffusion_model.transformer.layers.39.face_attn.key_value.weight
[2025-02-07 09:52:51,378] [INFO] [RANK 0] model.diffusion_model.transformer.layers.39.face_attn.key_value.bias
[2025-02-07 09:52:51,378] [INFO] [RANK 0] model.diffusion_model.transformer.layers.39.face_attn.dense.weight
[2025-02-07 09:52:51,378] [INFO] [RANK 0] model.diffusion_model.transformer.layers.39.face_attn.dense.bias
[2025-02-07 09:52:51,379] [INFO] [RANK 0] model.diffusion_model.transformer.layers.40.attention.query_key_value.weight
[2025-02-07 09:52:51,379] [INFO] [RANK 0] model.diffusion_model.transformer.layers.40.attention.query_key_value.bias
[2025-02-07 09:52:51,380] [INFO] [RANK 0] model.diffusion_model.transformer.layers.40.attention.dense.weight
[2025-02-07 09:52:51,380] [INFO] [RANK 0] model.diffusion_model.transformer.layers.40.attention.dense.bias
[2025-02-07 09:52:51,380] [INFO] [RANK 0] model.diffusion_model.transformer.layers.40.post_attention_layernorm.weight
[2025-02-07 09:52:51,380] [INFO] [RANK 0] model.diffusion_model.transformer.layers.40.post_attention_layernorm.bias
[2025-02-07 09:52:51,380] [INFO] [RANK 0] model.diffusion_model.transformer.layers.40.face_input_layernorm.weight
[2025-02-07 09:52:51,380] [INFO] [RANK 0] model.diffusion_model.transformer.layers.40.face_input_layernorm.bias
[2025-02-07 09:52:51,381] [INFO] [RANK 0] model.diffusion_model.transformer.layers.40.face_attn.query.weight
[2025-02-07 09:52:51,381] [INFO] [RANK 0] model.diffusion_model.transformer.layers.40.face_attn.query.bias
[2025-02-07 09:52:51,381] [INFO] [RANK 0] model.diffusion_model.transformer.layers.40.face_attn.key_value.weight
[2025-02-07 09:52:51,381] [INFO] [RANK 0] model.diffusion_model.transformer.layers.40.face_attn.key_value.bias
[2025-02-07 09:52:51,381] [INFO] [RANK 0] model.diffusion_model.transformer.layers.40.face_attn.dense.weight
[2025-02-07 09:52:51,403] [INFO] [RANK 0] model.diffusion_model.transformer.layers.40.face_attn.dense.bias
[2025-02-07 09:52:51,425] [INFO] [RANK 0] model.diffusion_model.transformer.layers.41.attention.query_key_value.weight
[2025-02-07 09:52:51,426] [INFO] [RANK 0] model.diffusion_model.transformer.layers.41.attention.query_key_value.bias
[2025-02-07 09:52:51,426] [INFO] [RANK 0] model.diffusion_model.transformer.layers.41.attention.dense.weight
[2025-02-07 09:52:51,426] [INFO] [RANK 0] model.diffusion_model.transformer.layers.41.attention.dense.bias
[2025-02-07 09:52:51,426] [INFO] [RANK 0] model.diffusion_model.transformer.layers.41.post_attention_layernorm.weight
[2025-02-07 09:52:51,426] [INFO] [RANK 0] model.diffusion_model.transformer.layers.41.post_attention_layernorm.bias
[2025-02-07 09:52:51,426] [INFO] [RANK 0] model.diffusion_model.transformer.layers.41.face_input_layernorm.weight
[2025-02-07 09:52:51,427] [INFO] [RANK 0] model.diffusion_model.transformer.layers.41.face_input_layernorm.bias
[2025-02-07 09:52:51,427] [INFO] [RANK 0] model.diffusion_model.transformer.layers.41.face_attn.query.weight
[2025-02-07 09:52:51,427] [INFO] [RANK 0] model.diffusion_model.transformer.layers.41.face_attn.query.bias
[2025-02-07 09:52:51,427] [INFO] [RANK 0] model.diffusion_model.transformer.layers.41.face_attn.key_value.weight
[2025-02-07 09:52:51,427] [INFO] [RANK 0] model.diffusion_model.transformer.layers.41.face_attn.key_value.bias
[2025-02-07 09:52:51,427] [INFO] [RANK 0] model.diffusion_model.transformer.layers.41.face_attn.dense.weight
[2025-02-07 09:52:51,427] [INFO] [RANK 0] model.diffusion_model.transformer.layers.41.face_attn.dense.bias
[2025-02-07 09:52:51,428] [INFO] [RANK 0] model.diffusion_model.transformer.face_proj.proj.weight
[2025-02-07 09:52:51,428] [INFO] [RANK 0] model.diffusion_model.transformer.face_proj.proj.bias
[2025-02-07 09:52:51,428] [INFO] [RANK 0] model.diffusion_model.transformer.face_proj.norm.weight
[2025-02-07 09:52:51,428] [INFO] [RANK 0] model.diffusion_model.transformer.face_proj.norm.bias
[2025-02-07 09:52:51,497] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.0.attention.query_key_value.weight
[2025-02-07 09:52:51,497] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.0.attention.query_key_value.bias
[2025-02-07 09:52:51,497] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.0.attention.dense.weight
[2025-02-07 09:52:51,497] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.0.attention.dense.bias
[2025-02-07 09:52:51,497] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.0.post_attention_layernorm.weight
[2025-02-07 09:52:51,498] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.0.post_attention_layernorm.bias
[2025-02-07 09:52:51,498] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.1.attention.query_key_value.weight
[2025-02-07 09:52:51,498] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.1.attention.query_key_value.bias
[2025-02-07 09:52:51,498] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.1.attention.dense.weight
[2025-02-07 09:52:51,499] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.1.attention.dense.bias
[2025-02-07 09:52:51,499] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.1.post_attention_layernorm.weight
[2025-02-07 09:52:51,499] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.1.post_attention_layernorm.bias
[2025-02-07 09:52:51,500] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.2.attention.query_key_value.weight
[2025-02-07 09:52:51,500] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.2.attention.query_key_value.bias
[2025-02-07 09:52:51,500] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.2.attention.dense.weight
[2025-02-07 09:52:51,500] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.2.attention.dense.bias
[2025-02-07 09:52:51,500] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.2.post_attention_layernorm.weight
[2025-02-07 09:52:51,517] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.2.post_attention_layernorm.bias
[2025-02-07 09:52:51,518] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.3.attention.query_key_value.weight
[2025-02-07 09:52:51,519] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.3.attention.query_key_value.bias
[2025-02-07 09:52:51,519] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.3.attention.dense.weight
[2025-02-07 09:52:51,519] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.3.attention.dense.bias
[2025-02-07 09:52:51,519] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.3.post_attention_layernorm.weight
[2025-02-07 09:52:51,519] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.3.post_attention_layernorm.bias
[2025-02-07 09:52:51,520] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.4.attention.query_key_value.weight
[2025-02-07 09:52:51,520] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.4.attention.query_key_value.bias
[2025-02-07 09:52:51,520] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.4.attention.dense.weight
[2025-02-07 09:52:51,521] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.4.attention.dense.bias
[2025-02-07 09:52:51,521] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.4.post_attention_layernorm.weight
[2025-02-07 09:52:51,521] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.4.post_attention_layernorm.bias
[2025-02-07 09:52:51,543] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.5.attention.query_key_value.weight
[2025-02-07 09:52:51,543] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.5.attention.query_key_value.bias
[2025-02-07 09:52:51,543] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.5.attention.dense.weight
[2025-02-07 09:52:51,543] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.5.attention.dense.bias
[2025-02-07 09:52:51,543] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.5.post_attention_layernorm.weight
[2025-02-07 09:52:51,544] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.5.post_attention_layernorm.bias
[2025-02-07 09:52:51,544] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.6.attention.query_key_value.weight
[2025-02-07 09:52:51,544] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.6.attention.query_key_value.bias
[2025-02-07 09:52:51,544] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.6.attention.dense.weight
[2025-02-07 09:52:51,545] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.6.attention.dense.bias
[2025-02-07 09:52:51,545] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.6.post_attention_layernorm.weight
[2025-02-07 09:52:51,545] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.6.post_attention_layernorm.bias
[2025-02-07 09:52:51,545] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.7.attention.query_key_value.weight
[2025-02-07 09:52:51,546] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.7.attention.query_key_value.bias
[2025-02-07 09:52:51,546] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.7.attention.dense.weight
[2025-02-07 09:52:51,546] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.7.attention.dense.bias
[2025-02-07 09:52:51,546] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.7.post_attention_layernorm.weight
[2025-02-07 09:52:51,546] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.7.post_attention_layernorm.bias
[2025-02-07 09:52:51,547] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.8.attention.query_key_value.weight
[2025-02-07 09:52:51,547] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.8.attention.query_key_value.bias
[2025-02-07 09:52:51,547] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.8.attention.dense.weight
[2025-02-07 09:52:51,547] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.8.attention.dense.bias
[2025-02-07 09:52:51,555] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.8.post_attention_layernorm.weight
[2025-02-07 09:52:51,555] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.8.post_attention_layernorm.bias
[2025-02-07 09:52:51,556] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.9.attention.query_key_value.weight
[2025-02-07 09:52:51,556] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.9.attention.query_key_value.bias
[2025-02-07 09:52:51,556] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.9.attention.dense.weight
[2025-02-07 09:52:51,556] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.9.attention.dense.bias
[2025-02-07 09:52:51,556] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.9.post_attention_layernorm.weight
[2025-02-07 09:52:51,556] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.9.post_attention_layernorm.bias
[2025-02-07 09:52:51,557] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.10.attention.query_key_value.weight
[2025-02-07 09:52:51,557] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.10.attention.query_key_value.bias
[2025-02-07 09:52:51,557] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.10.attention.dense.weight
[2025-02-07 09:52:51,557] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.10.attention.dense.bias
[2025-02-07 09:52:51,557] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.10.post_attention_layernorm.weight
[2025-02-07 09:52:51,558] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.10.post_attention_layernorm.bias
[2025-02-07 09:52:51,558] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.11.attention.query_key_value.weight
[2025-02-07 09:52:51,558] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.11.attention.query_key_value.bias
[2025-02-07 09:52:51,558] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.11.attention.dense.weight
[2025-02-07 09:52:51,559] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.11.attention.dense.bias
[2025-02-07 09:52:51,559] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.11.post_attention_layernorm.weight
[2025-02-07 09:52:51,559] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.11.post_attention_layernorm.bias
[2025-02-07 09:52:51,560] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.12.attention.query_key_value.weight
[2025-02-07 09:52:51,560] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.12.attention.query_key_value.bias
[2025-02-07 09:52:51,563] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.12.attention.dense.weight
[2025-02-07 09:52:51,563] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.12.attention.dense.bias
[2025-02-07 09:52:51,563] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.12.post_attention_layernorm.weight
[2025-02-07 09:52:51,563] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.12.post_attention_layernorm.bias
[2025-02-07 09:52:51,564] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.13.attention.query_key_value.weight
[2025-02-07 09:52:51,565] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.13.attention.query_key_value.bias
[2025-02-07 09:52:51,565] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.13.attention.dense.weight
[2025-02-07 09:52:51,565] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.13.attention.dense.bias
[2025-02-07 09:52:51,565] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.13.post_attention_layernorm.weight
[2025-02-07 09:52:51,565] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.13.post_attention_layernorm.bias
[2025-02-07 09:52:51,582] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.14.attention.query_key_value.weight
[2025-02-07 09:52:51,583] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.14.attention.query_key_value.bias
[2025-02-07 09:52:51,583] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.14.attention.dense.weight
[2025-02-07 09:52:51,587] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.14.attention.dense.bias
[2025-02-07 09:52:51,587] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.14.post_attention_layernorm.weight
[2025-02-07 09:52:51,587] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.14.post_attention_layernorm.bias
[2025-02-07 09:52:51,588] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.15.attention.query_key_value.weight
[2025-02-07 09:52:51,588] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.15.attention.query_key_value.bias
[2025-02-07 09:52:51,588] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.15.attention.dense.weight
[2025-02-07 09:52:51,588] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.15.attention.dense.bias
[2025-02-07 09:52:51,588] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.15.post_attention_layernorm.weight
[2025-02-07 09:52:51,588] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.15.post_attention_layernorm.bias
[2025-02-07 09:52:51,589] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.16.attention.query_key_value.weight
[2025-02-07 09:52:51,589] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.16.attention.query_key_value.bias
[2025-02-07 09:52:51,590] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.16.attention.dense.weight
[2025-02-07 09:52:51,590] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.16.attention.dense.bias
[2025-02-07 09:52:51,590] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.16.post_attention_layernorm.weight
[2025-02-07 09:52:51,590] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.16.post_attention_layernorm.bias
[2025-02-07 09:52:51,591] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.17.attention.query_key_value.weight
[2025-02-07 09:52:51,591] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.17.attention.query_key_value.bias
[2025-02-07 09:52:51,591] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.17.attention.dense.weight
[2025-02-07 09:52:51,591] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.17.attention.dense.bias
[2025-02-07 09:52:51,591] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.17.post_attention_layernorm.weight
[2025-02-07 09:52:51,591] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.17.post_attention_layernorm.bias
[2025-02-07 09:52:51,592] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.18.attention.query_key_value.weight
[2025-02-07 09:52:51,592] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.18.attention.query_key_value.bias
[2025-02-07 09:52:51,592] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.18.attention.dense.weight
[2025-02-07 09:52:51,592] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.18.attention.dense.bias
[2025-02-07 09:52:51,592] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.18.post_attention_layernorm.weight
[2025-02-07 09:52:51,593] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.18.post_attention_layernorm.bias
[2025-02-07 09:52:51,593] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.19.attention.query_key_value.weight
[2025-02-07 09:52:51,593] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.19.attention.query_key_value.bias
[2025-02-07 09:52:51,594] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.19.attention.dense.weight
[2025-02-07 09:52:51,594] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.19.attention.dense.bias
[2025-02-07 09:52:51,594] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.19.post_attention_layernorm.weight
[2025-02-07 09:52:51,594] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.19.post_attention_layernorm.bias
[2025-02-07 09:52:51,595] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.20.attention.query_key_value.weight
[2025-02-07 09:52:51,595] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.20.attention.query_key_value.bias
[2025-02-07 09:52:51,599] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.20.attention.dense.weight
[2025-02-07 09:52:51,599] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.20.attention.dense.bias
[2025-02-07 09:52:51,599] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.20.post_attention_layernorm.weight
[2025-02-07 09:52:51,600] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.20.post_attention_layernorm.bias
[2025-02-07 09:52:51,600] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.21.attention.query_key_value.weight
[2025-02-07 09:52:51,600] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.21.attention.query_key_value.bias
[2025-02-07 09:52:51,600] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.21.attention.dense.weight
[2025-02-07 09:52:51,601] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.21.attention.dense.bias
[2025-02-07 09:52:51,601] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.21.post_attention_layernorm.weight
[2025-02-07 09:52:51,601] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.21.post_attention_layernorm.bias
[2025-02-07 09:52:51,601] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.22.attention.query_key_value.weight
[2025-02-07 09:52:51,601] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.22.attention.query_key_value.bias
[2025-02-07 09:52:51,602] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.22.attention.dense.weight
[2025-02-07 09:52:51,602] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.22.attention.dense.bias
[2025-02-07 09:52:51,602] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.22.post_attention_layernorm.weight
[2025-02-07 09:52:51,602] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.22.post_attention_layernorm.bias
[2025-02-07 09:52:51,603] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.23.attention.query_key_value.weight
[2025-02-07 09:52:51,603] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.23.attention.query_key_value.bias
[2025-02-07 09:52:51,603] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.23.attention.dense.weight
[2025-02-07 09:52:51,603] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.23.attention.dense.bias
[2025-02-07 09:52:51,603] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.23.post_attention_layernorm.weight
[2025-02-07 09:52:51,603] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.23.post_attention_layernorm.bias
[2025-02-07 09:52:51,604] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.24.attention.query_key_value.weight
[2025-02-07 09:52:51,604] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.24.attention.query_key_value.bias
[2025-02-07 09:52:51,604] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.24.attention.dense.weight
[2025-02-07 09:52:51,622] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.24.attention.dense.bias
[2025-02-07 09:52:51,622] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.24.post_attention_layernorm.weight
[2025-02-07 09:52:51,622] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.24.post_attention_layernorm.bias
[2025-02-07 09:52:51,623] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.25.attention.query_key_value.weight
[2025-02-07 09:52:51,623] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.25.attention.query_key_value.bias
[2025-02-07 09:52:51,623] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.25.attention.dense.weight
[2025-02-07 09:52:51,623] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.25.attention.dense.bias
[2025-02-07 09:52:51,623] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.25.post_attention_layernorm.weight
[2025-02-07 09:52:51,623] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.25.post_attention_layernorm.bias
[2025-02-07 09:52:51,634] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.26.attention.query_key_value.weight
[2025-02-07 09:52:51,634] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.26.attention.query_key_value.bias
[2025-02-07 09:52:51,634] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.26.attention.dense.weight
[2025-02-07 09:52:51,635] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.26.attention.dense.bias
[2025-02-07 09:52:51,635] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.26.post_attention_layernorm.weight
[2025-02-07 09:52:51,635] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.26.post_attention_layernorm.bias
[2025-02-07 09:52:51,635] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.27.attention.query_key_value.weight
[2025-02-07 09:52:51,636] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.27.attention.query_key_value.bias
[2025-02-07 09:52:51,636] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.27.attention.dense.weight
[2025-02-07 09:52:51,636] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.27.attention.dense.bias
[2025-02-07 09:52:51,636] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.27.post_attention_layernorm.weight
[2025-02-07 09:52:51,636] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.27.post_attention_layernorm.bias
[2025-02-07 09:52:51,637] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.28.attention.query_key_value.weight
[2025-02-07 09:52:51,637] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.28.attention.query_key_value.bias
[2025-02-07 09:52:51,637] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.28.attention.dense.weight
[2025-02-07 09:52:51,637] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.28.attention.dense.bias
[2025-02-07 09:52:51,637] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.28.post_attention_layernorm.weight
[2025-02-07 09:52:51,637] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.28.post_attention_layernorm.bias
[2025-02-07 09:52:51,638] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.29.attention.query_key_value.weight
[2025-02-07 09:52:51,638] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.29.attention.query_key_value.bias
[2025-02-07 09:52:51,638] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.29.attention.dense.weight
[2025-02-07 09:52:51,638] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.29.attention.dense.bias
[2025-02-07 09:52:51,638] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.29.post_attention_layernorm.weight
[2025-02-07 09:52:51,638] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.29.post_attention_layernorm.bias
[2025-02-07 09:52:51,639] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.30.attention.query_key_value.weight
[2025-02-07 09:52:51,639] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.30.attention.query_key_value.bias
[2025-02-07 09:52:51,639] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.30.attention.dense.weight
[2025-02-07 09:52:51,639] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.30.attention.dense.bias
[2025-02-07 09:52:51,640] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.30.post_attention_layernorm.weight
[2025-02-07 09:52:51,640] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.30.post_attention_layernorm.bias
[2025-02-07 09:52:51,710] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.31.attention.query_key_value.weight
[2025-02-07 09:52:51,710] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.31.attention.query_key_value.bias
[2025-02-07 09:52:51,710] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.31.attention.dense.weight
[2025-02-07 09:52:51,710] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.31.attention.dense.bias
[2025-02-07 09:52:51,710] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.31.post_attention_layernorm.weight
[2025-02-07 09:52:51,731] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.31.post_attention_layernorm.bias
[2025-02-07 09:52:51,732] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.32.attention.query_key_value.weight
[2025-02-07 09:52:51,732] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.32.attention.query_key_value.bias
[2025-02-07 09:52:51,732] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.32.attention.dense.weight
[2025-02-07 09:52:51,732] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.32.attention.dense.bias
[2025-02-07 09:52:51,733] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.32.post_attention_layernorm.weight
[2025-02-07 09:52:51,733] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.32.post_attention_layernorm.bias
[2025-02-07 09:52:51,734] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.33.attention.query_key_value.weight
[2025-02-07 09:52:51,734] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.33.attention.query_key_value.bias
[2025-02-07 09:52:51,734] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.33.attention.dense.weight
[2025-02-07 09:52:51,734] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.33.attention.dense.bias
[2025-02-07 09:52:51,734] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.33.post_attention_layernorm.weight
[2025-02-07 09:52:51,735] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.33.post_attention_layernorm.bias
[2025-02-07 09:52:51,735] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.34.attention.query_key_value.weight
[2025-02-07 09:52:51,736] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.34.attention.query_key_value.bias
[2025-02-07 09:52:51,736] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.34.attention.dense.weight
[2025-02-07 09:52:51,736] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.34.attention.dense.bias
[2025-02-07 09:52:51,736] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.34.post_attention_layernorm.weight
[2025-02-07 09:52:51,736] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.34.post_attention_layernorm.bias
[2025-02-07 09:52:51,758] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.35.attention.query_key_value.weight
[2025-02-07 09:52:51,759] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.35.attention.query_key_value.bias
[2025-02-07 09:52:51,759] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.35.attention.dense.weight
[2025-02-07 09:52:51,760] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.35.attention.dense.bias
[2025-02-07 09:52:51,760] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.35.post_attention_layernorm.weight
[2025-02-07 09:52:51,760] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.35.post_attention_layernorm.bias
[2025-02-07 09:52:51,761] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.36.attention.query_key_value.weight
[2025-02-07 09:52:51,761] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.36.attention.query_key_value.bias
[2025-02-07 09:52:51,761] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.36.attention.dense.weight
[2025-02-07 09:52:51,761] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.36.attention.dense.bias
[2025-02-07 09:52:51,761] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.36.post_attention_layernorm.weight
[2025-02-07 09:52:51,762] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.36.post_attention_layernorm.bias
[2025-02-07 09:52:51,763] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.37.attention.query_key_value.weight
[2025-02-07 09:52:51,763] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.37.attention.query_key_value.bias
[2025-02-07 09:52:51,763] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.37.attention.dense.weight
[2025-02-07 09:52:51,771] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.37.attention.dense.bias
[2025-02-07 09:52:51,771] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.37.post_attention_layernorm.weight
[2025-02-07 09:52:51,771] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.37.post_attention_layernorm.bias
[2025-02-07 09:52:51,772] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.38.attention.query_key_value.weight
[2025-02-07 09:52:51,772] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.38.attention.query_key_value.bias
[2025-02-07 09:52:51,773] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.38.attention.dense.weight
[2025-02-07 09:52:51,773] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.38.attention.dense.bias
[2025-02-07 09:52:51,773] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.38.post_attention_layernorm.weight
[2025-02-07 09:52:51,773] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.38.post_attention_layernorm.bias
[2025-02-07 09:52:51,774] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.39.attention.query_key_value.weight
[2025-02-07 09:52:51,774] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.39.attention.query_key_value.bias
[2025-02-07 09:52:51,775] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.39.attention.dense.weight
[2025-02-07 09:52:51,775] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.39.attention.dense.bias
[2025-02-07 09:52:51,775] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.39.post_attention_layernorm.weight
[2025-02-07 09:52:51,775] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.39.post_attention_layernorm.bias
[2025-02-07 09:52:51,776] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.40.attention.query_key_value.weight
[2025-02-07 09:52:51,776] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.40.attention.query_key_value.bias
[2025-02-07 09:52:51,776] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.40.attention.dense.weight
[2025-02-07 09:52:51,776] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.40.attention.dense.bias
[2025-02-07 09:52:51,777] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.40.post_attention_layernorm.weight
[2025-02-07 09:52:51,777] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.40.post_attention_layernorm.bias
[2025-02-07 09:52:51,777] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.41.attention.query_key_value.weight
[2025-02-07 09:52:51,778] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.41.attention.query_key_value.bias
[2025-02-07 09:52:51,778] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.41.attention.dense.weight
[2025-02-07 09:52:51,778] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.41.attention.dense.bias
[2025-02-07 09:52:51,778] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.41.post_attention_layernorm.weight
[2025-02-07 09:52:51,778] [INFO] [RANK 0] ref_model.diffusion_model.transformer.layers.41.post_attention_layernorm.bias
[2025-02-07 09:52:51,779] [INFO] [RANK 0] ***** Total trainable parameters: 4232284160 *****
[2025-02-07 09:52:51,779] [INFO] [RANK 0] [<class 'sat.ops.layernorm.LayerNorm'>, <class 'torch.nn.modules.normalization.LayerNorm'>, <class 'sat.ops.layernorm.RMSNorm'>] is set to no_weight_decay
[2025-02-07 09:52:51,909] [INFO] [RANK 0] Syncing initialized parameters...
[2025-02-07 09:52:59,148] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2025-02-07 09:52:59,149] [WARNING] [config_utils.py:70:_process_deprecated_field] Config parameter cpu_offload is deprecated use offload_optimizer instead
[2025-02-07 09:52:59,174] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2025-02-07 09:52:59,175] [WARNING] [config_utils.py:70:_process_deprecated_field] Config parameter cpu_offload is deprecated use offload_optimizer instead
[2025-02-07 09:52:59,193] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2025-02-07 09:52:59,219] [WARNING] [config_utils.py:70:_process_deprecated_field] Config parameter cpu_offload is deprecated use offload_optimizer instead
[2025-02-07 09:52:59,272] [INFO] [RANK 0] Finished syncing initialized parameters.
[2025-02-07 09:52:59,297] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2025-02-07 09:52:59,298] [WARNING] [config_utils.py:70:_process_deprecated_field] Config parameter cpu_offload is deprecated use offload_optimizer instead
[2025-02-07 09:52:59,273] [INFO] [RANK 0] Using optimizer sat.ops.FusedEmaAdam from sat.
[2025-02-07 09:52:59,319] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed info: version=0.16.2, git-hash=unknown, git-branch=unknown
[2025-02-07 09:52:59,319] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2025-02-07 09:52:59,320] [WARNING] [config_utils.py:70:_process_deprecated_field] Config parameter cpu_offload is deprecated use offload_optimizer instead
[2025-02-07 09:52:59,320] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2025-02-07 09:52:59,321] [WARNING] [config_utils.py:70:_process_deprecated_field] Config parameter cpu_offload is deprecated use offload_optimizer instead
[2025-02-07 09:52:59,327] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2025-02-07 09:52:59,329] [WARNING] [config_utils.py:70:_process_deprecated_field] Config parameter cpu_offload is deprecated use offload_optimizer instead
[2025-02-07 09:52:59,330] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2025-02-07 09:52:59,346] [WARNING] [config_utils.py:70:_process_deprecated_field] Config parameter cpu_offload is deprecated use offload_optimizer instead
[2025-02-07 09:53:00,385] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
Using /root/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /root/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /root/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /root/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /root/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /root/.cache/torch_extensions/py310_cu121/fused_ema_adam/build.ninja...
/sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1965: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
Building extension module fused_ema_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Using /root/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /root/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Using /root/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
ninja: no work to do.
Loading extension module fused_ema_adam...
Loading extension module fused_ema_adam...
Time to load fused_ema_adam op: 0.28191375732421875 seconds
[2025-02-07 09:53:00,733] [INFO] [logging.py:128:log_dist] [Rank 0] Using client callable to create basic optimizer
[2025-02-07 09:53:00,733] [INFO] [logging.py:128:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
Time to load fused_ema_adam op: 0.12071895599365234 seconds
Loading extension module fused_ema_adam...
Time to load fused_ema_adam op: 0.11698055267333984 seconds
Loading extension module fused_ema_adam...
Time to load fused_ema_adam op: 0.3076002597808838 seconds
Loading extension module fused_ema_adam...
Time to load fused_ema_adam op: 0.3103370666503906 seconds
Loading extension module fused_ema_adam...
Time to load fused_ema_adam op: 0.30632591247558594 seconds
Loading extension module fused_ema_adam...
Time to load fused_ema_adam op: 0.3078310489654541 seconds
Loading extension module fused_ema_adam...
Time to load fused_ema_adam op: 0.34539127349853516 seconds
[2025-02-07 09:53:01,680] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedEmaAdam
[2025-02-07 09:53:01,681] [INFO] [utils.py:59:is_zero_supported_optimizer] Checking ZeRO support for optimizer=FusedEmaAdam type=<class 'sat.ops.fused_ema_adam.FusedEmaAdam'>
[2025-02-07 09:53:01,681] [WARNING] [engine.py:1244:_do_optimizer_sanity_check] **** You are using ZeRO with an untested optimizer, proceed with caution *****
[2025-02-07 09:53:01,681] [INFO] [logging.py:128:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer
[2025-02-07 09:53:01,681] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 1000000000
[2025-02-07 09:53:01,681] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 1000000000
[2025-02-07 09:53:01,681] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False
[2025-02-07 09:53:01,681] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False
[2025-02-07 09:53:34,022] [INFO] [utils.py:781:see_memory_usage] Before initializing optimizer states
[2025-02-07 09:53:34,024] [INFO] [utils.py:782:see_memory_usage] MA 34.18 GB         Max_MA 34.18 GB         CA 35.83 GB         Max_CA 36 GB 
[2025-02-07 09:53:34,026] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 896.25 GB, percent = 44.5%
[2025-02-07 09:53:37,877] [INFO] [utils.py:781:see_memory_usage] After initializing optimizer states
[2025-02-07 09:53:37,879] [INFO] [utils.py:782:see_memory_usage] MA 34.18 GB         Max_MA 36.15 GB         CA 37.81 GB         Max_CA 38 GB 
[2025-02-07 09:53:37,880] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 913.55 GB, percent = 45.3%
[2025-02-07 09:53:37,880] [INFO] [stage_1_and_2.py:544:__init__] optimizer state initialized
[2025-02-07 09:53:42,584] [INFO] [utils.py:781:see_memory_usage] After initializing ZeRO optimizer
[2025-02-07 09:53:42,585] [INFO] [utils.py:782:see_memory_usage] MA 34.18 GB         Max_MA 34.18 GB         CA 37.81 GB         Max_CA 38 GB 
[2025-02-07 09:53:42,586] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 953.67 GB, percent = 47.3%
[2025-02-07 09:53:42,594] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedZeroOptimizer
[2025-02-07 09:53:42,595] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed using configured LR scheduler = None
[2025-02-07 09:53:42,595] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2025-02-07 09:53:42,595] [INFO] [logging.py:128:log_dist] [Rank 0] step=0, skipped=0, lr=[1.0, 1.0], mom=[[0.9, 0.95], [0.9, 0.95]]
[2025-02-07 09:53:42,633] [INFO] [config.py:999:print] DeepSpeedEngine configuration:
[2025-02-07 09:53:42,635] [INFO] [config.py:1003:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2025-02-07 09:53:42,635] [INFO] [config.py:1003:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True, 'use_gds': False}
[2025-02-07 09:53:42,635] [INFO] [config.py:1003:print]   amp_enabled .................. False
[2025-02-07 09:53:42,635] [INFO] [config.py:1003:print]   amp_params ................... False
[2025-02-07 09:53:42,636] [INFO] [config.py:1003:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2025-02-07 09:53:42,648] [INFO] [config.py:1003:print]   bfloat16_enabled ............. True
[2025-02-07 09:53:42,649] [INFO] [config.py:1003:print]   bfloat16_immediate_grad_update  False
[2025-02-07 09:53:42,649] [INFO] [config.py:1003:print]   checkpoint_parallel_write_pipeline  False
[2025-02-07 09:53:42,649] [INFO] [config.py:1003:print]   checkpoint_tag_validation_enabled  True
[2025-02-07 09:53:42,649] [INFO] [config.py:1003:print]   checkpoint_tag_validation_fail  False
[2025-02-07 09:53:42,649] [INFO] [config.py:1003:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f1cabfc4ac0>
[2025-02-07 09:53:42,649] [INFO] [config.py:1003:print]   communication_data_type ...... None
[2025-02-07 09:53:42,649] [INFO] [config.py:1003:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2025-02-07 09:53:42,649] [INFO] [config.py:1003:print]   curriculum_enabled_legacy .... False
[2025-02-07 09:53:42,649] [INFO] [config.py:1003:print]   curriculum_params_legacy ..... False
[2025-02-07 09:53:42,649] [INFO] [config.py:1003:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2025-02-07 09:53:42,649] [INFO] [config.py:1003:print]   data_efficiency_enabled ...... False
[2025-02-07 09:53:42,649] [INFO] [config.py:1003:print]   dataloader_drop_last ......... False
[2025-02-07 09:53:42,649] [INFO] [config.py:1003:print]   disable_allgather ............ False
[2025-02-07 09:53:42,649] [INFO] [config.py:1003:print]   dump_state ................... False
[2025-02-07 09:53:42,649] [INFO] [config.py:1003:print]   dynamic_loss_scale_args ...... None
[2025-02-07 09:53:42,649] [INFO] [config.py:1003:print]   eigenvalue_enabled ........... False
[2025-02-07 09:53:42,649] [INFO] [config.py:1003:print]   eigenvalue_gas_boundary_resolution  1
[2025-02-07 09:53:42,649] [INFO] [config.py:1003:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2025-02-07 09:53:42,649] [INFO] [config.py:1003:print]   eigenvalue_layer_num ......... 0
[2025-02-07 09:53:42,650] [INFO] [config.py:1003:print]   eigenvalue_max_iter .......... 100
[2025-02-07 09:53:42,650] [INFO] [config.py:1003:print]   eigenvalue_stability ......... 1e-06
[2025-02-07 09:53:42,650] [INFO] [config.py:1003:print]   eigenvalue_tol ............... 0.01
[2025-02-07 09:53:42,650] [INFO] [config.py:1003:print]   eigenvalue_verbose ........... False
[2025-02-07 09:53:42,650] [INFO] [config.py:1003:print]   elasticity_enabled ........... False
[2025-02-07 09:53:42,650] [INFO] [config.py:1003:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2025-02-07 09:53:42,664] [INFO] [config.py:1003:print]   fp16_auto_cast ............... None
[2025-02-07 09:53:42,665] [INFO] [config.py:1003:print]   fp16_enabled ................. False
[2025-02-07 09:53:42,665] [INFO] [config.py:1003:print]   fp16_master_weights_and_gradients  False
[2025-02-07 09:53:42,665] [INFO] [config.py:1003:print]   global_rank .................. 0
[2025-02-07 09:53:42,665] [INFO] [config.py:1003:print]   grad_accum_dtype ............. None
[2025-02-07 09:53:42,665] [INFO] [config.py:1003:print]   gradient_accumulation_steps .. 1
[2025-02-07 09:53:42,665] [INFO] [config.py:1003:print]   gradient_clipping ............ 0.1
[2025-02-07 09:53:42,665] [INFO] [config.py:1003:print]   gradient_predivide_factor .... 1.0
[2025-02-07 09:53:42,665] [INFO] [config.py:1003:print]   graph_harvesting ............. False
[2025-02-07 09:53:42,665] [INFO] [config.py:1003:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2025-02-07 09:53:42,665] [INFO] [config.py:1003:print]   initial_dynamic_scale ........ 1
[2025-02-07 09:53:42,665] [INFO] [config.py:1003:print]   load_universal_checkpoint .... False
[2025-02-07 09:53:42,665] [INFO] [config.py:1003:print]   loss_scale ................... 1.0
[2025-02-07 09:53:42,665] [INFO] [config.py:1003:print]   memory_breakdown ............. False
[2025-02-07 09:53:42,665] [INFO] [config.py:1003:print]   mics_hierarchial_params_gather  False
[2025-02-07 09:53:42,665] [INFO] [config.py:1003:print]   mics_shard_size .............. -1
[2025-02-07 09:53:42,666] [INFO] [config.py:1003:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') comet=CometConfig(enabled=False, samples_log_interval=100, project=None, workspace=None, api_key=None, experiment_name=None, experiment_key=None, online=None, mode=None) wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName')
[2025-02-07 09:53:42,666] [INFO] [config.py:1003:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2025-02-07 09:53:42,666] [INFO] [config.py:1003:print]   optimizer_legacy_fusion ...... False
[2025-02-07 09:53:42,666] [INFO] [config.py:1003:print]   optimizer_name ............... None
[2025-02-07 09:53:42,666] [INFO] [config.py:1003:print]   optimizer_params ............. None
[2025-02-07 09:53:42,666] [INFO] [config.py:1003:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2025-02-07 09:53:42,666] [INFO] [config.py:1003:print]   pld_enabled .................. False
[2025-02-07 09:53:42,666] [INFO] [config.py:1003:print]   pld_params ................... False
[2025-02-07 09:53:42,666] [INFO] [config.py:1003:print]   prescale_gradients ........... False
[2025-02-07 09:53:42,666] [INFO] [config.py:1003:print]   scheduler_name ............... None
[2025-02-07 09:53:42,666] [INFO] [config.py:1003:print]   scheduler_params ............. None
[2025-02-07 09:53:42,666] [INFO] [config.py:1003:print]   seq_parallel_communication_data_type  torch.float32
[2025-02-07 09:53:42,666] [INFO] [config.py:1003:print]   sparse_attention ............. None
[2025-02-07 09:53:42,666] [INFO] [config.py:1003:print]   sparse_gradients_enabled ..... False
[2025-02-07 09:53:42,666] [INFO] [config.py:1003:print]   steps_per_print .............. 50
[2025-02-07 09:53:42,666] [INFO] [config.py:1003:print]   timers_config ................ enabled=True synchronized=True
[2025-02-07 09:53:42,679] [INFO] [config.py:1003:print]   train_batch_size ............. 8
[2025-02-07 09:53:42,680] [INFO] [config.py:1003:print]   train_micro_batch_size_per_gpu  1
[2025-02-07 09:53:42,680] [INFO] [config.py:1003:print]   use_data_before_expert_parallel_  False
[2025-02-07 09:53:42,680] [INFO] [config.py:1003:print]   use_node_local_storage ....... False
[2025-02-07 09:53:42,680] [INFO] [config.py:1003:print]   wall_clock_breakdown ......... False
[2025-02-07 09:53:42,680] [INFO] [config.py:1003:print]   weight_quantization_config ... None
[2025-02-07 09:53:42,680] [INFO] [config.py:1003:print]   world_size ................... 8
[2025-02-07 09:53:42,680] [INFO] [config.py:1003:print]   zero_allow_untested_optimizer  True
[2025-02-07 09:53:42,680] [INFO] [config.py:1003:print]   zero_config .................. stage=2 contiguous_gradients=False reduce_scatter=True reduce_bucket_size=1000000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=1000000000 overlap_comm=True load_from_fp32_weights=False elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None prefetch_bucket_size=50000000 param_persistence_threshold=100000 model_persistence_threshold=9223372036854775807 max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=False module_granularity_threshold=0 use_all_reduce_for_fetch_params=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False zeropp_loco_param=None mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2025-02-07 09:53:42,680] [INFO] [config.py:1003:print]   zero_enabled ................. True
[2025-02-07 09:53:42,680] [INFO] [config.py:1003:print]   zero_force_ds_cpu_optimizer .. True
[2025-02-07 09:53:42,680] [INFO] [config.py:1003:print]   zero_optimization_stage ...... 2
[2025-02-07 09:53:42,680] [INFO] [config.py:989:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "steps_per_print": 50, 
    "gradient_clipping": 0.1, 
    "zero_optimization": {
        "stage": 2, 
        "cpu_offload": false, 
        "contiguous_gradients": false, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 1.000000e+09, 
        "allgather_bucket_size": 1.000000e+09, 
        "load_from_fp32_weights": false
    }, 
    "zero_allow_untested_optimizer": true, 
    "bf16": {
        "enabled": true
    }, 
    "fp16": {
        "enabled": false
    }, 
    "loss_scale": 0, 
    "loss_scale_window": 400, 
    "hysteresis": 2, 
    "min_loss_scale": 1, 
    "activation_checkpointing": {
        "partition_activations": false, 
        "contiguous_memory_optimization": false
    }, 
    "wall_clock_breakdown": false
}
[2025-02-07 09:53:42,681] [INFO] [RANK 0] learning rate decaying style linear, ratio 10.0
[2025-02-07 09:53:42,681] [INFO] [RANK 0] Finetuning Model...
[2025-02-07 09:53:42,681] [INFO] [RANK 0] arguments:
[2025-02-07 09:53:42,681] [INFO] [RANK 0]   base ......................... ['configs/cogvideox_5b_i2v_s1.yaml', 'configs/sft_s1.yaml']
[2025-02-07 09:53:42,681] [INFO] [RANK 0]   model_parallel_size .......... 1
[2025-02-07 09:53:42,681] [INFO] [RANK 0]   force_pretrain ............... False
[2025-02-07 09:53:42,681] [INFO] [RANK 0]   device ....................... 0
[2025-02-07 09:53:42,681] [INFO] [RANK 0]   debug ........................ False
[2025-02-07 09:53:42,681] [INFO] [RANK 0]   log_image .................... True
[2025-02-07 09:53:42,681] [INFO] [RANK 0]   output_dir ................... samples
[2025-02-07 09:53:42,681] [INFO] [RANK 0]   input_dir .................... None
[2025-02-07 09:53:42,681] [INFO] [RANK 0]   input_type ................... cli
[2025-02-07 09:53:42,694] [INFO] [RANK 0]   input_file ................... input.txt
[2025-02-07 09:53:42,695] [INFO] [RANK 0]   final_size ................... 2048
[2025-02-07 09:53:42,695] [INFO] [RANK 0]   sdedit ....................... False
[2025-02-07 09:53:42,695] [INFO] [RANK 0]   grid_num_rows ................ 1
[2025-02-07 09:53:42,695] [INFO] [RANK 0]   force_inference .............. False
[2025-02-07 09:53:42,695] [INFO] [RANK 0]   lcm_steps .................... None
[2025-02-07 09:53:42,695] [INFO] [RANK 0]   sampling_num_frames .......... 32
[2025-02-07 09:53:42,695] [INFO] [RANK 0]   sampling_fps ................. 8
[2025-02-07 09:53:42,695] [INFO] [RANK 0]   only_save_latents ............ False
[2025-02-07 09:53:42,695] [INFO] [RANK 0]   only_log_video_latents ....... True
[2025-02-07 09:53:42,695] [INFO] [RANK 0]   latent_channels .............. 32
[2025-02-07 09:53:42,695] [INFO] [RANK 0]   image2video .................. False
[2025-02-07 09:53:42,695] [INFO] [RANK 0]   experiment_name .............. train-stage-1-02-07-09-42
[2025-02-07 09:53:42,695] [INFO] [RANK 0]   train_iters .................. 30000
[2025-02-07 09:53:42,695] [INFO] [RANK 0]   batch_size ................... 1
[2025-02-07 09:53:42,695] [INFO] [RANK 0]   lr ........................... 1e-05
[2025-02-07 09:53:42,695] [INFO] [RANK 0]   mode ......................... finetune
[2025-02-07 09:53:42,695] [INFO] [RANK 0]   seed ......................... 16920
[2025-02-07 09:53:42,696] [INFO] [RANK 0]   zero_stage ................... 0
[2025-02-07 09:53:42,696] [INFO] [RANK 0]   checkpoint_activations ....... True
[2025-02-07 09:53:42,696] [INFO] [RANK 0]   checkpoint_num_layers ........ 1
[2025-02-07 09:53:42,696] [INFO] [RANK 0]   checkpoint_skip_layers ....... 0
[2025-02-07 09:53:42,696] [INFO] [RANK 0]   fp16 ......................... False
[2025-02-07 09:53:42,696] [INFO] [RANK 0]   bf16 ......................... True
[2025-02-07 09:53:42,696] [INFO] [RANK 0]   gradient_accumulation_steps .. 1
[2025-02-07 09:53:42,696] [INFO] [RANK 0]   profiling .................... -1
[2025-02-07 09:53:42,696] [INFO] [RANK 0]   epochs ....................... None
[2025-02-07 09:53:42,696] [INFO] [RANK 0]   log_interval ................. 1
[2025-02-07 09:53:42,696] [INFO] [RANK 0]   summary_dir .................. 
[2025-02-07 09:53:42,696] [INFO] [RANK 0]   save_args .................... False
[2025-02-07 09:53:42,696] [INFO] [RANK 0]   lr_decay_iters ............... None
[2025-02-07 09:53:42,696] [INFO] [RANK 0]   lr_decay_style ............... linear
[2025-02-07 09:53:42,696] [INFO] [RANK 0]   lr_decay_ratio ............... 0.1
[2025-02-07 09:53:42,696] [INFO] [RANK 0]   warmup ....................... 0.01
[2025-02-07 09:53:42,696] [INFO] [RANK 0]   weight_decay ................. 0.0001
[2025-02-07 09:53:42,696] [INFO] [RANK 0]   save ......................... ./stage-1/train-stage-1-02-07-09-42
[2025-02-07 09:53:42,696] [INFO] [RANK 0]   load ......................... ./pretrained_models/cogvideox-5b-i2v-sat/transformer
[2025-02-07 09:53:42,696] [INFO] [RANK 0]   force_train .................. True
[2025-02-07 09:53:42,697] [INFO] [RANK 0]   save_interval ................ 500
[2025-02-07 09:53:42,697] [INFO] [RANK 0]   no_save_rng .................. False
[2025-02-07 09:53:42,697] [INFO] [RANK 0]   no_load_rng .................. True
[2025-02-07 09:53:42,697] [INFO] [RANK 0]   resume_dataloader ............ False
[2025-02-07 09:53:42,697] [INFO] [RANK 0]   distributed_backend .......... nccl
[2025-02-07 09:53:42,697] [INFO] [RANK 0]   local_rank ................... 0
[2025-02-07 09:53:42,697] [INFO] [RANK 0]   exit_interval ................ None
[2025-02-07 09:53:42,697] [INFO] [RANK 0]   wandb ........................ False
[2025-02-07 09:53:42,697] [INFO] [RANK 0]   wandb_project_name ........... default_project
[2025-02-07 09:53:42,697] [INFO] [RANK 0]   eval_batch_size .............. 1
[2025-02-07 09:53:42,697] [INFO] [RANK 0]   eval_iters ................... 1
[2025-02-07 09:53:42,697] [INFO] [RANK 0]   eval_interval ................ 30000
[2025-02-07 09:53:42,704] [INFO] [RANK 0]   strict_eval .................. False
[2025-02-07 09:53:42,705] [INFO] [RANK 0]   train_data ................... ['./data/hallo3.json']
[2025-02-07 09:53:42,705] [INFO] [RANK 0]   train_data_weights ........... None
[2025-02-07 09:53:42,705] [INFO] [RANK 0]   iterable_dataset ............. False
[2025-02-07 09:53:42,705] [INFO] [RANK 0]   iterable_dataset_eval ........ 
[2025-02-07 09:53:42,705] [INFO] [RANK 0]   batch_from_same_dataset ...... False
[2025-02-07 09:53:42,705] [INFO] [RANK 0]   valid_data ................... ['./data/hallo3.json']
[2025-02-07 09:53:42,705] [INFO] [RANK 0]   test_data .................... None
[2025-02-07 09:53:42,705] [INFO] [RANK 0]   split ........................ 1,0,0
[2025-02-07 09:53:42,705] [INFO] [RANK 0]   num_workers .................. 8
[2025-02-07 09:53:42,705] [INFO] [RANK 0]   block_size ................... 10000
[2025-02-07 09:53:42,705] [INFO] [RANK 0]   prefetch_factor .............. 4
[2025-02-07 09:53:42,705] [INFO] [RANK 0]   sample_rate .................. 16000
[2025-02-07 09:53:42,705] [INFO] [RANK 0]   wav2vec_model_path ........... None
[2025-02-07 09:53:42,705] [INFO] [RANK 0]   wav2vec_features ............. all
[2025-02-07 09:53:42,705] [INFO] [RANK 0]   audio_separator_model_path ... None
[2025-02-07 09:53:42,705] [INFO] [RANK 0]   face_analysis_model_path ..... None
[2025-02-07 09:53:42,706] [INFO] [RANK 0]   deepspeed .................... True
[2025-02-07 09:53:42,706] [INFO] [RANK 0]   deepspeed_config ............. {'train_micro_batch_size_per_gpu': 1, 'gradient_accumulation_steps': 1, 'steps_per_print': 50, 'gradient_clipping': 0.1, 'zero_optimization': {'stage': 2, 'cpu_offload': False, 'contiguous_gradients': False, 'overlap_comm': True, 'reduce_scatter': True, 'reduce_bucket_size': 1000000000, 'allgather_bucket_size': 1000000000, 'load_from_fp32_weights': False}, 'zero_allow_untested_optimizer': True, 'bf16': {'enabled': True}, 'fp16': {'enabled': False}, 'loss_scale': 0, 'loss_scale_window': 400, 'hysteresis': 2, 'min_loss_scale': 1, 'activation_checkpointing': {'partition_activations': False, 'contiguous_memory_optimization': False}, 'wall_clock_breakdown': False}
[2025-02-07 09:53:42,706] [INFO] [RANK 0]   deepscale .................... False
[2025-02-07 09:53:42,706] [INFO] [RANK 0]   deepscale_config ............. None
[2025-02-07 09:53:42,707] [INFO] [RANK 0]   model_config ................. {'scale_factor': 0.7, 'disable_first_stage_autocast': True, 'latent_input': False, 'noised_image_input': True, 'noised_image_all_concat': False, 'noised_image_dropout': 0.05, 'not_trainable_prefixes': ['audio'], 'train_prefix': {'ref_model': ['attention'], 'model': ['face', 'attention']}, 'log_keys': ['txt'], 'ref_net_path': './pretrained_models/cogvideox-5b-i2v-sat/transformer/', 'denoiser_config': {'target': 'sgm.modules.diffusionmodules.denoiser.DiscreteDenoiser', 'params': {'num_idx': 1000, 'quantize_c_noise': False, 'weighting_config': {'target': 'sgm.modules.diffusionmodules.denoiser_weighting.EpsWeighting'}, 'scaling_config': {'target': 'sgm.modules.diffusionmodules.denoiser_scaling.VideoScaling'}, 'discretization_config': {'target': 'sgm.modules.diffusionmodules.discretizer.ZeroSNRDDPMDiscretization', 'params': {'shift_scale': 1.0}}}}, 'network_config': {'target': 'dit_video_concat.DiffusionTransformer', 'params': {'time_embed_dim': 512, 'elementwise_affine': True, 'num_frames': 49, 'time_compressed_rate': 4, 'latent_width': 90, 'latent_height': 60, 'num_layers': 42, 'patch_size': 2, 'in_channels': 32, 'out_channels': 16, 'hidden_size': 3072, 'adm_in_channels': 256, 'num_attention_heads': 48, 'add_audio_module': False, 'transformer_args': {'checkpoint_activations': True, 'vocab_size': 1, 'max_sequence_length': 64, 'layernorm_order': 'pre', 'skip_init': False, 'model_parallel_size': 1, 'is_decoder': False, 'cross_attn_hidden_size': 768, 'face_cross_attn_hidden_size': 1024, 'num_layers': 42, 'hidden_size': 3072, 'num_attention_heads': 48, 'parallel_output': True, 'add_audio_module': False}, 'modules': {'pos_embed_config': {'target': 'dit_video_concat.Rotary3DPositionEmbeddingMixin', 'params': {'learnable_pos_embed': True, 'hidden_size_head': 64, 'text_length': 226}}, 'patch_embed_config': {'target': 'dit_video_concat.ImagePatchEmbeddingMixin', 'params': {'text_hidden_size': 4096}}, 'adaln_layer_config': {'target': 'dit_video_concat.AdaLNMixin', 'params': {'qk_ln': True}}, 'final_layer_config': {'target': 'dit_video_concat.FinalLayerMixin'}}, 'dtype': 'bf16'}}, 'ref_network_config': {'target': 'ref_dit_video_concat.DiffusionTransformer', 'params': {'time_embed_dim': 512, 'elementwise_affine': True, 'num_frames': 49, 'time_compressed_rate': 4, 'latent_width': 90, 'latent_height': 60, 'num_layers': 42, 'patch_size': 2, 'in_channels': 32, 'out_channels': 16, 'hidden_size': 3072, 'adm_in_channels': 256, 'num_attention_heads': 48, 'transformer_args': {'checkpoint_activations': False, 'vocab_size': 1, 'max_sequence_length': 64, 'layernorm_order': 'pre', 'skip_init': False, 'model_parallel_size': 1, 'is_decoder': False, 'num_layers': 42, 'hidden_size': 3072, 'num_attention_heads': 48, 'parallel_output': True}, 'modules': {'pos_embed_config': {'target': 'ref_dit_video_concat.Rotary3DPositionEmbeddingMixin', 'params': {'learnable_pos_embed': True, 'hidden_size_head': 64, 'text_length': 226}}, 'patch_embed_config': {'target': 'ref_dit_video_concat.ImagePatchEmbeddingMixin', 'params': {'text_hidden_size': 4096}}, 'adaln_layer_config': {'target': 'ref_dit_video_concat.AdaLNMixin', 'params': {'qk_ln': True}}, 'final_layer_config': {'target': 'ref_dit_video_concat.FinalLayerMixin'}}, 'dtype': 'bf16'}}, 'conditioner_config': {'target': 'sgm.modules.GeneralConditioner', 'params': {'emb_models': [{'is_trainable': False, 'input_key': 'txt', 'ucg_rate': 0.1, 'target': 'sgm.modules.encoders.modules.FrozenT5Embedder', 'params': {'model_dir': './pretrained_models/t5-v1_1-xxl', 'max_length': 226}}]}}, 'first_stage_config': {'target': 'vae_modules.autoencoder.VideoAutoencoderInferenceWrapper', 'params': {'cp_size': 1, 'ckpt_path': './pretrained_models/cogvideox-5b-i2v-sat/vae/3d-vae.pt', 'ignore_keys': ['loss'], 'loss_config': {'target': 'torch.nn.Identity'}, 'regularizer_config': {'target': 'vae_modules.regularizers.DiagonalGaussianRegularizer'}, 'encoder_config': {'target': 'vae_modules.cp_enc_dec.ContextParallelEncoder3D', 'params': {'double_z': True, 'z_channels': 16, 'resolution': 256, 'in_channels': 3, 'out_ch': 3, 'ch': 128, 'ch_mult': [1, 2, 2, 4], 'attn_resolutions': [], 'num_res_blocks': 3, 'dropout': 0.0, 'gather_norm': True}}, 'decoder_config': {'target': 'vae_modules.cp_enc_dec.ContextParallelDecoder3D', 'params': {'double_z': True, 'z_channels': 16, 'resolution': 256, 'in_channels': 3, 'out_ch': 3, 'ch': 128, 'ch_mult': [1, 2, 2, 4], 'attn_resolutions': [], 'num_res_blocks': 3, 'dropout': 0.0, 'gather_norm': True}}}}, 'loss_fn_config': {'target': 'sgm.modules.diffusionmodules.loss.VideoDiffusionLoss', 'params': {'batch2model_keys': ['audio_emb', 'face_emb'], 'fixed_frames': 0, 'offset_noise_level': 0, 'sigma_sampler_config': {'target': 'sgm.modules.diffusionmodules.sigma_sampling.DiscreteSampling', 'params': {'uniform_sampling': True, 'num_idx': 1000, 'discretization_config': {'target': 'sgm.modules.diffusionmodules.discretizer.ZeroSNRDDPMDiscretization', 'params': {'shift_scale': 1.0}}}}}}, 'sampler_config': {'target': 'sgm.modules.diffusionmodules.sampling.VPSDEDPMPP2MSampler', 'params': {'fixed_frames': 0, 'num_steps': 50, 'verbose': True, 'discretization_config': {'target': 'sgm.modules.diffusionmodules.discretizer.ZeroSNRDDPMDiscretization', 'params': {'shift_scale': 1.0}}, 'guider_config': {'target': 'sgm.modules.diffusionmodules.guiders.DynamicCFG', 'params': {'scale': 6, 'exp': 5, 'num_steps': 50}}}}}
[2025-02-07 09:53:42,723] [INFO] [RANK 0]   data_config .................. {'target': 'data_video.SFTDataset', 'params': {'video_size': [480, 720], 'fps': 8, 'max_num_frames': 49, 'skip_frms_num': 3.0}}
[2025-02-07 09:53:42,724] [INFO] [RANK 0]   cuda ......................... True
[2025-02-07 09:53:42,724] [INFO] [RANK 0]   rank ......................... 0
[2025-02-07 09:53:42,733] [INFO] [RANK 0]   world_size ................... 8
[2025-02-07 09:53:42,734] [INFO] [RANK 0]   deepspeed_activation_checkpointing  True
[2025-02-07 09:53:42,734] [INFO] [RANK 0]   master_ip .................... 297hi17a9s0l1-0
[2025-02-07 09:53:42,734] [INFO] [RANK 0]   master_port .................. 59080
[2025-02-07 09:53:42,734] [INFO] [RANK 0]   log_config ................... [{'model': {'scale_factor': 0.7, 'disable_first_stage_autocast': True, 'latent_input': False, 'noised_image_input': True, 'noised_image_all_concat': False, 'noised_image_dropout': 0.05, 'not_trainable_prefixes': ['audio'], 'train_prefix': {'ref_model': ['attention'], 'model': ['face', 'attention']}, 'log_keys': ['txt'], 'ref_net_path': './pretrained_models/cogvideox-5b-i2v-sat/transformer/', 'denoiser_config': {'target': 'sgm.modules.diffusionmodules.denoiser.DiscreteDenoiser', 'params': {'num_idx': 1000, 'quantize_c_noise': False, 'weighting_config': {'target': 'sgm.modules.diffusionmodules.denoiser_weighting.EpsWeighting'}, 'scaling_config': {'target': 'sgm.modules.diffusionmodules.denoiser_scaling.VideoScaling'}, 'discretization_config': {'target': 'sgm.modules.diffusionmodules.discretizer.ZeroSNRDDPMDiscretization', 'params': {'shift_scale': 1.0}}}}, 'network_config': {'target': 'dit_video_concat.DiffusionTransformer', 'params': {'time_embed_dim': 512, 'elementwise_affine': True, 'num_frames': 49, 'time_compressed_rate': 4, 'latent_width': 90, 'latent_height': 60, 'num_layers': 42, 'patch_size': 2, 'in_channels': 32, 'out_channels': 16, 'hidden_size': 3072, 'adm_in_channels': 256, 'num_attention_heads': 48, 'add_audio_module': False, 'transformer_args': {'checkpoint_activations': True, 'vocab_size': 1, 'max_sequence_length': 64, 'layernorm_order': 'pre', 'skip_init': False, 'model_parallel_size': 1, 'is_decoder': False, 'cross_attn_hidden_size': 768, 'face_cross_attn_hidden_size': 1024}, 'modules': {'pos_embed_config': {'target': 'dit_video_concat.Rotary3DPositionEmbeddingMixin', 'params': {'learnable_pos_embed': True, 'hidden_size_head': 64, 'text_length': 226}}, 'patch_embed_config': {'target': 'dit_video_concat.ImagePatchEmbeddingMixin', 'params': {'text_hidden_size': 4096}}, 'adaln_layer_config': {'target': 'dit_video_concat.AdaLNMixin', 'params': {'qk_ln': True}}, 'final_layer_config': {'target': 'dit_video_concat.FinalLayerMixin'}}}}, 'ref_network_config': {'target': 'ref_dit_video_concat.DiffusionTransformer', 'params': {'time_embed_dim': 512, 'elementwise_affine': True, 'num_frames': 49, 'time_compressed_rate': 4, 'latent_width': 90, 'latent_height': 60, 'num_layers': 42, 'patch_size': 2, 'in_channels': 32, 'out_channels': 16, 'hidden_size': 3072, 'adm_in_channels': 256, 'num_attention_heads': 48, 'transformer_args': {'checkpoint_activations': False, 'vocab_size': 1, 'max_sequence_length': 64, 'layernorm_order': 'pre', 'skip_init': False, 'model_parallel_size': 1, 'is_decoder': False}, 'modules': {'pos_embed_config': {'target': 'ref_dit_video_concat.Rotary3DPositionEmbeddingMixin', 'params': {'learnable_pos_embed': True, 'hidden_size_head': 64, 'text_length': 226}}, 'patch_embed_config': {'target': 'ref_dit_video_concat.ImagePatchEmbeddingMixin', 'params': {'text_hidden_size': 4096}}, 'adaln_layer_config': {'target': 'ref_dit_video_concat.AdaLNMixin', 'params': {'qk_ln': True}}, 'final_layer_config': {'target': 'ref_dit_video_concat.FinalLayerMixin'}}}}, 'conditioner_config': {'target': 'sgm.modules.GeneralConditioner', 'params': {'emb_models': [{'is_trainable': False, 'input_key': 'txt', 'ucg_rate': 0.1, 'target': 'sgm.modules.encoders.modules.FrozenT5Embedder', 'params': {'model_dir': './pretrained_models/t5-v1_1-xxl', 'max_length': 226}}]}}, 'first_stage_config': {'target': 'vae_modules.autoencoder.VideoAutoencoderInferenceWrapper', 'params': {'cp_size': 1, 'ckpt_path': './pretrained_models/cogvideox-5b-i2v-sat/vae/3d-vae.pt', 'ignore_keys': ['loss'], 'loss_config': {'target': 'torch.nn.Identity'}, 'regularizer_config': {'target': 'vae_modules.regularizers.DiagonalGaussianRegularizer'}, 'encoder_config': {'target': 'vae_modules.cp_enc_dec.ContextParallelEncoder3D', 'params': {'double_z': True, 'z_channels': 16, 'resolution': 256, 'in_channels': 3, 'out_ch': 3, 'ch': 128, 'ch_mult': [1, 2, 2, 4], 'attn_resolutions': [], 'num_res_blocks': 3, 'dropout': 0.0, 'gather_norm': True}}, 'decoder_config': {'target': 'vae_modules.cp_enc_dec.ContextParallelDecoder3D', 'params': {'double_z': True, 'z_channels': 16, 'resolution': 256, 'in_channels': 3, 'out_ch': 3, 'ch': 128, 'ch_mult': [1, 2, 2, 4], 'attn_resolutions': [], 'num_res_blocks': 3, 'dropout': 0.0, 'gather_norm': True}}}}, 'loss_fn_config': {'target': 'sgm.modules.diffusionmodules.loss.VideoDiffusionLoss', 'params': {'batch2model_keys': ['audio_emb', 'face_emb'], 'fixed_frames': 0, 'offset_noise_level': 0, 'sigma_sampler_config': {'target': 'sgm.modules.diffusionmodules.sigma_sampling.DiscreteSampling', 'params': {'uniform_sampling': True, 'num_idx': 1000, 'discretization_config': {'target': 'sgm.modules.diffusionmodules.discretizer.ZeroSNRDDPMDiscretization', 'params': {'shift_scale': 1.0}}}}}}, 'sampler_config': {'target': 'sgm.modules.diffusionmodules.sampling.VPSDEDPMPP2MSampler', 'params': {'fixed_frames': 0, 'num_steps': 50, 'verbose': True, 'discretization_config': {'target': 'sgm.modules.diffusionmodules.discretizer.ZeroSNRDDPMDiscretization', 'params': {'shift_scale': 1.0}}, 'guider_config': {'target': 'sgm.modules.diffusionmodules.guiders.DynamicCFG', 'params': {'scale': 6, 'exp': 5, 'num_steps': 50}}}}}}, {'args': {'checkpoint_activations': True, 'model_parallel_size': 1, 'experiment_name': 'train-stage-1', 'mode': 'finetune', 'load': './pretrained_models/cogvideox-5b-i2v-sat/transformer', 'no_load_rng': True, 'train_iters': 30000, 'eval_iters': 1, 'eval_interval': 30000, 'eval_batch_size': 1, 'save': './stage-1', 'save_interval': 500, 'log_interval': 1, 'train_data': ['./data/hallo3.json'], 'valid_data': ['./data/hallo3.json'], 'split': '1,0,0', 'num_workers': 8, 'force_train': True, 'only_log_video_latents': True}, 'data': {'target': 'data_video.SFTDataset', 'params': {'video_size': [480, 720], 'fps': 8, 'max_num_frames': 49, 'skip_frms_num': 3.0}}, 'deepspeed': {'train_micro_batch_size_per_gpu': 1, 'gradient_accumulation_steps': 1, 'steps_per_print': 50, 'gradient_clipping': 0.1, 'zero_optimization': {'stage': 2, 'cpu_offload': False, 'contiguous_gradients': False, 'overlap_comm': True, 'reduce_scatter': True, 'reduce_bucket_size': 1000000000, 'allgather_bucket_size': 1000000000, 'load_from_fp32_weights': False}, 'zero_allow_untested_optimizer': True, 'bf16': {'enabled': True}, 'fp16': {'enabled': False}, 'loss_scale': 0, 'loss_scale_window': 400, 'hysteresis': 2, 'min_loss_scale': 1, 'optimizer': {'type': 'sat.ops.FusedEmaAdam', 'params': {'lr': '1e-5', 'betas': [0.9, 0.95], 'eps': '1e-8', 'weight_decay': '1e-4'}}, 'activation_checkpointing': {'partition_activations': False, 'contiguous_memory_optimization': False}, 'wall_clock_breakdown': False}}]
[2025-02-07 09:53:42,744] [INFO] [RANK 0]   do_train ..................... True
[2025-02-07 09:53:42,745] [INFO] [RANK 0]   val_last_shape ............... []
[2025-02-07 09:53:42,745] [INFO] [RANK 0]   val_drop_number .............. 0
[2025-02-07 09:53:42,745] [INFO] [RANK 0]   do_valid ..................... True
[2025-02-07 09:53:42,745] [INFO] [RANK 0]   do_test ...................... False
[2025-02-07 09:53:42,745] [INFO] [RANK 0]   iteration .................... 0
[2025-02-07 09:55:33,536] [INFO] [RANK 0]  iteration        1/   30000 | elapsed time per iteration (ms): 99196.0 | learning rate 6.667E-08 | total loss 1.756253E-01 | loss 1.756253E-01 |speed 0.60 samples/(min*GPU)
[2025-02-07 09:55:33,540] [INFO] [RANK 0] after 1 iterations memory (MB) | allocated: 41516.5224609375 | max allocated: 59760.69775390625 | cached: 56038.0 | max cached: 66454.0
[2025-02-07 09:55:33,540] [INFO] [RANK 0] time (ms) | forward: 86960.53 | backward: 11684.34 | allreduce: 0.00 | optimizer: 536.10 | data loader: 8185.34
[2025-02-07 09:56:16,721] [INFO] [RANK 0]  iteration        2/   30000 | elapsed time per iteration (ms): 43181.9 | learning rate 1.000E-07 | total loss 1.330637E-01 | loss 1.330637E-01 |speed 1.39 samples/(min*GPU)
[2025-02-07 09:56:16,754] [INFO] [RANK 0] time (ms) | forward: 30671.39 | backward: 12283.42 | allreduce: 0.00 | optimizer: 181.71 | data loader: 10.94
[2025-02-07 09:56:52,610] [INFO] [RANK 0]  iteration        3/   30000 | elapsed time per iteration (ms): 35891.7 | learning rate 1.333E-07 | total loss 1.102021E-01 | loss 1.102021E-01 |speed 1.67 samples/(min*GPU)
[2025-02-07 09:56:52,615] [INFO] [RANK 0] time (ms) | forward: 23259.90 | backward: 12395.37 | allreduce: 0.00 | optimizer: 167.15 | data loader: 5.56
[rank0]: Traceback (most recent call last):
[rank0]:   File "/wangbenyou/huanghj/workspace/hallo3/hallo3/train_video.py", line 227, in <module>
[rank0]:     training_main(
[rank0]:   File "/sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/sat/training/deepspeed_training.py", line 157, in training_main
[rank0]:     iteration, skipped = train(model, optimizer,
[rank0]:   File "/sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/sat/training/deepspeed_training.py", line 359, in train
[rank0]:     lm_loss, skipped_iter, metrics = train_step(train_data_iterator,
[rank0]:   File "/sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/sat/training/deepspeed_training.py", line 443, in train_step
[rank0]:     forward_ret = forward_step(data_iterator, model, args, timers, **kwargs)
[rank0]:   File "/wangbenyou/huanghj/workspace/hallo3/hallo3/train_video.py", line 180, in forward_step
[rank0]:     batch = next(data_iterator)
[rank0]:   File "/sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 630, in __next__
[rank0]:     data = self._next_data()
[rank0]:   File "/sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1324, in _next_data
[rank0]:     return self._process_data(data)
[rank0]:   File "/sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1370, in _process_data
[rank0]:     data.reraise()
[rank0]:   File "/sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/_utils.py", line 706, in reraise
[rank0]:     raise exception
[rank0]: AssertionError: Caught AssertionError in DataLoader worker process 3.
[rank0]: Original Traceback (most recent call last):
[rank0]:   File "/sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py", line 309, in _worker_loop
[rank0]:     data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
[rank0]:   File "/sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch
[rank0]:     data = [self.dataset[idx] for idx in possibly_batched_index]
[rank0]:   File "/sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 52, in <listcomp>
[rank0]:     data = [self.dataset[idx] for idx in possibly_batched_index]
[rank0]:   File "/sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/sat/data_utils/configure_data.py", line 360, in __getitem__
[rank0]:     return self.wrapped_data[index]
[rank0]:   File "/sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/sat/data_utils/configure_data.py", line 342, in __getitem__
[rank0]:     return self.datasets[dataset_idx][sample_idx]
[rank0]:   File "/wangbenyou/huanghj/workspace/hallo3/hallo3/data_video.py", line 550, in __getitem__
[rank0]:     assert ori_vlen > sample_len, video_path
[rank0]: AssertionError: /wangbenyou/huanghj/data/hallo3-dataset/videos/003a5800f7511a6d7609a2245391f00b.mp4

W0207 09:57:22.238000 140587200083776 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 129428 closing signal SIGTERM
W0207 09:57:22.241000 140587200083776 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 129429 closing signal SIGTERM
W0207 09:57:22.249000 140587200083776 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 129430 closing signal SIGTERM
W0207 09:57:22.275000 140587200083776 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 129431 closing signal SIGTERM
W0207 09:57:22.281000 140587200083776 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 129433 closing signal SIGTERM
W0207 09:57:22.291000 140587200083776 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 129434 closing signal SIGTERM
W0207 09:57:22.297000 140587200083776 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 129435 closing signal SIGTERM
W0207 09:57:52.331000 140587200083776 torch/distributed/elastic/multiprocessing/api.py:875] Unable to shutdown process 129429 via Signals.SIGTERM, forcefully exiting via Signals.SIGKILL
W0207 09:58:23.548000 140587200083776 torch/distributed/elastic/multiprocessing/api.py:875] Unable to shutdown process 129435 via Signals.SIGTERM, forcefully exiting via Signals.SIGKILL
E0207 09:58:30.947000 140587200083776 torch/distributed/elastic/multiprocessing/api.py:833] failed (exitcode: 1) local_rank: 0 (pid: 129427) of binary: /sds_wangby/group_conda_envs/anaconda3/envs/hallo3/bin/python
Traceback (most recent call last):
  File "/sds_wangby/group_conda_envs/anaconda3/envs/hallo3/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 348, in wrapper
    return f(*args, **kwargs)
  File "/sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/distributed/run.py", line 901, in main
    run(args)
  File "/sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 133, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/sds_wangby/group_conda_envs/anaconda3/envs/hallo3/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
hallo3/train_video.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-02-07_09:57:22
  host      : 297hi17a9s0l1-0
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 129427)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
